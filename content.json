{"pages":[{"title":"","text":"","link":"/style.css"},{"title":"","text":"帅俊岚","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"},{"title":"","text":"Java并发编程的是艺术 不要将获取锁的过程写在try块中，因为如果在锁获取（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放； ReentrantReadWriteLock，锁降级中读锁的获取是否有必要呢？","link":"/todo/Java%E2%96%93%D0%B2%E2%95%96%D0%B2%E2%96%92%D1%80%E2%94%82%E2%95%A0%E2%95%A1%E2%94%80%E2%95%A9%E2%95%9F%E2%95%A5%E2%95%92%E2%95%A9%D1%97.html"},{"title":"","text":"Netty 入门与实战：仿写微信 IM 即时通讯系统笔记 Java NIO的selector实现原理？ 如何理解下面这句话？ IO 读写是面向流的，一次性只能从流中读取一个或者多个字节，并且读完之后流无法再读取，你需要自己缓存数据。 而 NIO 的读写是面向 Buffer 的，你可以随意读取里面任何一个字节数据，不需要你自己缓存数据，这一切只需要移动读写指针即可。 下面是我总结的使用 Netty 不使用 JDK 原生 NIO 的原因 123456781.使用 JDK 自带的NIO需要了解太多的概念，编程复杂，一不小心 bug 横飞2.Netty 底层 IO 模型随意切换，而这一切只需要做微小的改动，改改参数，Netty可以直接从 NIO 模型变身为 IO 模型3.Netty 自带的拆包解包，异常检测等机制让你从NIO的繁重细节中脱离出来，让你只需要关心业务逻辑4.Netty 解决了 JDK 的很多包括空轮询在内的 Bug5.Netty 底层对线程，selector 做了很多细小的优化，精心设计的 reactor 线程模型做到非常高效的并发处理6.自带各种协议栈让你处理任何一种通用协议都几乎不用亲自动手7.Netty 社区活跃，遇到问题随时邮件列表或者 issue8.Netty 已经历各大 RPC 框架，消息中间件，分布式通信中间件线上的广泛验证，健壮性无比强大. 回调 channelRead() 方法，这里的第二个参数 msg，在我们这个场景中，可以直接强转为 ByteBuf，为什么 Netty 不直接把这个参数类型定义为 ByteBuf ？","link":"/todo/Netty%20%E2%95%9A%D1%8B%E2%94%9C%E2%94%BC%E2%95%99%D1%8B%E2%95%A9%E2%95%A1%E2%95%92%E2%95%9C%D0%B3%E2%95%91%E2%95%96%E2%94%AC%E2%95%A8%E2%94%A4%E2%95%AC%D0%B2%E2%95%A8%E2%94%BC%20IM%20%E2%95%9D%E2%94%A4%E2%95%A9%E2%96%92%E2%95%90%D0%B8%E2%95%A4%E2%95%A2%E2%95%A7%E2%95%A1%E2%95%90%E2%94%82%E2%96%92%E2%95%A9%E2%95%9D%E2%95%9F.html"},{"title":"Java中Unsafe类详解","text":"VM “intrinsification.” ie CAS (Compare-And-Swap) used in Lock-Free Hash Tables eg:sun.misc.Unsafe.compareAndSwapInt it can make real JNI calls into native code that contains special instructions for CAS read more about CAS here http://en.wikipedia.org/wiki/Compare-and-swap The sun.misc.Unsafe functionality of the host VM can be used to allocate uninitialized objects and then interpret the constructor invocation as any other method call. One can track the data from the native address.It is possible to retrieve an object’s memory address using the java.lang.Unsafe class, and operate on its fields directly via unsafe get/put methods! Compile time optimizations for JVM. HIgh performance VM using “magic”, requiring low-level operations. eg: http://en.wikipedia.org/wiki/Jikes_RVM Allocating memory, sun.misc.Unsafe.allocateMemory eg:- DirectByteBuffer constructor internally calls it when ByteBuffer.allocateDirect is invoked Tracing the call stack and replaying with values instantiated by sun.misc.Unsafe, useful for instrumentation sun.misc.Unsafe.arrayBaseOffset and arrayIndexScale can be used to develop arraylets,a technique for efficiently breaking up large arrays into smaller objects to limit the real-time cost of scan, update or move operations on large objects http://robaustin.wikidot.com/how-to-write-to-direct-memory-locations-in-java Reference https://stackoverflow.com/questions/5574241/why-does-sun-misc-unsafe-exist-and-how-can-it-be-used-in-the-real-world http://bytescrolls.blogspot.com/2011/04/interesting-uses-of-sunmiscunsafe.html","link":"/todo/java-unsafe-class.html"},{"title":"Netty中Reactor线程模型详解","text":"netty源码分析之揭开reactor线程的面纱（三）","link":"/todo/netty-reactor.html"},{"title":"","text":"Guide to the Java Phaser Java 7中新增了一个灵活的线程同步栅栏—Phaser，如果你需要在执行某些任务之前等待其他任务执行到某个状态，那么Phaser是一个很好的选择，这篇文章将介绍java.util.concurrent.Phaser，它和CountDownLatch具有相似的功能，但是Phaser更灵活。 基本术语在理解Phaser类的运行机制之前，我们先来了解Phaser类中的一些基本术语： Registration 开篇我们讲过，Phaser比CountDownLatch和CyclicBarrier更灵活，因为它可以通过register()和bulkRegister(int parties)来动态调整注册任务的数量，任务也可以通过执行arriveAndDeregister()来注销任务，Phaser允许的最大任务注册数量为65535。 Arrival 正如Phaser类的名字所暗示，每个Phaser实例都会维护一个phase number，初始值为0。每当所有注册的任务都到达Phaser时，phase number累加，并在超过Integer.MAX_VALUE后清零。arrive()和arriveAndDeregister()方法用于记录到 达，arriveAndAwaitAdvance()方法用于记录到达，并且等待其它未到达的任务。 Termination Phaser支持终止。Phaser终止之后，调用register()和bulkRegister(int parties)方法没有任何效果，arriveAndAwaitAdvance()方法也会立即返回。触发终止的时机是在protected boolean onAdvance(int phase, int registeredParties)方法返回时，如果该方法返回true，那么Phaser会被终止，默认实现是在注册任务数为0时返回true（即 return registeredParties == 0;），我们也可以通过重写这个方法来自定义的终止逻辑。此外，forceTermination()方法用于强制终止，isTerminated()方法用于判断是否已经终止。 Tiering Phaser支持层次结构，即通过构造函数Phaser(Phaser parent)和Phaser(Phaser parent, int parties)构造一个树形结构。这有助于减轻因在单个的Phaser上注册过多的任务而导致的竞争，从而提升吞吐量，代价是增加单个操作的开销。 核心API Phaser(int parties)，构造方法，与CountDownLatch一样，传入同步的线程数，也支持层次构造Phaser(Phaser parent)。 register()，bulkRegister(int Parties)，动态添加一个或多个参与者。 arriveAndDeregister()方法，动态撤销线程在phaser的注册，通知phaser对象，该线程已经结束该阶段且不参与后面阶段。 isTerminated()，当phaser没有参与同步的线程时（或者onAdvance返回true），phaser是终止态（如果phaser进入终止态arriveAndAwaitAdvance()和awaitAdvance()都会立即返回，不在等待）isTerminated返回true。 arrive()方法，通知phaser该线程已经完成该阶段，但不等待其他线程。 arriveAndAwaitAdvance()方法，类似await()方法，记录到达线程数，阻塞等待其他线程到达同步点后再继续执行。 awaitAdvance(int phase) /awaitAdvanceInterruptibly(int phase) 传入阶段数，只有当前阶段等于phase阶段时才阻塞等待。后者如果线程在休眠被中断会抛出InterruptedException异常（phaser的其他方法对中断都不会抛出异常）。 onAdvance(int phase, int registeredParties)方法。参数phase是阶段数，每经过一个阶段该数加1，registeredParties是当注册的线程数。此方法有2个作用：1、当每一个阶段执行完毕，此方法会被自动调用，因此，重载此方法写入的代码会在每个阶段执行完毕时执行，相当于CyclicBarrier的barrierAction。2、当此方法返回true时，意味着Phaser被终止，因此可以巧妙的设置此方法的返回值来终止所有线程。例如：若此方法返回值为 phase &gt;= 3，其含义为当整个线程执行了3个阶段后，程序终止。 forceTermination()方法，强制phaser进入终止态。 简单示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @author Shuai Junlan[shuaijunlan@gmail.com]. * @since Created in 2:26 PM 11/7/18. */public class PhaserTest { public static void main(String[] args) throws InterruptedException { final Phaser phaser = new Phaser(1); for (int index = 1; index &lt;= 10; index++){ phaser.register(); new Thread( new Player(phaser), \"Player\" + index).start(); } System.out.println(\"Game start\"); phaser.arriveAndDeregister(); while (!phaser.isTerminated()){ Thread.sleep(100); } System.out.println(\"Game over\"); }}class Player implements Runnable{ private final Phaser phaser; Player(Phaser phaser){ this.phaser = phaser; } @Override public void run() { //First step, waiting for all threads be created phaser.arriveAndAwaitAdvance(); try { //Second step, waiting for all players be ready Thread.sleep( new Random().nextInt(100) * 10L); System.out.println( Thread.currentThread().getName() + \" ready\"); phaser.arriveAndAwaitAdvance(); /////////////////running//////////////////// //Third step, waiting for all players arrived, then competition finishing. System.out.println( Thread.currentThread().getName() + \" arrived\"); phaser.arriveAndDeregister(); } catch (InterruptedException e) { e.printStackTrace(); } }} 输出结果： 12345678910111213141516171819202122Game startPlayer10 readyPlayer4 readyPlayer9 readyPlayer1 readyPlayer7 readyPlayer6 readyPlayer8 readyPlayer5 readyPlayer2 readyPlayer3 readyPlayer3 arrivedPlayer5 arrivedPlayer6 arrivedPlayer1 arrivedPlayer4 arrivedPlayer7 arrivedPlayer8 arrivedPlayer9 arrivedPlayer10 arrivedPlayer2 arrivedGame over","link":"/todo/java-phaser.html"},{"title":"","text":"synchronized 关键字原理","link":"/todo/synchorize.html"},{"title":"Netty服务端启动过程分析","text":"Difficult","link":"/todo/netty-serverside-bootstrap-procedure.html"}],"posts":[{"title":"Autoboxing and Autounboxing","text":"前言： 首先我们要知道Java中有哪些基本数据类型以及它们各自的封装类:package java.lang; 基本数据类型 封装类 byte Byte boolean Boolean char Character short Short int Integer long Long float Float double Double 一、什么是Autoboxing java中Autoboxing是指将基本数据类型自动转换成封装类类型。比如说： 123456789public void test1(){ int a = 10; Integer b = a; System.out.println(b); Character d = 'c'; System.out.println(d);} 函数参数为封装类类型时，调用时传递基本数据类型，会发生Autoboxing。 将基本数据类型变量赋值给封装类类型时，会发生Autoboxing。 二、什么是Autounboxing java中Autounboxing是指将封装类类型自动转换成基本数据类型。比如说： 12345678910public void test2(){ Integer a = new Integer(10); int b = a; System.out.println(b); Character c = 'c'; char d = c; System.out.println(d);} 函数参数为基本数据类型，调用时传递封装类类型，会发生Autounboxing。 将封装类类型变量赋值给基本数据类型，或者直接用封装类类型进行基本运算，会发生Autounboxing。 三、以int类型为例，讲解Autoboxing和Autounboxing实现原理 先来看一段代码反汇编的结果 java代码 12345678910111213141516171819package com.sh.$16.$12.$22;/** * Created by Mr SJL on 2016/12/22. * * @Author Junlan Shuai */import java.util.ArrayList;import java.util.List;public class App1{ public static void main(String[] args) { Integer integer = 10; int i = integer; }} 反汇编结果 1234567891011121314151617public class com.sh.$16.$12.$22.App1 { public com.sh.$16.$12.$22.App1(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public static void main(java.lang.String[]); Code: 0: bipush 10 2: invokestatic #2 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 5: astore_1 6: aload_1 7: invokevirtual #3 // Method java/lang/Integer.intValue:()I 10: istore_2 11: return} 从以上java代码可以看出，“Integer integer = 10;”此句发生了Autoboxing。从汇编结果可以看出，实际在编译的时候发生了，Integer a = Integer.valueOf(10);调用了Integer类的valueOf方法。 1234567891011121314151617181920/** * Returns an {@code Integer} instance representing the specified * {@code int} value. If a new {@code Integer} instance is not * required, this method should generally be used in preference to * the constructor {@link #Integer(int)}, as this method is likely * to yield significantly better space and time performance by * caching frequently requested values. * * This method will always cache values in the range -128 to 127, * inclusive, and may cache other values outside of this range. * * @param i an {@code int} value. * @return an {@code Integer} instance representing {@code i}. * @since 1.5 */public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);} 从以上java代码可以看出，“int i = integer;”此句发生了Autounboxing。从汇编结果可以看出，实际在编译的时候发生了，int i = integer.intValue();调用了Integer类的intValue方法。 1234567/** * Returns the value of this {@code Integer} as an * {@code int}. */public int intValue() { return value;} 四、总结 其他基本数据类型的Autoboxing and Autounboxing也满足此。 思考：1234567891011121314151617181920212223242526272829303132package com.sh.$16.$12.$24;/** * Created by Mr SJL on 2016/12/24. * * @Author Junlan Shuai */public class App2{ public static void main(String[] args) { int a = 10; int b = 10; Integer c = new Integer(10); Integer d = Integer.valueOf(10); Integer e = 2000; Integer f = 2000; System.out.println(\"a=b:\" +(a==b)); System.out.println(\"a=c:\" +(a==c)); System.out.println(\"a=d:\" +(a==d)); System.out.println(\"c=d:\" +(c==d)); System.out.println(\"e=f:\" +(e==f)); }}// 运行结果：a=b:truea=c:truea=d:truec=d:falsee=f:false","link":"/2016/09/26/Autopacking%20and%20Autounpacking/"},{"title":"Basing on Spring SpringMVC MyBatis Druid Shrio developing web system","text":"源码下载地址：https://github.com/shuaijunlan/Autumn-Framework 在线Demo：http://autumn.shuaijunlan.cn 项目介绍Autumn-Framework旨在提供通用的web系统解决方案，目前由作者本人一个人维护，更新速度缓慢，但是会持续更新，此项目适合初学者学习使用，也欢迎您加入我一起维护整个项目。 效果图 登录界面 系统主界面![系统主界面][main] 菜单管理![菜单管理][menu] 日志管理![日志管理][log] ![日志管理][log1] 技术选型前端以Layui为主要框架，并使用了ECharts、editor.md等其他第三方插件后端主要使用Spring、SpringMVC、MyBatis、Shiro、Druid、Ehcache构建整个web系统，并使用Maven管理项目，使用Mysql存储数据，使用tomcat部署web系统。 代码结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950.└── src-------------------------------------------源码根目录 └── main ├── java │ └── com │ └── autumnframework │ └── cms │ ├── architect-------------包含常用的工具类和常量 │ │ ├── conf │ │ ├── constant │ │ ├── filter │ │ ├── interceptor │ │ └── utils │ ├── controller------------控制器层 │ │ └── system │ ├── dao-------------------dao层 │ │ ├── bomapper │ │ └── vomapper │ │ ├── impl │ │ └── interfaces │ ├── model-----------------model层 │ │ ├── bo │ │ ├── po │ │ └── vo │ ├── service---------------service层 │ │ ├── impl │ │ └── interfaces │ └── shiroconfig-----------shiro配置 │ ├── filter │ └── realm ├── resources----------------------------资源文件目录 │ ├── mapperxml------------------------mapper映射文件 │ ├── mybatis-generator----------------mybatis-generator配置文件 │ └── spring---------------------------所有与spring相关的配置文件 └── webapp-------------------------------前端源码文件 ├── BasePlu--------------------------公共库 ├── comm ├── Lib------------------------------第三方库 │ ├── Echarts-3.7.2 │ ├── editor.md │ ├── jquery │ └── layui_v2.1.2 ├── static--------------------------静态资源 ├── Sys-----------------------------系统功能插件目录 │ ├── js │ └── plugin └── WEB-INF └── views ├── error-------------------异常目录 └── main--------------------系统主界面目录 运行系统 拷贝代码到本地git clone git@github.com:shuaijunlan/Autumn-Framework.git 进入Autumn-Framework目录cd Autumn-Framework 执行mvn install 再进入cms目录cd cms 在执行mvn tomcat7:run 最后在浏览器中访问localhost:8081，就可以看到登录界面 Tips：以上所有操作基于您的电脑已经安装了jdk8、maven和git环境 FAQ联系作者您有任何问题都可以随时联系我！ Email：shuaijunlan@gmail.com [main]:https://github.com/shuaijunlan/shuaijunlan.github.io/blob/master/images/main-page.png?raw=true “系统主界面””[menu]:https://github.com/shuaijunlan/shuaijunlan.github.io/blob/master/images/menu-manage.png?raw=true “菜单管理””[log]:https://github.com/shuaijunlan/shuaijunlan.github.io/blob/master/images/log-manage1.png?raw=true “日志管理”[log1]:https://github.com/shuaijunlan/shuaijunlan.github.io/blob/master/images/log-manage2.png?raw=true “日志管理”","link":"/2017/11/03/Basing-on-Spring-SpringMVC-MyBatis-Druid-Shrio-developing-web-system/"},{"title":"CentOS7中配置KVM教程","text":"基本环境：CentOS7.0 [root@localhost /]# egrep ‘(vmx|svm)’ /proc/cpuinfo 和 Xen 不同，KVM 需要有 CPU 的支持（Intel VT 或 AMD SVM），在安装 KVM 之前检查一下 CPU 是否提供了虚拟技术的支持,可以通过下面命令查询是否支持，如果输出有相关的vmx或者svm，表明CPU支持，否则就不支持。 [root@localhost /]# yum install qemu-kvm qemu-img virt-manager libvirt libvirt-python python-virtinst libvirt-client virt-install virt-viewer kvm相关安装包及其作用（按需选择安装） qemu-kvm：qemu模拟器,主要的KVM程序包 qemu-img：qemu磁盘image管理器 virt-install：基于libvirt服务的虚拟机创建命令，用来创建虚拟机的命令行工具 libvirt：提供libvirtd daemon来管理虚拟机和控制hypervisor libvirt-client：提供客户端API用来访问server和提供管理虚拟机命令行工具的virsh实体 python-virtinst：创建虚拟机所需要的命令行工具和程序库 virt-manager：GUI虚拟机管理工具 virt-top：虚拟机统计命令 virt-viewer：GUI连接程序，连接到已配置好的虚拟机 bridge-utils：创建和管理桥接设备的工具 验证是否安装成功 验证内核模块是否加载 [root@localhost /]# lsmod | grep kvm 启动服务(同时设置了开机自启) [root@localhost /]# systemctl start libvirtd.service 重启服务 [root@localhost /]# systemctl restart libvirtd.service 设置可用 [root@localhost /]# systemctl enable libvirtd.service 查看服务基本信息 [root@localhost /]# systemctl status libvirtd.service 配置虚拟机网络 见《libvirt kvm虚拟机网络配置》一文 在CentOS上安装vnc服务，通过vnc客户端远程连接CentOS，通过图形化界面在宿主机上安装客户机，安装教程见《使用VNC工具初级教程》一文 最后安装客户机 下载虚拟机要安装的ISO系统镜像文件，之后需创建存储池，指定在宿主机上虚拟机磁盘的存储位置，创建存储目录：(目录随便设定，按照自己的需求设定) [root@localhost /]# mkdir -p /home/kvm1 定义一个储存池和绑定目录： [root@localhost /]# virsh pool-define-as vmspool –type dir –target /home/kvm1 建立并激活存储池： [root@localhost /]# virsh pool-build vmspool [root@localhost /]# virsh pool-start vmspool virsh-install: 1、输入虚拟机名称 2、分配多少内存 3、处理器的个数 4、此步可以直接输入iso的位置或是url 5、虚拟机类型KVM 6、定义虚拟机磁盘映像的位置 7、磁盘的大小 6、指定哪个桥或者可以指定多个桥 7、额外的控制台和KS文件 8、连接到系统参数 参数说明注意每行都要空格 -n 虚拟机名称 -r 分配虚拟机内存大小 –vcpus 分配虚拟cpu个数 -c 镜像文件位置 –vnc –vncport=5901 –vnclisten=0.0.0.0 启动图形安装界面 –virt-type 虚拟机模式 -f 虚拟机系统文件存储目录 -s 分配磁盘大小（GB） -w 联网方式（birdge bridge:br0/nat bridge:virbr0） –os-type=’windows’ –os-variant=win2k3 安装windows最好加上这个否则会报错 virt-install工具安装虚拟机后，在目录/etc/libvirt/qemu/下生成xml配置文件 -s 用来指定虚拟磁盘的大小单位为GB -m 指定虚拟网卡的硬件地址默认virt-install自动产生 -p 以半虚拟化方式建立虚拟机 -l 指定安装来源 -x EXTRA, –extra-args=EXTRA当执行从”–location”选项指定位置的客户机安装时，附加内核命令行参数到安装程序。 -v, –hvm 设置全虚拟化 创建第一个guest： [root@localhost /]# virt-install –name=CentOS7-1 –ram=4096 –vcpus=1 –cdrom=/home/kvm1/CentOS-7-x86_64-Minimal-1511.iso –virt-type=kvm –disk path=/home/kvm1/centos7-1.img,device=disk,format=qcow2,bus=virtio,cache=writeback,size=250 –graphics vnc,listen=0.0.0.0,port=5920,password=123456 –network bridge:br0 –accelerate –force –autostart 创建第二个guest： [root@localhost /]# virt-install –name=CentOS7-2 –ram=7168 –vcpus=2,maxvcpus=4 –cdrom=/home/kvm1/CentOS-7-x86_64-Minimal-1511.iso –virt-type=kvm –disk path=/home/kvm1/centos7-2.img,device=disk,format=qcow2,bus=virtio,cache=writeback,size=400 –graphics vnc,listen=0.0.0.0,port=5921,password=123456 –network bridge:br0 –accelerate –force –autostart 创建第三个guest： [root@localhost /]# virt-install –name=CentOS7-3 –ram=7168 –vcpus=6,maxvcpus=9 –cpuset=6,7,8,9,10,11 –cdrom=/home/kvm1/CentOS-7-x86_64-Minimal-1511.iso –virt-type=kvm –disk path=/home/kvm1/centos7-3.img,device=disk,format=qcow2,bus=virtio,cache=writeback,size=400 –graphics vnc,listen=0.0.0.0,port=5922,password=123456 –network bridge:br0 –accelerate –force –autostart 创建第四个guest： [root@localhost /]# virt-install –name=CentOS7-4 –ram=7168 –vcpus=6,maxvcpus=9 –cpuset=12,13,14,15,16,17 –cdrom=/home/kvm1/CentOS-7-x86_64-Minimal-1511.iso –virt-type=kvm –disk path=/home/kvm1/centos7-4.img,device=disk,format=qcow2,bus=virtio,cache=writeback,size=400 –graphics vnc,listen=0.0.0.0,port=5923,password=123456 –network bridge:br0 –accelerate –force –autostart 持续更新中…… REFERENCES KVM虚拟机创建功能详细讲解 绑定KVM虚拟机的vcpu与物理CPU 基于Linux命令行KVM虚拟机的安装配置与基本使用 CENTOS7 安装KVM笔记之安装 linux下配置和安装KVM虚拟机","link":"/2016/11/20/CentOS7-kvm/"},{"title":"CentOS7设置免密登陆","text":"基本环境 master(centOS7-4:192.168.1.75) slave1(CentOS7-1:192.168.1.21) slave2(CentOS7-2:192.168.1.129) 前提条件 要保证这三台机器之间可以互相ping通 基本配置 在slave1机器上输入命令：vi /etc/ssh/sshd_config 在master机器上输入命令：vi /etc/ssh/sshd_config 在master和slave1上建立相同的用户，此文章以root用户为例，读者可以自行创建其他用户。 登陆到master机器上 执行命令：mkdir .ssh（创建.ssh文件夹），如果存在此文件夹可以不用创建 进入到.ssh目录（执行命令：cd .ssh）,并执行命令：ssh-keygen -t rsa，并一直回车，出现以下结果： 可以看到在.ssh目录下面生成了两个文件：id_rsa（私钥）和id_rsa.pub（公钥）两个文件 使用root用户登陆slave1，同样执行1-3步。 合并id_rsa.pub，追加到authorized_key文件中 root登录master, 在“.ssh”文件夹下，执行命令：scp id_rsa.pub root@slave1:~/.ssh/authorized_keys 拷贝master的公钥id_rsa.pub到slave1的.ssh/authorized_keys。此过程会要求输入密码。 test登录slave,在“.ssh”文件夹下，输入命令：cat id_rsa.pub &gt;&gt; authorized.keys,把slave1的公钥id_rsa.pub追加到slave的authorized_keys文件。 在slave1的“.ssh”文件夹下，复制authorized_keys到master的root，命令“scp authorized_keys root@master:~/.ssh/“，此时，master “.ssh”文件夹下，已经存在与slave1相同的authorized_keys文件 测试登陆 输入命令：ssh master，登陆到master系统 输入命令：exit，退出系统","link":"/2016/11/26/CentOS7-login/"},{"title":"基于Zookeeper实现分布式锁","text":"基于Zookeeper实现分布式锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import com.google.common.base.Strings;import com.google.common.util.concurrent.ThreadFactoryBuilder;import org.apache.zookeeper.*;import java.io.IOException;import java.util.concurrent.*;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 15:37 2018/3/31. */public class DistributedLockBasedOnZookeeper { private String hostPort = \"host:port\"; private String lockNameSpace = \"/myLock\"; private String nodeString = lockNameSpace + \"/test1\"; private ZooKeeper zk; public DistributedLockBasedOnZookeeper(){ try { zk = new ZooKeeper(hostPort, 6000, event -&gt; { System.out.println(\"Receive event \" + event); if (Watcher.Event.KeeperState.SyncConnected == event.getState()){ System.out.println(\"Connection is established...\"); } }); } catch (IOException e) { e.printStackTrace(); } } private void ensureRootPath() throws InterruptedException { try { if (zk.exists(lockNameSpace, true) == null){ zk.create(lockNameSpace, \"\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); } } catch (KeeperException e) { e.printStackTrace(); } } private void watchNode(String nodeString, final Thread thread){ try { zk.exists(nodeString, event -&gt; { System.out.println(\"==\" + event.toString()); if (event.getType() == Watcher.Event.EventType.NodeDeleted){ System.out.println(\"There is a Thread released lock.....\"); thread.interrupt(); } try { zk.exists(nodeString, true); } catch (KeeperException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } }); } catch (KeeperException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } } /** * get Lock * @return */ public boolean getLock() throws InterruptedException { String path = null; ensureRootPath(); watchNode(nodeString, Thread.currentThread()); while (true){ try { path = zk.create(nodeString, \"\".getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL); } catch (KeeperException e) { System.out.println(Thread.currentThread().getName() + \"getting Lock but can not get\"); Thread.sleep(5000); } if (!Strings.nullToEmpty(path).trim().isEmpty()){ System.out.println(Thread.currentThread().getName() + \" get Lock...\"); return true; } } } /** * release Lock */ public void unlock(){ try { zk.delete(nodeString, -1); System.out.println(Thread.currentThread().getName() + \" release Lock...\"); } catch (InterruptedException e) { e.printStackTrace(); } catch (KeeperException e) { e.printStackTrace(); } } public static void main(String[] args) { ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat(\"demo-pool-%d\").build(); ExecutorService service = new ThreadPoolExecutor(10, 10, 1000L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;&gt;(1024), threadFactory, new ThreadPoolExecutor.AbortPolicy()); for (int i = 0; i &lt; 4; i++){ service.execute(() -&gt; { DistributedLockBasedOnZookeeper lockBasedOnZookeeper = new DistributedLockBasedOnZookeeper(); try { lockBasedOnZookeeper.getLock(); Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } lockBasedOnZookeeper.unlock(); }); } service.shutdown(); }}","link":"/2018/03/31/Distributed-Lock-Based-On-Zookeeper/"},{"title":"Distributed-Systems-Technologies","text":"1.分布式系统中基本概念及常用技术介绍网络I/O模型1.同步和异步 同步： 异步： 2.阻塞和非阻塞 阻塞： 非阻塞: 3.UNIX网络I/O模型远程过程调用（RPC） 2.分布式系统架构体系基于对象的体系结构面向服务的架构（SOA）REST风格的架构微服务架构（MSA）容器技术Serverless架构原则3.分布式消息服务ActiveMQRabbitMQRocketMQKafka","link":"/2018/03/22/Distributed-Systems-Technologies/"},{"title":"How-to-understand-the-DeadLock","text":"如何理解如下代码会造成DeadLock1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 10:36 2018/4/14. */public class DeadLock { static class Friend{ private final String name; public Friend(String name){ this.name = name; } public String getName(){ return this.name; } public synchronized void bow(Friend friend){ System.out.format(\"%s:%s\" + \" has bowed to me!%n\", this.name, friend.getName()); friend.bowBack(this); } public synchronized void bowBack(Friend friend){ System.out.format(\"%s:%s\" + \" has bowed back to me!%n\", this.name, friend.getName()); } } public static void main(String[] args) throws InterruptedException { final Friend friendA = new Friend(\"Shuai\"); final Friend friendB = new Friend(\"Junlan\"); ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(2, 2, 1000L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;&gt;(2)); /// Why not using this way to create ThreadPool? // ExecutorService fixedThreadPool = Executors.newFixedThreadPool(2); threadPoolExecutor.execute(() -&gt; friendA.bow(friendB)); threadPoolExecutor.execute(() -&gt; friendB.bow(friendA)); threadPoolExecutor.shutdown(); }} output 12Shuai:Junlan has bowed to me!Junlan:Shuai has bowed to me! Conclusion 类的实例对类中所有的synchronized方法都持有锁；（表述不够官方）","link":"/2018/03/25/How-to-understand-the-DeadLock/"},{"title":"Java类与对象初始化过程","text":"看看如下代码，输出结果是啥？1234567891011121314151617181920212223242526272829303132/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 18:59 2018/4/1. */public class Test { public static int k = 0; public static Test t1 = new Test(\"t1\"); public static Test t2 = new Test(\"t2\"); public static int i = print(\"i\"); public static int n = 99; public int j = print(\"j\"); static { print(\"静态块\"); } public Test(String string){ System.out.println((++k) + \":\" + string + \" i=\" + i + \" n=\" + n); ++i; ++n; } { print(\"构造块\"); } public static int print(String string){ System.out.println((++k) + \":\" + string + \" i=\" + i + \" n=\" + n); ++n; return ++i; } public static void main(String[] args) { Test test = new Test(\"init\"); }} Output 12345678910111:j i=0 n=02:构造块 i=1 n=13:t1 i=2 n=24:j i=3 n=35:构造块 i=4 n=46:t2 i=5 n=57:i i=6 n=68:静态块 i=7 n=999:j i=8 n=10010:构造块 i=9 n=10111:init i=10 n=102 Reference Java类与对象初始化的过程","link":"/2018/04/01/Java-Class-and-Object-Initializing-Process/"},{"title":"Java NIO and BIO","text":"我们都知NIO是非阻塞IO，BIO是阻塞IO，那到底什么是阻塞，什么是非阻塞呢，它们与同步/异步又有什么区别呢？先来了解一下阻塞/非阻塞，同步/异步的概念。 阻塞/非阻塞/同步/异步 阻塞： 当某个事件或者任务在执行过程中，它发出一个请求操作，但是由于该请求操作需要的条件不满足，那么就会一直在那等待，直至条件满足； 非阻塞： 当某个事件或者任务在执行过程中，它发出一个请求操作，如果该请求操作需要的条件不满足，会立即返回一个标志信息告知条件不满足，不会一直在那等待。 同步： 可以理解为在执行一个函数或方法，只有接收到返回的值或消息后才会继续往下执行其他的命令。 callee执行完成才返回返回值即结果 异步： 可以理解为在执行一个函数或方法，不用等待其返回，继续往下执行其他的命令。 callee不需要执行完成就可返回caller要获取结果，需要通过轮询、回调等机制 Update 同步与异步的区别：函数调用发生时，消息(参数)从caller传递到callee，控制权(指令执行)从caller转移到callee。调用返回时，控制权从callee转移到caller。两者的区别在于，callee是否需要等待执行完成才将控制权转移给caller。 阻塞IO和非阻塞IO通常来说，IO操作包括：对硬盘的读写、对socket的读写以及外设的读写。 当用户线程发起一个IO请求操作（本文以读请求操作为例），内核会去查看要读取的数据是否就绪，对于阻塞IO来说，如果数据没有就绪，则会一直在那等待，直到数据就绪；对于非阻塞IO来说，如果数据没有就绪，则会返回一个标志信息告知用户线程当前要读的数据没有就绪。当数据就绪之后，便将数据拷贝到用户线程，这样才完成了一个完整的IO读请求操作，也就是说一个完整的IO读请求操作包括两个阶段： 查看数据是否就绪； 进行数据拷贝（内核将数据拷贝到用户线程）。 那么阻塞（BIO）和非阻塞（NIO）的区别就在于第一个阶段，如果数据没有就绪，在查看数据是否就绪的过程中是一直等待，还是直接返回一个标志信息。 Java中传统的IO都是阻塞IO，比如通过socket来读数据，调用read()方法之后，如果数据没有就绪，当前线程就会一直阻塞在read方法调用那里，直到有数据才返回；而如果是非阻塞IO的话，当数据没有就绪，read()方法应该返回一个标志信息，告知当前线程数据没有就绪，而不是一直在那里等待，从jdk1.4开始引入NIO。 基于Java API实现NioServer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 14:19 2018/4/15. * * 基于Java API实现NIO server */public class PlainNioServer { public void server(int port) throws IOException { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); ServerSocket serverSocket =serverSocketChannel.socket(); //将服务器绑定到选定的端口 InetSocketAddress address = new InetSocketAddress(port); serverSocket.bind(address); //打开Selector来处理Channel Selector selector = Selector.open(); //将ServerSocket注册到Selector以接受连接 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); final ByteBuffer msg = ByteBuffer.wrap(\"Hi! \\r\\n\".getBytes()); for (;;){ try { //等待需要处理的新事件；阻塞将一直持续到下一个传入事件 selector.select(); } catch (IOException ex){ ex.printStackTrace(); break; } //获取所有接收事件的SelectorKey实例 Set&lt;SelectionKey&gt; readyKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = readyKeys.iterator(); while (iterator.hasNext()){ SelectionKey key = iterator.next(); iterator.remove(); //检查事件是否是一个新的已经就绪可以被接受的连接 if (key.isAcceptable()){ ServerSocketChannel server = (ServerSocketChannel) key.channel(); SocketChannel client = server.accept(); client.configureBlocking(false); //接受客户端，并将它注册到选择器 client.register(selector, SelectionKey.OP_WRITE | SelectionKey.OP_READ, msg.duplicate()); System.out.println(\"Accepted connection from \" + client); } //检查套接字是否已经准备好写数据 if (key.isWritable()){ SocketChannel client = (SocketChannel)key.channel(); ByteBuffer byteBuffer = (ByteBuffer)key.attachment(); while (byteBuffer.hasRemaining()){ //将数据写到已连接的客户端 if (client.write(byteBuffer) == 0){ break; } } //关闭连接 client.close(); } key.cancel(); key.channel().close(); } } }}","link":"/2018/04/19/Java-NIO-and-BIO/"},{"title":"基于HashMap和双向链表实现LRUCache","text":"使用HashMap和双向链表实现LRUCache，HashMap用来定位节点是否已经存在，时间复杂度为O(1)，双向链表用来用来实现LRU规则，移动节点的时间复杂度也是O(1)，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package cn.shuaijunlan.cache.lru;import java.util.HashMap;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 10:48 2018/4/12. */public class LruCacheOnLinkedAndMap&lt;K, V&gt; { /** * 定义双向链表节点 * @param &lt;K&gt; * @param &lt;V&gt; */ private class Entry&lt;K, V&gt;{ Entry pre; Entry next; K key; V value; public Entry(K key,V value){ this.key = key; this.value = value; } } /** * 缓存大小 */ private final int size; /** * 存储Entry Node */ private HashMap&lt;K,Entry&lt;K,V&gt;&gt; map; /** * 链表尾节点 */ private Entry last; /** * 链表头节点 */ private Entry first; public LruCacheOnLinkedAndMap(int size){ if (size &lt;= 0){ throw new IllegalArgumentException(\"The size of Cache must more than zero!\"); } this.size = size; map = new HashMap(); } public void put(K key, V value){ Entry entry = map.get(key); if (entry == null){ if (map.size() &gt;= this.size){ removeLast(); } entry = new Entry(key, value); } entry.value = value; moveToFirst(entry); map.put(key, entry); } /** * 删除尾节点 */ public void removeLast(){ if (last != null){ map.remove(last.key); last = last.pre; if (last == null){ first = null; }else { last.next = null; } } } public Entry get(K key){ Entry entry = map.get(key); if (entry == null){ return null; } moveToFirst(entry); return entry; } /** * 根据LRU规则，将最近使用的节点移至链表头部 * @param entry */ public void moveToFirst(Entry entry){ if (entry == first){ return; } if (entry.pre != null){ entry.pre.next = entry.next; } if (entry.next != null){ entry.next.pre = entry.pre; } if (entry == last){ last = last.pre; } if (first == null || last == null){ first = last = entry; return; } entry.next = first; first.pre = entry; first = entry; entry.pre = null; } public void print() { Entry temp = first; while (temp != null){ System.out.println(\"Key:\" + temp.key + \" Value:\" + temp.value); temp = temp.next; } System.out.println(map.size()); } /** * 测试函数 * @param args */ public static void main(String[] args) { LruCacheOnLinkedAndMap&lt;String, Integer&gt; lruCacheOnLinkedAndMap = new LruCacheOnLinkedAndMap&lt;&gt;(6); lruCacheOnLinkedAndMap.put(\"s\", 1); lruCacheOnLinkedAndMap.put(\"h\", 2); lruCacheOnLinkedAndMap.put(\"u\", 3); lruCacheOnLinkedAndMap.put(\"a\", 8); lruCacheOnLinkedAndMap.put(\"i\", 4); lruCacheOnLinkedAndMap.put(\"j\", 7); lruCacheOnLinkedAndMap.put(\"u\", 1); lruCacheOnLinkedAndMap.put(\"s\", 10); lruCacheOnLinkedAndMap.print(); }}","link":"/2018/04/12/LruCache-On-Map-And-LinkedList/"},{"title":"MyBatis实战（一)","text":"一、MyBatis框架简介 MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 二、使用MyBatis框架与原生开发方式对比 数据库连接配置： 使用MyBatis框架： 1234567891011&lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://115.28.61.171:3306/xx\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"********\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; 使用JDBC： 1234567891011121314151617public Connection conn = null; public String url=\"jdbc:mysql://134.78.21.143:3306/xx\"; public String password=\"********\"; public String dbName=\"root\"; public String driverName=\"com.mysql.jdbc.Driver\"; public Connection getConnection()throws ClassNotFoundException,SQLException { try { Class.forName(driverName);//指定连接类型 conn = DriverManager.getConnection(url, dbName, password);//获取连接 }catch (SQLException e) { e.printStackTrace(); } return conn; } 查询数据库 使用MyBatis框架： 1234567891011&lt;mapper namespace=\"com.mb.interfaces.IWcUserOperation\"&gt; &lt;resultMap type=\"WcUser\" id=\"resultListUser\"&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"openid\" property=\"openid\"/&gt; &lt;result column=\"nickname\" property=\"nickname\"/&gt; &lt;result column=\"province\" property=\"province\"/&gt; &lt;/resultMap&gt; &lt;select id=\"selectUserById\" parameterType=\"int\" resultType=\"WcUser\"&gt; select * from WXUSER where id= #{id} &lt;/select&gt; &lt;/mapper&gt; 12IWcUserOperation userOperation = session.getMapper(IWcUserOperation.class); WcUser wcUser = userOperation.selectUserById(15); 使用JDBC： 123456789101112131415161718192021222324252627282930public void getArticle(Connection conn, ArtisvrInitPara yjsvrInitPara, JSONObject jo) { String sql = \"select * from \"+yjsvrInitPara.getTabname()+\" where \"+yjsvrInitPara.getExp(); try { st= conn.createStatement(); rs= st.executeQuery(sql); System.out.println(rs); while(rs.next()) { Article ar= new Article(); ar.setId( rs.getInt(\"id\")); ar.setClasses( rs.getString(\"classes\")); ar.setContent( rs.getString(\"content\")); ar.setClirate( rs.getInt(\"clirate\")); ar.setTitle( rs.getString(\"title\")); ar.setFbtime( rs.getString(\"fbtime\")); list.add(ar); } } catch (SQLException e) { e.printStackTrace(); } JSONArray ja=JSONArray.fromObject(list); jo.put(\"ret\", ja); ms.close(rs, st, conn); } 三、总结 使用Mybatis框架可以直接将数据表中每个字段映射到实体类的属性，简化了使用JDBC带来的复杂度。 附录：（完整Demo）（暂时没有时间整理Demo，后期提供） 持续更新中。。。。。。","link":"/2017/06/26/MyBatis-tutorial/"},{"title":"Spring中Bean的初始化与销毁（基于Spring4.x）","text":"通过在bean中设置init-method和destroy-method 配置beanspring-lifecycle.xml 123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"beanLifeCycle\" class=\"com.sh.imcdemo.services.impl.BeanLifeCycle\" init-method=\"start\" destroy-method=\"stop\"&gt;&lt;/bean&gt;&lt;/beans&gt; com.sh.imcdemo.services.impl 实现类 1234567891011121314151617package com.sh.imcdemo.services.impl;/** * Created by Mr SJL on 2016/11/26. * * @Author Junlan Shuai */public class BeanLifeCycle{ public void start() { System.out.println(\"Bean start.\"); } public void stop() { System.out.println(\"Bean stop.\"); }} 通过实现InitializingBean和DisposableBean接口 配置beanspring-lifecycle.xml 123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"beanLifeCycle1\" class=\"com.sh.imcdemo.services.impl.BeanLifeCycle\"&gt;&lt;/bean&gt;&lt;/beans&gt; com.sh.imcdemo.services.impl实现类 123456789101112131415161718192021222324package com.sh.imcdemo.services.impl;import org.springframework.beans.factory.DisposableBean;import org.springframework.beans.factory.InitializingBean;/** * Created by Mr SJL on 2016/11/26. * * @Author Junlan Shuai */public class BeanLifeCycle implements InitializingBean, DisposableBean{ public void destroy() throws Exception { System.out.println(\"Bean destory.\"); } public void afterPropertiesSet() throws Exception { System.out.println(\"Bean afterPropertiesSet.\"); }} 通过设置default-destroy-method和default-init-method 对于同一配置文件下的所有的Bean都会使用该默认的初始化和销毁方法（但有特殊情况，见本篇总结部分） 1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\" default-destroy-method=\"defaultDestroy\" default-init-method=\"defaultInit\"&gt; &lt;bean id=\"beanLifeCycle\" class=\"com.sh.imcdemo.services.impl.BeanLifeCycle\"&gt;&lt;/bean&gt;&lt;/beans&gt; com.sh.imcdemo.services.impl 123456789101112131415161718package com.sh.imcdemo.services.impl;/** * Created by Mr SJL on 2016/11/26. * * @Author Junlan Shuai */public class BeanLifeCycle{ public void defaultInit() { System.out.println(\"Bean defaultInit.\"); } public void defaultDestroy() { System.out.println(\"Bean defaultDestory\"); }} 总结 当三种方式同时使用时，我们会发现，第三种方式被覆盖了，另外两种方式的输出先后顺序是：先是2再是1。 当使用第3种方式时，实现类中不一定非要实现该默认方法，如果没有该方法，则没有处理。 当第2种和第3中方式同时使用时，默认方法却没有被覆盖，两者都会输出，但是第1种和第3种同时使用时，默认方法却被覆盖了。（？？？） 附录 测试基类 com.sh.imcdemo.unitTest 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.sh.imcdemo.unitTest;import org.apache.commons.lang.StringUtils;import org.junit.After;import org.junit.Before;import org.springframework.beans.BeansException;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * Created by Mr SJL on 2016/11/26. * * @Author Junlan Shuai */public class UnitTestBase{ private ClassPathXmlApplicationContext context; private String springXmlpath; public UnitTestBase() { } public UnitTestBase(String springXmlpath) { this.springXmlpath = springXmlpath; } @Before public void before() { if (StringUtils.isEmpty(springXmlpath)) { springXmlpath = \"classpath*:spring-*.xml\"; } try { context = new ClassPathXmlApplicationContext(springXmlpath.split(\"[,\\\\s]+\")); context.start(); } catch (BeansException e) { e.printStackTrace(); } } @After public void after() { context.destroy(); } protected &lt;T extends Object&gt; T getBean(String beanId) { return (T)context.getBean(beanId); } protected &lt;T extends Object&gt; T getBean(Class&lt;T&gt; clas) { return context.getBean(clas); }} 测试类com.sh.imcdemo.unitTest 12345678910111213141516171819202122232425262728293031package com.sh.imcdemo.unitTest;import org.junit.Test;import org.junit.runner.RunWith;import org.junit.runners.BlockJUnit4ClassRunner;/** * Created by Mr SJL on 2016/11/26. * * @Author Junlan Shuai */@RunWith(BlockJUnit4ClassRunner.class)public class App3 extends UnitTestBase{ public App3() { super(\"classpath:spring-lifecycle.xml\"); } @Test public void test1() { super.getBean(\"beanLifeCycle\"); } @Test public void test2() { super.getBean(\"beanLifeCycle1\"); }} 依赖包pom.xml 1234567891011121314151617181920212223242526272829303132&lt;spring.version&gt;4.3.2.RELEASE&lt;/spring.version&gt;&lt;junit.version&gt;4.11&lt;/junit.version&gt;&lt;!-- Spring依赖包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 单元测试包 --&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt;&lt;/dependency&gt;","link":"/2016/10/26/Spring-bean-init-destory/"},{"title":"akka-actor-introduction","text":"","link":"/2019/04/17/akka-actor-introduction/"},{"title":"analyse the source code of Timer","text":"Timer Class Introduction 在JDK库中Timer类主要负责计划任务的功能，也就是在指定的时间开始执行某任务。 A Simple Example12345678910111213141516171819202122232425262728293031323334353637383940414243import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.Timer;import java.util.TimerTask;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 9:53 2017/7/26. */public class TimerTest { // define a timer private static Timer timer = new Timer(); // define MyTask class static public class MyTask extends TimerTask{ private String str; public MyTask(String str){ this.str = str; } @Override public void run() { System.out.println(this.str + \"running:\" + new Date()); } } // test main public static void main(String[] args) throws ParseException { MyTask myTask1 = new MyTask(\"task1\"); MyTask myTask2 = new MyTask(\"task2\"); SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String dateString1 = \"2017-07-26 10:06:01\"; Date date1 = sdf.parse(dateString1); String dateString2 = \"2017-07-26 10:05:01\"; Date date2 = sdf.parse(dateString2); timer.schedule(myTask1, date1); timer.schedule(myTask2, date2); }} 在这个例子中，定义了两个TimerTask，并且设定执行时间，调用Timer的schedule()方法，传入任务和时间，执行正确。 Timer源码分析 首先我们以timer.schedule()方法为入口，进一步剖析整个执行流程。看看Timer的schedule()的源码： 123public void schedule(TimerTask task, Date time) { sched(task, time.getTime(), 0);} 再进一步看sched()方法的源码 123456789101112131415161718192021222324252627private void sched(TimerTask task, long time, long period) { if (time &lt; 0) throw new IllegalArgumentException(\"Illegal execution time.\"); // Constrain value of period sufficiently to prevent numeric // overflow while still being effectively infinitely large. if (Math.abs(period) &gt; (Long.MAX_VALUE &gt;&gt; 1)) period &gt;&gt;= 1; synchronized(queue) { if (!thread.newTasksMayBeScheduled) throw new IllegalStateException(\"Timer already cancelled.\"); synchronized(task.lock) { if (task.state != TimerTask.VIRGIN) throw new IllegalStateException( \"Task already scheduled or cancelled\"); task.nextExecutionTime = time; task.period = period; task.state = TimerTask.SCHEDULED; } queue.add(task); if (queue.getMin() == task) queue.notify(); }} 在这个函数里面涉及到了两个重要的变量（queue和task）； 首先是获取queue同步锁，设置task的基本属性，包括nextExecutionTime、perid、state； 将task添加到queue中，等待task被执行； TaskQueue源码分析 底层是定义了一个private TimerTask[] queue = new TimerTask[128];数组，用来存储TimerTask，默认值为128； TaskQueue是直接定义在Timer.java的类，是一个优先级队列，是根据nextExecutionTime排序的；最小的nextExecutionTime 如果queue不是空的，最小的TimeTask.nextExecutionTime就是queue[1]； 主要理解两个函数：fixUp()和fixDown(); 12345678910111213141516171819202122private void fixUp(int k) { while (k &gt; 1) { int j = k &gt;&gt; 1; if (queue[j].nextExecutionTime &lt;= queue[k].nextExecutionTime) break; TimerTask tmp = queue[j]; queue[j] = queue[k]; queue[k] = tmp; k = j; }}private void fixDown(int k) { int j; while ((j = k &lt;&lt; 1) &lt;= size &amp;&amp; j &gt; 0) { if (j &lt; size &amp;&amp; queue[j].nextExecutionTime &gt; queue[j+1].nextExecutionTime) j++; // j indexes smallest kid if (queue[k].nextExecutionTime &lt;= queue[j].nextExecutionTime) break; TimerTask tmp = queue[j]; queue[j] = queue[k]; queue[k] = tmp; k = j; }} 每次调用add()方法，先将任务添加到quene的最后一个，然后调用fixUp()方法，调整整个queue，将拥有最小nextExecutionTime的TimerTask调整到queue[1]位置，如果位置不够，则需要扩容，按照原来容量的两倍扩容；","link":"/2017/07/26/analyse-the-source-code-of-Timer/"},{"title":"Dubbo Gracefully Shutdown机制分析","text":"","link":"/2018/09/22/dubbo-gracefully-shutdown/"},{"title":"Dubbo基于Javassist实现动态代理分析","text":"12345org.apache.dubbo.common.bytecode.Proxy //生成代理类org.apache.dubbo.common.bytecode.ClassGenerator //基于javassist封装org.apache.dubbo.common.utils.ClassHelper; //工具类org.apache.dubbo.common.utils.ReflectUtils; //工具类 123456789101112131415161718192021// create ProxyInstance class.//生成代理类的实例String pcn = pkg + \".proxy\" + id;ccp.setClassName(pcn);ccp.addField(\"public static java.lang.reflect.Method[] methods;\");ccp.addField(\"private \" + InvocationHandler.class.getName() + \" handler;\");ccp.addConstructor(Modifier.PUBLIC, new Class&lt;?&gt;[]{InvocationHandler.class}, new Class&lt;?&gt;[0], \"handler=$1;\");ccp.addDefaultConstructor();Class&lt;?&gt; clazz = ccp.toClass();clazz.getField(\"methods\").set(null, methods.toArray(new Method[0]));// create Proxy class.//生成代理类，通过调用newInstance()方法获取实例String fcn = Proxy.class.getName() + id;ccm = ClassGenerator.newInstance(cl);ccm.setClassName(fcn);ccm.addDefaultConstructor();ccm.setSuperClass(Proxy.class);ccm.addMethod(\"public Object newInstance(\" + InvocationHandler.class.getName() + \" h){ return new \" + pcn + \"($1); }\");Class&lt;?&gt; pc = ccm.toClass();proxy = (Proxy) pc.newInstance();","link":"/2018/08/02/dubbo-proxy-basing-on-javassist/"},{"title":"Dubbo路由机制分析","text":"这篇文章主要讲Dubbo的路由特性，当Consumer发起一个请求，Dubbo依据配置的路由规则，计算出那些提供者可以提供这次的请求服务，所以路由机制会在集群容错策略和负载均衡策略之前被执行，下面我们来开始分析源码。 执行路由机制的入口是在AbstractClusterInvoker类的invoke方法，其中调用了list()方法，然后会执行AbstractDirectory的list()方法： AbstractDirectory#list() 1234567891011121314151617181920212223@Overridepublic List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException { if (destroyed) { throw new RpcException(\"Directory already destroyed .url: \" + getUrl()); } //获取所有的提供者 List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation); //在哪里设置的routers？稍后揭晓 List&lt;Router&gt; localRouters = this.routers; // local reference if (localRouters != null &amp;&amp; !localRouters.isEmpty()) { for (Router router : localRouters) { try { if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, false)) { //依次通过路由规则进行过滤 invokers = router.route(invokers, getConsumerUrl(), invocation); } } catch (Throwable t) { logger.error(\"Failed to execute router: \" + getUrl() + \", cause: \" + t.getMessage(), t); } } } return invokers;} 那么路由器是在哪设置的？通过搜索代码发现是则AbstractDirectory类的setRouters()方法里设置的： AbstractDirectory#setRouters() 123456789101112131415161718protected void setRouters(List&lt;Router&gt; routers) { // copy list routers = routers == null ? new ArrayList&lt;Router&gt;() : new ArrayList&lt;Router&gt;(routers); // append url router String routerKey = url.getParameter(Constants.ROUTER_KEY); if (routerKey != null &amp;&amp; routerKey.length() &gt; 0) { //根据Dubbo SPI机制获取RouterFactory RouterFactory routerFactory = ExtensionLoader.getExtensionLoader(RouterFactory.class).getExtension(routerKey); routers.add(routerFactory.getRouter(url)); } // append mock invoker selector 为什么添加这个？ //MockInvokersSelector路由器，是dubbo对mock调用支持的一部分,稍后看下源码 routers.add(new MockInvokersSelector()); //进行排序？？ //排序后MockInvokersSelector会放在最后 Collections.sort(routers); this.routers = routers;} 再进一步分析，setRouters()在哪里被调用了？通过查看方法调用栈，在AbstractDirectory的子类RegisterDirectory里notify()方法里调用了，notify()方法是注册中心通知consumer回调的方法： RegisterDirectory#notify() 12345678910111213141516171819202122232425262728293031323334353637383940414243@Overridepublic synchronized void notify(List&lt;URL&gt; urls) { List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;(); for (URL url : urls) { String protocol = url.getProtocol(); String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); if (Constants.ROUTERS_CATEGORY.equals(category) || Constants.ROUTE_PROTOCOL.equals(protocol)) { routerUrls.add(url); } else if (Constants.CONFIGURATORS_CATEGORY.equals(category) || Constants.OVERRIDE_PROTOCOL.equals(protocol)) { configuratorUrls.add(url); } else if (Constants.PROVIDERS_CATEGORY.equals(category)) { invokerUrls.add(url); } else { logger.warn(\"Unsupported category \" + category + \" in notified url: \" + url + \" from registry \" + getUrl().getAddress() + \" to consumer \" + NetUtils.getLocalHost()); } } // configurators if (configuratorUrls != null &amp;&amp; !configuratorUrls.isEmpty()) { this.configurators = toConfigurators(configuratorUrls); } // routers if (routerUrls != null &amp;&amp; !routerUrls.isEmpty()) { //把路由配置转换成路由实例 List&lt;Router&gt; routers = toRouters(routerUrls); if (routers != null) { // null - do nothing setRouters(routers); } } List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference // merge override parameters this.overrideDirectoryUrl = directoryUrl; if (localConfigurators != null &amp;&amp; !localConfigurators.isEmpty()) { for (Configurator configurator : localConfigurators) { this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl); } } // providers refreshInvoker(invokerUrls);} 在上面的方法中，有一个比较重要的方法toRouters()，它将路由配置转换成路由实例： RegisterDirectory#toRouters() 12345678910111213141516171819202122232425262728293031/** * @param urls * @return null : no routers ,do nothing * else :routers list */private List&lt;Router&gt; toRouters(List&lt;URL&gt; urls) { List&lt;Router&gt; routers = new ArrayList&lt;Router&gt;(); if (urls == null || urls.isEmpty()) { return routers; } if (urls != null &amp;&amp; !urls.isEmpty()) { for (URL url : urls) { if (Constants.EMPTY_PROTOCOL.equals(url.getProtocol())) { continue; } String routerType = url.getParameter(Constants.ROUTER_KEY); if (routerType != null &amp;&amp; routerType.length() &gt; 0) { url = url.setProtocol(routerType); } try { Router router = routerFactory.getRouter(url); if (!routers.contains(router)) { routers.add(router); } } catch (Throwable t) { logger.error(\"convert router url to router error, url: \" + url, t); } } } return routers;} 下面将分别分析四种路由的具体实现和配置方法： ConditionRouterFactory创建一个ConditionRouter实例， ScriptRouterFactory创建一个ScriptRouter实例， TagRouterFactory创建一个TagRouter实例， FileRouterFactory","link":"/2018/10/17/dubbo-router-analysis/"},{"title":"HTTP详解","text":"The Hypertext Transfer Protocol (HTTP) is an application-level protocol that uses TCP as an underlying transport and typically runs on port 80. HTTP is a stateless protocol i.e. server maintains no information about past client requests. HTTP与TCP/IP的关系HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠的传递数据包，使在网络上的另一端收到发端发出的所有包，并且顺序与发出顺序一致。TCP有可靠，面向连接的特点。 HTTP是无状态的HTTP协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系。HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）。 长连接和短连接在HTTP/1.0中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。 但从 HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：Connection:keep-alive 相对于持久化连接HTTP1.1还有另外比较重要的改动： HTTP 1.1增加host字段 HTTP 1.1中引入了Chunked transfer-coding，范围请求，实现断点续传(实际上就是利用HTTP消息头使用分块传输编码，将实体主体分块传输) HTTP 1.1管线化(pipelining)理论，客户端可以同时发出多个HTTP请求，而不用一个个等待响应之后再请求 ​ 注意：这个pipelining仅仅是限于理论场景下，大部分桌面浏览器仍然会选择默认关闭HTTP pipelining！ ​ 所以现在使用HTTP1.1协议的应用，都是有可能会开多个TCP连接的！ 短连接我们模拟一下TCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server 发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起 close操作。为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在 client/server间传递一次读写操作 优点：管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段 长连接接下来我们再模拟一下长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。 优点 Lower CPU and memory usage because there are less number of connections. Allows HTTP pipelining of requests and responses. Reduced network congestion (fewer TCP connections). Reduced latency in subsequent requests (no handshaking). Errors can be reported without the penalty of closing the TCP connection. 缺点 Resources may be be kept occupied even when not needed and may not be available to others. REFERENCEhttp://developer.51cto.com/art/201808/580780.htm Persistent Connections HTTP Non-Persistent &amp; Persistent Connection | Set 1 HTTP长连接和短连接","link":"/2018/05/19/http/"},{"title":"Collections.sort()源码分析（基于jdk1.8）","text":"Collections类中定义了一系列的静态方法，其中就包括sort方法(下面为该方法的源码),从这个方法的源码中可以看出，它调用的是list.sort()方法，在该方法中先将list转换成数组，然后调用Arrays.sort()方法。在Arrays.sort()方法中，有一个条件判断（LegacyMergeSort.userRequested），当此条件为true时，调用legacyMergeSort(a, c);若为false则调用TimSort.sort(a, 0, a.length, c, null, 0, 0);通过legacyMergeSort(a, c);源码就可以看出此方法实现的是归并排序， Collections.sort()方法源码1234@SuppressWarnings({\"unchecked\", \"rawtypes\"})public static &lt;T&gt; void sort(List&lt;T&gt; list, Comparator&lt;? super T&gt; c) { list.sort(c);} list.sort()方法源码12345678910@SuppressWarnings({\"unchecked\", \"rawtypes\"})default void sort(Comparator&lt;? super E&gt; c) { Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) { i.next(); i.set((E) e); }} Arrays.sort()方法源码12345678910public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) { if (c == null) { sort(a); } else { if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); }} mergeSort()方法源码，legacyMergeSort()方法将会在未来的版本中被移除。mergeSort()方法中，当待排序数组长度小于7时，使用的是插入排序。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** To be removed in a future release. */private static &lt;T&gt; void legacyMergeSort(T[] a, Comparator&lt;? super T&gt; c) { T[] aux = a.clone(); if (c==null) mergeSort(aux, a, 0, a.length, 0); else mergeSort(aux, a, 0, a.length, 0, c);}/** * Tuning parameter: list size at or below which insertion sort will be * used in preference to mergesort. * To be removed in a future release. */private static final int INSERTIONSORT_THRESHOLD = 7;/** * Src is the source array that starts at index 0 * Dest is the (possibly larger) array destination with a possible offset * low is the index in dest to start sorting * high is the end index in dest to end sorting * off is the offset to generate corresponding low, high in src * To be removed in a future release. */@SuppressWarnings({\"unchecked\", \"rawtypes\"})private static void mergeSort(Object[] src, Object[] dest, int low, int high, int off) { int length = high - low; // Insertion sort on smallest arrays if (length &lt; INSERTIONSORT_THRESHOLD) { for (int i=low; i&lt;high; i++) for (int j=i; j&gt;low &amp;&amp; ((Comparable) dest[j-1]).compareTo(dest[j])&gt;0; j--) swap(dest, j, j-1); return; } // Recursively sort halves of dest into src int destLow = low; int destHigh = high; low += off; high += off; int mid = (low + high) &gt;&gt;&gt; 1; mergeSort(dest, src, low, mid, -off); mergeSort(dest, src, mid, high, -off); // If list is already sorted, just copy from src to dest. This is an // optimization that results in faster sorts for nearly ordered lists. if (((Comparable)src[mid-1]).compareTo(src[mid]) &lt;= 0) { System.arraycopy(src, low, dest, destLow, length); return; } // Merge sorted halves (now in src) into dest for(int i = destLow, p = low, q = mid; i &lt; destHigh; i++) { if (q &gt;= high || p &lt; mid &amp;&amp; ((Comparable)src[p]).compareTo(src[q])&lt;=0) dest[i] = src[p++]; else dest[i] = src[q++]; }}/** * Swaps x[a] with x[b]. */private static void swap(Object[] x, int a, int b) { Object t = x[a]; x[a] = x[b]; x[b] = t;}","link":"/2017/02/26/java-Collections-sort-method/"},{"title":"队列同步器(AbstractQueuedSynchronizer)源码分析","text":"AbstractQueuedSynchronizer(队列同步器)在Java并发工具中经常被用到，比如说我们常用的CountDownLatch、ReentrantLock、ReentrantReadWriteLock和Semaphore等等并发工具类底层都是基于队列同步器的，只有掌握了队列同步器底层的工作原理才能更好的理解其他的并发工具的工作机制，这篇文章将会从源码的角度分析队列同步器的工作原理。 队列同步器设计是基于模板方法的，使用者只需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。 通过对队列同步器的API进行分析，主要通过三个方法来修改队列同步器的状态： getState() //获取当前的状态 setState() //设置当前的同步状态 compareAndSetState() //使用CAS机制设置当前的状态 需要重写的方法： 独占操作 方法名称 描述 protected boolean tryAcquire(int arg) 独占式获取同步状态，实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行CAS设置同步状态 protected boolean tryRelease(int arg) 独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态 共享操作 方法名称 描述 protected int tryAcquireShared(int arg) 共享式获取同步状态，返回大于等于0，表示获取成功，反之获取失败 protected boolean tryReleaseShared(int arg) 共享式释放同步状态 protected boolean isHeldExclusively() 当前同步器是否独占模式下被线程占用，一般该方法表示是否被当前线程所占用 同步队列队列同步器一来内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前显示获取同步状态失败时，队列同步器将会以当前线程以及等待状态等信息来构建一个Node节点，并将其加入同步队列的尾部，同时会阻塞当前线程，当同步状态释放时，会把同步队列的首节点中的线程唤醒，使其再次尝试获取同步状态。 我们来看一下Node节点有哪些属性： 属性类型和名称 描述 int waitStatus 等待状态，包含如下状态： 1.CANCELLED，值为1，由于在同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待。节点进入该状态将不会发生变化2.SIGNAL，值为-1，后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，将会通知后继节点，使后继节点的线程得以运行3.CONDITION，值为-2，表示当前节点正在条件队列（AQS下的ConditionObject里也维护了个队列）中，在从conditionObject队列转移到同步队列前，它不会在同步队列（AQS下的队列）中被使用，当成功转移后，该节点的状态值将由CONDITION设置为04.PROPAGATE，值为-3，共享模式下的释放操作应该被传播到其他节点。该状态值在doReleaseShared方法中被设置的5.INITIAL，值为0，初始状态 Node prev 前驱节点，当节点加入同步队列时被设置 Node next 后继节点 Node nextWaiter ConditionObject链表的后继节点或者代表共享模式的节点SHARED。Condition条件队列：因为Condition队列只能在独占模式下被能被访问， 我们只需要简单的使用链表队列来链接正在等待条件的节点。再然后它们会被转移到同步队列（AQS队列）再次重新获取。由于条件队列只能在独占模式下使用，所以我们要表示共享模式的节点的话只要使用特殊值SHARED来标明即可。 Thread thread 节点所指向的线程 独占式同步状态获取与释放 共享式同步状态获取与释放独占式超时获取同步状态 自定义同步组件Reference 《Java并发编程的艺术》","link":"/2018/11/22/java-abstract-queued-synchronizer/"},{"title":"Java基础知识点总结","text":"总结了一些Java基础知识点，主要包括Container、Concurrent、IO、JVM等方面，通过思维导图的方式展现，随着我进一步的学习，也会不断更新下面的知识点，具体请看下图：","link":"/2018/12/26/java-basic-knowledge-summary/"},{"title":"深入研究Java阻塞队列实现","text":"阻塞队列是一个非常常见的数据结构，比如在线程池中用阻塞队列存放任务，下面我们将围绕阻塞队列的实现对其源码进行深度剖析，主要讲解ArrayBlockingQueue、PriorityBlockingQueue、SynchronousQueue和LinkedBlockingQueue四大阻塞队列的实现。 LinkedBlockingQueue 双锁队列算法的变体 优化 Why copy final member field into local final variable? 双锁队列比单锁队列的好处？ LinkedBlockingQueue#dequeue()的优化 1234567891011private E dequeue() { // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x;} 基本接口 offer()方法和put()方法的区别？ 线程池如何关闭空闲线程的？","link":"/2018/10/15/java-blocking-queue/"},{"title":"CAS and Lock-Free in Java","text":"在Java中的原子类中频繁的使用CAS策略来保证数据更新的安全性，它是一种Lock-Free机制，这篇文章将会讲解CAS原理，以及它在Java中的应用。 Lock-Free 如果一个方法是 Lock-Free 的, 它保证线程无限次调用这个方法都能够在有限步内完成. 相比于传统的基于 Mutex 锁机制, Lock-Free 有下面的优势: Lock-Free 的速度更快 线程之间不会相互影响, 没有死锁 不受异步信号影响, 可重入 不会发生线程优先级反转 在通常使用 Mutex 互斥锁的场景, 有的线程抢占了锁, 其他线程则会被阻塞, 当获得锁的进程挂掉之后, 整个程序就 block 住了. 但在 Lock-Free 的程序中, 单个线程挂掉, 也不会影响其他线程, 因为线程之间不会相互影响. 但是, Lock-Free 也有不少缺陷: 只能利用有限的原子操作, 例如 CAS (操作的位数有限), 编码实现复杂 竞争会加剧, 优先级不好控制 测试时需要考虑各种软硬件环境, 很难做到尽善尽美 再引入一个 Wait-Free 概念: 假如一个方法是 Wait-Free 的, 那么它保证了每一次调用都可以在有限的步骤内结束. 一般来说: 阻塞 &gt; Lock-Free &gt; Wait-Free CAS原语CAS (compare and swap) 是 CPU 硬件同步原语(primitive), CAS(V, A, B) 操作可以用下面的代码来示意: 12345678template &lt;class T&gt;bool CAS(T* addr, T expect_val, T val) { if (*addr == expect_val) { *addr = val; return true; } return false;} 从 80486 开始, 所有的 Intel 处理器上, 通过一条汇编指令 CMPXCHG 即可实现 CAS 操作. CAS 的价值在于它是一个原子操作, 不会被 CPU中断或者其他方式打断, 因为在硬件层实现, 所以开销极小. CAS 并不是一项新技术, 它的使用可以追溯到 70 年代, 早在 80 年代就有很多经典书籍中提到使用 CAS 来实现并行编程, 如 USC 大牛 Kai HWang 的 “Computer Architecture and Parallel Processing”. GCC 4.1+ 开始支持 CAS 的原子操作: 12bool __sync_bool_compare_and_swap (type *ptr, type oldval, type newval)type __sync_val_compare_and_swap (type *ptr, type oldval, type newval) 通常将 CAS 用于同步的方式是从地址 V 读取值 A, 执行多步计算来获得新值 B, 然后使用 CAS 将 V 的值从 A 改为 B, 如果 V 处的值尚未同时更改, 则 CAS 操作成功. CAS中的ABA问题ABA 问题描述: 切换到线程 T1, 获取内存 V 的值 A 切换到线程 T2, 获取内存 V 的值 A, 修改成 B, 然后再修改成 A 切换到线程 T1, 获取内存 V 的值还是 A, 继续执行 coolshell 上有篇文章给出了一个生动的例子(From 维基百科): 你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意的时候，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了. 更具有参考意义的是Hazard Pointer Wiki上提到的一个 Lock-Free 堆栈的例子: 当前栈元素 [A, B, C], 栈顶 head 指向 A 线程 T1 执行 pop() 准备 CAS(&amp;head, B, A) 线程 T2 抢占, pop A, pop B, 然后 push A 线程 T1 恢复, CAS(&amp;head, B, A) 成功, 则此时 head 指向一个被 pop 的元素 B CAS机制还存在其他问题： 循环时间长开销大: 自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 只能保证一个共享变量的原子操作: 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。 CAS在Java中的应用 在Java中所有原子类都采用了CAS机制，并且在jdk1.5之后提供了AtomicStampedReference来解决上述提到的ABA问题； AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用CAS机制来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下：","link":"/2018/12/27/java-cas-and-lock-free/"},{"title":"Java中常量池详解","text":"阅读这篇文章之前先来理解几个基本的概念 什么是常量 equals()方法和==的区别 引用和对象的区别 1. String常量池1.1 创建String对象的两种方式 通过new来创建String创对象，例如：String a = new String(“a”); 直接将字符串常量赋值给一个对象引用，例如：String b = “b”; 这两种不同的创建方法是有差别的，第一种方式是直接在Java heap内存空间创建一个新的对象，并且引用变量a指向这个对象，第二种方式是引用变量b指向常量池中的字符串。 1.2 先来看一个Demo12345678910111213141516171819202122232425262728293031323334353637package com.sh.oc.test;import org.junit.Test;import org.junit.runner.RunWith;import org.junit.runners.BlockJUnit4ClassRunner;/** * Created by Mr SJL on 2016/12/16. * * @Author Junlan Shuai */@RunWith(BlockJUnit4ClassRunner.class)public class Test1{ @Test public void test1() { String a = \"helloWorld\"; String b = \"helloWorld\"; String c = new String(\"helloWorld\"); String d = \"hello\"; String e = new String(\"hello\"); String temp = \"World\"; String f = \"hello\" + temp; String g = \"hello\" + \"World\"; System.out.println(\"(1) a=b:\" + (a == b)); System.out.println(\"(2) b=c:\" + (b == c)); System.out.println(\"(3) a=d:\" + (a == (d + \"World\"))); System.out.println(\"(4) a=e:\" + (a == (e + \"World\"))); System.out.println(\"(5) c=d:\" + (c == (d + \"World\"))); System.out.println(\"(6) c=e:\" + (c == (e + \"World\"))); System.out.println(\"(7) a=g:\" + (a == g)); System.out.println(\"(8) a=f:\" + (a == f)); }} 结果输出： 12345678910(1) a=b:true(2) b=c:false(3) a=d:false(4) a=e:false(5) c=d:false(6) c=e:false(7) a=g:true(8) a=f:falseProcess finished with exit code 0 1.3 总结： 对于第(1)个结果，直接将相同的字符串常量赋值给字符串引用变量（后称‘变量’）a，b，在编译的时候该字符串直接保存在常量池中，同时变量a，b同时指向这个字符串常量，所以a==b返回true； 第(2)个结果，对于变量c，是通过new一个对象（该对象保存在java heap中），然后变量c指向这个对象。故变量b和c指向的是不同的内存空间，b==c返回false； 第(3)个结果，对于加法运算d + “World”在执行的时候，首先是通过创建一个StringBuilder对象，然后调用该对象的append()方法，最后调用该对象的toString()方法。也就是相当于执行了new StringBuilder().append(d).append(“Word”).toString()。由StringBuilder源码可知，最后结果返回一个String对象(存放在java heap中)。故变量a和d指向不同的内存地址空间，虽然value是一样的，最终返回false。对于第(4)个结果，原理和(3)一样。 12345@Overridepublic String toString() { // Create a copy, don't share the array return new String(value, 0, count);} 对于第(5)和(6)个结果，因为变量c指向的是在java heap中的一个String对象，并且加法运算(d + “World”)，返回的也是一个String对象，但是它们指向的地址空间不同，故返回false。 对于第(7)和(8)的结果，原理和前面相同。 持续更新中。。。。。。","link":"/2016/07/26/java-constant-pool/"},{"title":"Java中Copy-On-Write容器","text":"Copy-On-Write简称COW，是一种用于程序设计中的优化策略。其基本思路是，从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器,它们是CopyOnWriteArrayList和CopyOnWriteArraySet。CopyOnWrite容器非常有用，可以在非常多的并发场景中使用到。 CopyOnWrite的缺点CopyOnWrite容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下。 内存占用问题。因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说200M左右，那么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的Yong GC和Full GC。之前我们系统中使用了一个服务由于每晚使用CopyOnWrite机制更新大对象，造成了每晚15秒的Full GC，应用响应时间也随之变长。 针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如ConcurrentHashMap。 数据一致性问题。CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。 Reference http://ifeve.com/java-copy-on-write/ https://blog.csdn.net/qq_31780525/article/details/54375792","link":"/2018/12/05/java-copy-on-write/"},{"title":"Java创建线程的三种方式(Thread/Runnable/Callable)","text":"1.继承Thread类 此方式只需要重写Thread类中的run()方法即可，示例如下： 1234567891011121314151617/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 19:41 2017/4/10. */public class ExtendThread extends Thread{ String name; public ExtendThread(String name) { this.name = name; } @Override public void run() { System.out.println(name); }} 2.实现Runnable接口 此方式只需要实现Runnable接口中的run()方法，示例如下： 12345678910111213141516/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 19:40 2017/4/10. */public class ImplRunnable implements Runnable{ public String name; public ImplRunnable(String name) { this.name = name; } public void run() { System.out.println(name); }} 3.实现Callable接口 实现Callable接口中的calla()方法，示例如下： 123456789101112131415161718import java.util.concurrent.Callable;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 19:43 2017/4/10. */public class ImplCallable implements Callable&lt;String&gt;{ public String name; public ImplCallable(String name) { this.name = name; } public String call() throws Exception { return name; }} 4.Runnable和Callable的区别1234567891011121314151617181920212223public interface Callable&lt;V&gt; { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;}public interface Runnable { /** * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used * to create a thread, starting the thread causes the object's * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing * thread. * &lt;p&gt; * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run();} Callable中申明的方法是call(),Runnable中申明的方法是run(); Callable中的call()方法有返回值，而run()方法没有返回值; call()方法可抛出异常，而run()方法则没有;5.Future详解 12345678public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} cancel()方法：当参数为true时，直接终止当前执行的任务，当参数为false是允许当前的任务执行完成； get()方法：等待任务执行完成，并可以获取任务执行完成的返回结果； ExecutorService中所有的submit()方法都将返回一个Future，从而将Callable或Runnable提交给Executor，并得到一个Future来获得任务的执行结果或取消任务； 附录：测试代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import org.junit.Test;import org.junit.runner.RunWith;import org.junit.runners.BlockJUnit4ClassRunner;import java.util.concurrent.*;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 19:45 2017/4/10. */@RunWith(BlockJUnit4ClassRunner.class)public class Test1{ @Test public void test1() { Thread thread = new ExtendThread(\"Junlan Shuai\"); thread.start(); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } @Test public void test2() { Thread thread = new Thread(new ImplRunnable(\"Junlan Shuai\")); thread.start(); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } @Test public void test3() { ImplCallable implCallable = new ImplCallable(\"Junlan Shuai\"); ExecutorService es = Executors.newFixedThreadPool(3); Future future = es.submit(implCallable); try { System.out.println(future.get()); Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } }}","link":"/2017/05/26/java-creating-thread/"},{"title":"HashMap&HashTable&ConcurrentHashMap (jdk1.8)","text":"Java中常用Map数据结构介绍 HashMapHashMap基本属性及其默认值HashMap底部数据结构get()和put()方法resize()方法resize()方法主要包括两个核心过程： 在第一次调用put()函数时时对数组进行初始化 在size &gt; threshold时进行扩容 分别讲一下这两个过程，在第一次初始化的时候，如果指定了初始容量 treeifyBin()方法tableSizeFor()方法红黑树TreeNode在HashMap中的实现HashMap在jdk1.7和jdk1.8中的区别HashMap在并发环境下存在的安全问题 HashMap在并发下可能出现的问题分析 常见hash算法原理hash冲突解决办法开放地址法、链地址法、再哈希法 References 【java集合】HashMap常见面试题 HashTable基本属性及其默认值get()和put()方法rehash()方法ConcurrentHashMapget()方法没有加锁，如何能保证线程安全 为什么ConcurrentHashMap的读操作不需要加锁？ get 操作的高效之处在于整个 get 过程不需要加锁，除非读到的值是空的才会加锁重读，我们知道 HashTable 容器的 get 方法是需要加锁的，那么 ConcurrentHashMap 的 get 操作是如何做到不加锁的呢？原因是它的 get 方法里将要使用的共享变量都定义成 volatile，如用于统计当前 Segement 大小的 count 字段和用于存储值的 HashEntry 的 value。定义成 volatile 的变量，能够在线程之间保持可见性，能够被多线程同时读，并且保证不会读到过期的值，但是只能被单线程写（有一种情况可以被多线程写，就是写入的值不依赖于原值），在 get 操作里只需要读不需要写共享变量 count 和 value，所以可以不用加锁。之所以不会读到过期的值，是根据 java 内存模型的 happen before 原则，对 volatile 字段的写入操作先于读操作，即使两个线程同时修改和获取 volatile 变量，get 操作也能拿到最新的值，这是用 volatile 替换锁的经典应用场景。 12transient volatile int count;volatile V value; 如何保证多线程环境下对数组修改的可见性123456789101112static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) { return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);}static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) { return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);}static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) { U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);} 如何保证数组元素的可见性 jdk1.7和jdk1.8中实现有什么区别 jdk7中ConcurrentHashMap源码 HashMap&amp;HashTable&amp;Concurrent对比分析 HashMap HashTable ConcurrentHashMap 默认DEFAULT_CAPACITY 16 11 16 默认loadFactors 0.75f 0.75f 0.75f 安全性 不安全 使用synchronize同步 线程安全，采用分段锁 扩容 newCap = oldCap &lt;&lt; 1 int newCapacity = (oldCapacity &lt;&lt; 1) + 1; ？？ hash算法 int hash = (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);int index = (tab.length - 1) &amp; hash int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length; int h = key.hashCode()int hash = (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;int index = (tab.length - 1) &amp; hash; 是否支持NULL key和value都能为null key和value都不能为null key和value都不能为null ConcurrentHashMap JAVA面试题05-ConcurrentHashMap的实现 扩展关于红黑树算法的原理如何防止恶意碰撞（hash）","link":"/2019/02/27/java-hashmap-hashtable-concurrenthashmap/"},{"title":"Java NIO核心组件：Selector","text":"REFERENCEShttp://ifeve.com/selectors/","link":"/2019/01/22/java-nio-selector/"},{"title":"Guide to the Java Phaser","text":"Java 7中新增了一个灵活的线程同步栅栏—Phaser，如果你需要在执行某些任务之前等待其他任务执行到某个状态，那么Phaser是一个很好的选择，这篇文章将介绍java.util.concurrent.Phaser，它和CountDownLatch具有相似的功能，但是Phaser更灵活。 基本术语在理解Phaser类的运行机制之前，我们先来了解Phaser类中的一些基本术语： Registration 开篇我们讲过，Phaser比CountDownLatch和CyclicBarrier更灵活，因为它可以通过register()和bulkRegister(int parties)来动态调整注册任务的数量，任务也可以通过执行arriveAndDeregister()来注销任务，Phaser允许的最大任务注册数量为65535。 Arrival 正如Phaser类的名字所暗示，每个Phaser实例都会维护一个phase number，初始值为0。每当所有注册的任务都到达Phaser时，phase number累加，并在超过Integer.MAX_VALUE后清零。arrive()和arriveAndDeregister()方法用于记录到 达，arriveAndAwaitAdvance()方法用于记录到达，并且等待其它未到达的任务。 Termination Phaser支持终止。Phaser终止之后，调用register()和bulkRegister(int parties)方法没有任何效果，arriveAndAwaitAdvance()方法也会立即返回。触发终止的时机是在protected boolean onAdvance(int phase, int registeredParties)方法返回时，如果该方法返回true，那么Phaser会被终止，默认实现是在注册任务数为0时返回true（即 return registeredParties == 0;），我们也可以通过重写这个方法来自定义的终止逻辑。此外，forceTermination()方法用于强制终止，isTerminated()方法用于判断是否已经终止。 Tiering Phaser支持层次结构，即通过构造函数Phaser(Phaser parent)和Phaser(Phaser parent, int parties)构造一个树形结构。这有助于减轻因在单个的Phaser上注册过多的任务而导致的竞争，从而提升吞吐量，代价是增加单个操作的开销。 核心API Phaser(int parties)，构造方法，与CountDownLatch一样，传入同步的线程数，也支持层次构造Phaser(Phaser parent)。 register()，bulkRegister(int Parties)，动态添加一个或多个参与者。 arriveAndDeregister()方法，动态撤销线程在phaser的注册，通知phaser对象，该线程已经结束该阶段且不参与后面阶段。 isTerminated()，当phaser没有参与同步的线程时（或者onAdvance返回true），phaser是终止态（如果phaser进入终止态arriveAndAwaitAdvance()和awaitAdvance()都会立即返回，不在等待）isTerminated返回true。 arrive()方法，通知phaser该线程已经完成该阶段，但不等待其他线程。 arriveAndAwaitAdvance()方法，类似await()方法，记录到达线程数，阻塞等待其他线程到达同步点后再继续执行。 awaitAdvance(int phase) /awaitAdvanceInterruptibly(int phase) 传入阶段数，只有当前阶段等于phase阶段时才阻塞等待。后者如果线程在休眠被中断会抛出InterruptedException异常（phaser的其他方法对中断都不会抛出异常）。 onAdvance(int phase, int registeredParties)方法。参数phase是阶段数，每经过一个阶段该数加1，registeredParties是当注册的线程数。此方法有2个作用：1、当每一个阶段执行完毕，此方法会被自动调用，因此，重载此方法写入的代码会在每个阶段执行完毕时执行，相当于CyclicBarrier的barrierAction。2、当此方法返回true时，意味着Phaser被终止，因此可以巧妙的设置此方法的返回值来终止所有线程。例如：若此方法返回值为 phase &gt;= 3，其含义为当整个线程执行了3个阶段后，程序终止。 forceTermination()方法，强制phaser进入终止态。 简单示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @author Shuai Junlan[shuaijunlan@gmail.com]. * @since Created in 2:26 PM 11/7/18. */public class PhaserTest { public static void main(String[] args) throws InterruptedException { final Phaser phaser = new Phaser(1); for (int index = 1; index &lt;= 10; index++){ phaser.register(); new Thread( new Player(phaser), \"Player\" + index).start(); } System.out.println(\"Game start\"); phaser.arriveAndDeregister(); while (!phaser.isTerminated()){ Thread.sleep(100); } System.out.println(\"Game over\"); }}class Player implements Runnable{ private final Phaser phaser; Player(Phaser phaser){ this.phaser = phaser; } @Override public void run() { //First step, waiting for all threads be created phaser.arriveAndAwaitAdvance(); try { //Second step, waiting for all players be ready Thread.sleep( new Random().nextInt(100) * 10L); System.out.println( Thread.currentThread().getName() + \" ready\"); phaser.arriveAndAwaitAdvance(); /////////////////running//////////////////// //Third step, waiting for all players arrived, then competition finishing. System.out.println( Thread.currentThread().getName() + \" arrived\"); phaser.arriveAndDeregister(); } catch (InterruptedException e) { e.printStackTrace(); } }} 输出结果： 12345678910111213141516171819202122Game startPlayer10 readyPlayer4 readyPlayer9 readyPlayer1 readyPlayer7 readyPlayer6 readyPlayer8 readyPlayer5 readyPlayer2 readyPlayer3 readyPlayer3 arrivedPlayer5 arrivedPlayer6 arrivedPlayer1 arrivedPlayer4 arrivedPlayer7 arrivedPlayer8 arrivedPlayer9 arrivedPlayer10 arrivedPlayer2 arrivedGame over","link":"/2018/11/08/java-phaser/"},{"title":"java中“...”的含义","text":"问题来源 在阅读spring源码时发现问题： 123456789/** * Create a new ClassPathXmlApplicationContext, loading the definitions * from the given XML files and automatically refreshing the context. * @param configLocations array of resource locations * @throws BeansException if context creation failed */public ClassPathXmlApplicationContext(String... configLocations) throws BeansException { this(configLocations, true, null);} 简介 是jdk1.5新增加特性，Java语言对方法参数支持一种新写法，叫可变长度参数列表，其语法就是类型后跟…，表示此处接受的参数为0到多个Object类型的对象，或者是一个Object[]。 测试 com.sh.test 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.sh.test;/** * Created by Mr SJL on 2016/11/19. * * @author Junlan Shuai */public class Test1{ public static void main(String[] args) { // 创建string对象数组，调用测试函数 String[] colors = new String[]{\"green\", \"blue\", \"red\"}; t1(colors); t2(colors); // 创建string实例，并调用测试函数 String color = \"black\"; t1(color);// t2(color); // 此处报错 java.lang.String[] can not be applied java.lang.String } /** * 测试函数1 * @param colors String...类型 */ public static void t1(String... colors) { for (String c : colors) { System.out.println(c); } } /** * 测试函数2 * @param colors String[]类型 */ public static void t2(String[] colors) { for (String c : colors) { System.out.println(c); } }} 注意事项 Error:(38, 24) java: 无法在com.sh.test.Test1中同时声明t1(java.lang.String[])和t1(java.lang.String…) 12345678910111213141516171819202122/** * 测试函数1 * @param colors String...类型 */public static void t1(String... colors){ for (String c : colors) { System.out.println(c); }}/** * 测试函数2 * @param colors String[]类型 */public static void t1(String[] colors){ for (String c : colors) { System.out.println(c); }}","link":"/2016/06/26/java-three-point/"},{"title":"Java TreeMap源码分析","text":"前言 A Red-Black tree based {@link NavigableMap} implementation. The map is sorted according to the {@linkplain Comparable natural ordering} of its keys, or by a {@link Comparator} provided at map creation time, depending on which constructor is used. This implementation provides guaranteed log(n) time cost for the {@code containsKey}, {@code get}, {@code put} and {@code remove} operations. Algorithms are adaptations of those in Cormen, Leiserson, and Rivest’s Introduction to Algorithms. 上面是一段关于TreeMap的官方Javadoc描述，简单来说就是，TreeMap底层是基于红黑树，保持了key的大小有序性，因此查找等操作的时间复杂度为O(logn)； 在这篇文章中我主要分析Java中是如何利用红黑树实现TreeMap的，关于红黑树的详细原理介绍可以参考这篇文章《教你透彻了解红黑树》。 put方法 Associates the specified value with the specified key in this map. If the map previously contained a mapping for the key, the old value is replaced. put函数如果存在相同的key，则会替换原来的旧值； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public V put(K key, V value) { Entry&lt;K,V&gt; t = root; if (t == null) { //插入第一个元素 compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); //设置root size = 1; modCount++; return null; } int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; //通过构造函数传入了比较器，则使用传入的比较器 if (cpr != null) { do { parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); //如果存在相同的key，则直接替换旧值 } while (t != null); } else { //否则使用Comparable（key得继承这个类） if (key == null) throw new NullPointerException(); @SuppressWarnings(\"unchecked\") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do { parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); //如果存在相同的key，则直接替换旧值 } while (t != null); } Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e); //进行红黑树变换 size++; modCount++; return null;} put函数其实也比较好理解，跟平衡二叉树的逻辑差不多，难点在于进行红黑树变化； get()方法 Returns the value to which the specified key is mapped, or {@code null} if this map contains no mapping for the key. 12345678910111213141516171819202122232425public V get(Object key) { Entry&lt;K,V&gt; p = getEntry(key); return (p==null ? null : p.value); //如果key不存在则返回null}final Entry&lt;K,V&gt; getEntry(Object key) { // Offload comparator-based version for sake of performance if (comparator != null) return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings(\"unchecked\") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; while (p != null) { int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; } return null;} 迭代遍历看一个Java代码： 1234567891011121314151617/** * @author Shuai Junlan[shuaijunlan@gmail.com]. * @since Created in 1:41 PM 1/18/19. */public class TreeMapTest { public static void main(String[] args) { TreeMap&lt;Integer, String&gt; treeMap = new TreeMap&lt;&gt;(); treeMap.put(5, \"green\"); treeMap.put(1, \"red\"); treeMap.put(3, \"yellow\"); treeMap.put(4, \"white\"); treeMap.put(2, \"black\"); for (Map.Entry&lt;Integer, String&gt; entry : treeMap.entrySet()) { System.out.println(entry.getKey() + \": \" + entry.getValue()); } }} 这个迭代遍历过程是一个有序的遍历，通过getFirstEntry()方法获取最小的子节点，每次调用next()方法时，它会调用successor(Entry&lt;K,V&gt; t)方法来获取下一个节点： 12345678910111213141516171819202122/** * Returns the successor of the specified Entry, or null if no such. *///该方法主要实现获取当前节点的下一个节点static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) { if (t == null) return null; else if (t.right != null) { Entry&lt;K,V&gt; p = t.right; while (p.left != null) p = p.left; return p; } else { Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; while (p != null &amp;&amp; ch == p.right) { ch = p; p = p.parent; } return p; }} 实现逻辑如下： 有右子树的节点，节点的下一个节点，肯定在右子树中，而右子树中“最左”的那个节点则是右子树中最小的一个，那么当然是右子树的“最左节点”，就好像下图所示： 无右子树的节点，先找到这个节点所在的左子树(右图)，那么这个节点所在的左子树的父节点(绿色节点)，就是下一个节点，如下图所示： REFERENCE Java TreeMap工作原理及实现","link":"/2019/01/18/java-treemap/"},{"title":"【LeetCode】Single Number题解","text":"Single Number I 原题链接：https://leetcode.com/problems/single-number/ 这个题目的大意就是，在一个数组中只有一个数字出现一次，其他数字都出现了两次； 这题的解题思路比较简单，我们知道如果两个相同的数异或运算之后结果为0，也就是n^n=0，借助这个思路，我们就可以遍历数组，对每个数都进行一次异或运算，最后得到的结果就是那个出现一次的数字，看一下代码： 123456789101112public class Solution { public int singleNumber(int[] nums){ if (nums == null){ return 0; } int sum = 0; for (int i = 0; i &lt; nums.length; i++){ sum ^= nums[i]; } return sum; }} 时间复杂度：O(n) 空间复杂度：O(1) Single Number II 原题链接：https://leetcode.com/problems/single-number-ii/ 这题的大意就是，一个数组中只有一个数字出现一次，其他数组出现三次，这题是上一题的加强版，依然可以采用位运算的思路；因为这是一个int数组（long数组同理），我们可以算出每一位1出现的次数，然后对3取余，最后相加得到的结果就是出现一次的那个数字： 12345678910111213141516public class Solution { public int singleNumber(int[] nums) { if (nums == null){ return 0; } int res = 0; for (int i = 0; i &lt; 32; i++){ int sum = 0; for (int j = 0; j &lt; nums.length; j++){ sum += (nums[j] &gt;&gt; i) &amp; 1; } res += ((sum % 3) &lt;&lt; i); } return res; }} 时间复杂度：O(n) 空间复杂度：O(1) References LeetCode] Single Number II 单独的数字之二 Single Number III 原题链接：https://leetcode.com/problems/single-number-iii/ 题目大意：已知一个数组，其中有两个数字在这个数组中只出现一次，其他数字都出现了两次，找出这两个只出现一次的数字，可以通过创建一个HashSet，然后遍历数组，如果HashSet中存在该数字，则从HashSet中删除该数字，最后HashSet会剩下两个数字，这两个数字就是只出现一次的数字： 12345678910111213141516171819public class Solution { public int[] singleNumber(int[] nums) { if (nums == null){ return null; } HashSet&lt;Integer&gt; hashSet = new HashSet&lt;&gt;(nums.length); for (int num : nums) { if (!hashSet.add(num)) { hashSet.remove(num); } } int[] re = new int[2]; int i = 0; for (Integer integer : hashSet) { re[i++] = integer; } return re; }} 时间复杂度：O(n) 空间复杂度：O(n)","link":"/2019/02/27/leetcode-single-number/"},{"title":"配置KVM虚拟机网络的两种方式（Bridge模式和NAT模式）","text":"Bridge原理(桥接模式) Bridge方式即虚拟网桥的网络连接方式，使客户机和子网里面的机器能够互相通信。可以使虚拟机成为网络中具有独立IP的主机。桥接网络（也叫物理设备共享）被用作把一个物理设备复制到一台虚拟机。网桥多用作高级设置，特别是主机多个网络接口的情况。 在bridged模式下，虚拟出来的操作系统就像是局域网中的一台独立的主机，它可以访问网内任何一台机器。同时，由于这个虚拟系统是局域网中的一个独立的主机系统，那么就可以手工配置它的TCP/IP配置信息，以实现通过局域网的网关或路由器访问互联网。使用bridged模式的虚拟系统和宿主机器的关系，就像连接在同一个Hub上的两台电脑。想让它们相互通讯，你就需要为虚拟系统配置IP地址和子网掩码，否则就无法通信（参考dhcp服务器是否开启，如果开启，则可以选择dhcp方式自动获取网络地址）。这种方式最简单，直接将虚拟网卡桥接到一个物理网卡上面，和linux下一个网卡绑定两个不同地址类似，实际上是将网卡设置为混杂模式，从而达到侦听多个IP的能力。在此种模式下，虚拟机内部的网卡（例如linux下的eth0)直接连到了物理网卡所在的网络上，可以想象为虚拟机和host机处于对等的地位，在网络关系上是平等的，没有谁在谁后面的问题。使用这种方式很简单，前提是你可以得到1个以上的地址。 如上图，网桥的基本原理就是创建一个桥接接口br0，在物理网卡和虚拟网络接口之间传递数据。 基本步骤 安装完CentOS7.0， 在/etc/sysconfig/network-scripts/目录下面会生成两个默认网络配置文件。（如图） 继续看文件里面的详细信息。 ifcfg-eth0 ifcfg-lo 配置静态IP 在相同目录下面添加一个ifcfg-br0文件，并在文件中添加如下内容 并且修改ifcfg-eth0文件 配置动态IP 在相同目录下面添加一个ifcfg-br0文件，并在文件中添加如下内容12345DEVICE=br0TYPE=BridgeNM_CONTROLLED=noBOOTPROTO=dhcpONBOOT=yes 并且修改ifcfg-eth0文件 申明 NAT原理(网络地址转换模式) 使用NAT模式，就是让虚拟系统借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。也就是说，使用NAT模式可以实现在虚拟系统里访问互联网。很显然，如果你只有一个外网地址，此种方式很合适。 virsh net-list 查看当前活跃的网络，可以看到一个default网络，这个就是一个默认的Nat网络了。 virsh net-dumpxml default 查看网络配置 持续更新中…… REFERENCES libvirt kvm 虚拟机上网 – Bridge桥接","link":"/2016/11/16/libvirt-kvm/"},{"title":"Liunx中Direct IO机制","text":"什么是Buffered I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。缓存 I/O 有以下这些优点： 缓存 I/O 使用了操作系统内核缓冲区，在一定程度上分离了应用程序空间和实际的物理设备。 缓存 I/O 可以减少读盘的次数，从而提高性能。 当应用程序尝试读取某块数据的时候，如果这块数据已经存放在了页缓存中，那么这块数据就可以立即返回给应用程序，而不需要经过实际的物理读盘操作。当然，如果数据在应用程序读取之前并未被存放在页缓存中，那么就需要先将数据从磁盘读到页缓存中去。对于写操作来说，应用程序也会将数据先写到页缓存中去，数据是否被立即写到磁盘上去取决于应用程序所采用的写操作机制：如果用户采用的是同步写机制（ synchronous writes ）, 那么数据会立即被写回到磁盘上，应用程序会一直等到数据被写完为止；如果用户采用的是延迟写机制（ deferred writes ），那么应用程序就完全不需要等到数据全部被写回到磁盘，数据只要被写到页缓存中去就可以了。在延迟写机制的情况下，操作系统会定期地将放在页缓存中的数据刷到磁盘上。与异步写机制（ asynchronous writes ）不同的是，延迟写机制在数据完全写到磁盘上的时候不会通知应用程序，而异步写机制在数据完全写到磁盘上的时候是会返回给应用程序的。所以延迟写机制本身是存在数据丢失的风险的，而异步写机制则不会有这方面的担心。 缓存I/O的特点在缓存 I/O 机制中，DMA 方式可以将数据直接从磁盘读到页缓存中，或者将数据从页缓存直接写回到磁盘上，而不能直接在应用程序地址空间和磁盘之间进行数据传输，这样的话，数据在传输过程中需要在应用程序地址空间和页缓存之间进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 对于某些特殊的应用程序来说，避开操作系统内核缓冲区而直接在应用程序地址空间和磁盘之间传输数据会比使用操作系统内核缓冲区获取更好的性能，下边这一小节中提到的自缓存应用程序就是其中的一种。 自缓存应用程序（ self-caching applications）对于某些应用程序来说，它会有它自己的数据缓存机制，比如，它会将数据缓存在应用程序地址空间，这类应用程序完全不需要使用操作系统内核中的高速缓冲存储器，这类应用程序就被称作是自缓存应用程序（ self-caching applications ）。数据库管理系统是这类应用程序的一个代表。自缓存应用程序倾向于使用数据的逻辑表达方式，而非物理表达方式；当系统内存较低的时候，自缓存应用程序会让这种数据的逻辑缓存被换出，而并非是磁盘上实际的数据被换出。自缓存应用程序对要操作的数据的语义了如指掌，所以它可以采用更加高效的缓存替换算法。自缓存应用程序有可能会在多台主机之间共享一块内存，那么自缓存应用程序就需要提供一种能够有效地将用户地址空间的缓存数据置为无效的机制，从而确保应用程序地址空间缓存数据的一致性。 对于自缓存应用程序来说，缓存 I/O 明显不是一个好的选择。由此引出我们这篇文章着重要介绍的 Linux 中的直接 I/O 技术。Linux 中的直接 I/O 技术非常适用于自缓存这类应用程序，该技术省略掉缓存 I/O 技术中操作系统内核缓冲区的使用，数据直接在应用程序地址空间和磁盘之间进行传输，从而使得自缓存应用程序可以省略掉复杂的系统级别的缓存结构，而执行程序自己定义的数据读写管理，从而降低系统级别的管理对应用程序访问数据的影响。在下面一节中，我们会着重介绍 Linux 中提供的直接 I/O 机制的设计与实现，该机制为自缓存应用程序提供了很好的支持。 Linux中的Direct I/O技术所有的I/O操作都是通过读文件或者写文件来完成的。在这里，我们把所有的外围设备，包括键盘和显示器都看成是文件系统中的文件。Linux中提供的访问文件的方式多种多样，下面将列出Linux中支持的文件访问方式。 标准访问文件的方式 同步访问文件的方式 内存映射方式 直接I/O的方式 异步访问文件的方式","link":"/2018/12/15/linux-direct-io/"},{"title":"log4j初级配置教程","text":"先来看个采用log4j输出日志的例子 添加依赖包 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt;&lt;/dependency&gt; 添加配置文件log4j.properties放在/resources目录下面 123456789101112131415161718192021222324252627### 设置###log4j.rootLogger = DEBUG,error,debug,stdout#log4j.rootLogger = INFO,stdout### 输出信息到控制台 ###log4j.appender.stdout = org.apache.log4j.ConsoleAppender#log4j.appender.stdout.Threshold = ERRORlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = [%-5p] %d{yyyy-MM-dd HH:mm:ss,SSS} method:%l%n%m%n### 输出DEBUG 级别以上的日志到=E://logs/debug.log ###log4j.appender.debug = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.debug.File = E://logs/debug.loglog4j.appender.debug.Append = true##Threshold是个全局的过滤器，它将把低于所设置的level的信息过滤不显示出来。log4j.appender.debug.Threshold = DEBUGlog4j.appender.debug.layout = org.apache.log4j.PatternLayoutlog4j.appender.debug.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n### 输出ERROR 级别以上的日志到=E://logs/error.log ###log4j.appender.error = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.error.File =E://logs/error.loglog4j.appender.error.Append = truelog4j.appender.error.Threshold = ERRORlog4j.appender.error.layout = org.apache.log4j.PatternLayoutlog4j.appender.error.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n java代码 1234567891011121314151617181920212223package com.sh.test;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * Created by Mr SJL on 2016/11/26. * * @Author Junlan Shuai */public class App{ public static void main(String[] args) { // 记录debug级别的信息 log.debug(\"This is debug message.\"); // 记录info级别的信息 log.info(\"This is info message.\"); // 记录error级别的信息 log.error(\"This is error message.\"); }} 控制台输出结果 log4j主要组件 Log4j有三个主要的组件：Loggers(记录器)，Appenders (输出源)和Layouts(布局)。这里可简单理解为日志类别，日志要输出的地方和日志以何种形式输出。综合使用这三个组件可以轻松地记录信息的类型和级别，并可以在运行时控制日志输出的样式和位置。 Loggers Loggers组件在此系统中被分为五个级别：DEBUG、INFO、WARN、ERROR和FATAL。这五个级别是有顺序的，DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，分别用来指定这条日志信息的重要程度，明白这一点很重要，Log4j有一个规则：只输出级别不低于设定级别的日志信息，假设Loggers级别设定为INFO，则INFO、WARN、ERROR和FATAL级别的日志信息都会输出，而级别比INFO低的DEBUG则不会输出。 Appenders 禁用和使用日志请求只是Log4j的基本功能，Log4j日志系统还提供许多强大的功能，比如允许把日志输出到不同的地方，如控制台（Console）、文件（Files）等，可以根据天数或者文件大小产生新的文件，可以以流的形式发送到其它地方等等。 常使用的类如下： org.apache.log4j.ConsoleAppender（控制台） org.apache.log4j.FileAppender（文件） org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件） org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件） org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） Layouts 有时用户希望根据自己的喜好格式化自己的日志输出，Log4j可以在Appenders的后面附加Layouts来完成这个功能。 Layouts提供四种日志输出样式，如根据HTML样式、自由指定样式、包含日志级别与信息的样式和包含日志时间、线程、类别等信息的样式。 常使用的类如下： org.apache.log4j.HTMLLayout（以HTML表格形式布局） org.apache.log4j.PatternLayout（可以灵活地指定布局模式） org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串） org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等信息） log4j.properties配置文件详解 在实际应用中，要使Log4j在系统中运行须事先设定配置文件。配置文件事实上也就是对Logger、Appender及Layout进行相应设定。Log4j支持两种配置文件格式，一种是XML格式的文件，一种是properties属性文件。下面以properties属性文件为例介绍 log4j.properties的配置。 配置根Logger log4j.rootLogger = [ level ] , appenderName1, appenderName2, … log4j.additivity.org.apache=false：表示Logger不会在父Logger的appender里输出，默认为true。 level ：设定日志记录的最低级别，可设的值有OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者自定义的级别，Log4j建议只使用中间四个级别。通过在这里设定级别，您可以控制应用程序中相应级别的日志信息的开关，比如在这里设定了INFO级别，则应用程序中所有DEBUG级别的日志信息将不会被打印出来。 appenderName：就是指定日志信息要输出到哪里。可以同时指定多个输出目的地，用逗号隔开。 例如：log4j.rootLogger＝INFO,A1,B2,C3 配置控制台输出 1234567### 输出信息到控制台 ###log4j.appender.stdout = org.apache.log4j.ConsoleAppender### 输出ERROR级别以上的日志到控制台 ###log4j.appender.stdout.Threshold = ERRORlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = [%-5p] %d{yyyy-MM-dd HH:mm:ss,SSS} method:%l%n%m%n 配置日志文件输出 12345678### 输出DEBUG 级别以上的日志到=E://logs/debug.log ###log4j.appender.debug = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.debug.File = E://logs/debug.loglog4j.appender.debug.Append = true##Threshold是个全局的过滤器，它将把低于所设置的level的信息过滤不显示出来。log4j.appender.debug.Threshold = DEBUGlog4j.appender.debug.layout = org.apache.log4j.PatternLayoutlog4j.appender.debug.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n REFERENCES Log4j.properties配置详解 最详细的Log4j使用教程","link":"/2017/04/26/log4j-tutorial/"},{"title":"Netty数据容器---ByteBuf","text":"ByteBuf工作原理ByteBuf维护了两个不同的索引：一个用于读取，一个用于写入。当从ByteBuf读取数据时，它的readerINdex将会递增已被读取的字节数。同样的，当你写入ByteBuf的时候，它的writerIndex也会被递增。 上图中表示的是一个读索引和写索引都设置为0的16字节ByteBuf，若果试图访问超出writerIndex范围的数据将会触发一个IndexOutOfBoundsException异常。 ByteBuf的使用模式堆缓冲区最常用的ByteBuf模式是将数据存储在JVM的堆空间中，这种模式被称为支撑数组（backing array），它能在没有使用池化的情况下提供快速的分配和释放。 直接缓冲区直接缓冲区是通过本地方法调用来分配堆外内存，这样可以避免在每次调用本地I/O操作之前（或者之后）将缓冲区的内容复制到一个中间缓冲区（或者从中间缓冲区把内容复制到缓冲区）。 直接缓冲区的主要缺点是：相对于基于堆的缓冲区，它们的分配和释放都较为昂贵。因为数据不在堆上，所以在操作数据之前不得不进行一次数据复制。 复合缓冲区复合缓冲区主要是为多个ByteBuf提供一个聚合视图，这是一个JDK的ByteBuffer实现完全缺失的特性。 操作ByteBuf字节","link":"/2018/07/24/netty-bytebuf-data-container/"},{"title":"Netty组件介绍","text":"下面将介绍Netty中所包含的各种组件，主要包括：Channel、EventLoop、ChannelFuture、ChannelHandler和ChannelPipeline等。 Channel、EventLoop和ChannelFuture 一个EventLoopGroup可以包含一个或者多个EventLoop； 一个EventLoop在它的生命周期内只和一个Thread绑定； 所有由EventLoop处理的I/O事件都将在它专有的Thread上被处理； 一个Channel在它的生命周期内只能注册于一个EventLoop； 一个EventLoop可能被分配给多个Channel； 在Netty中所有的I/O操作都是异步的，因此可以通过ChannelFuture来获取响应结果； ChannelHandler和ChannelPipeline ChannelPipeline提供了ChannelHandler链的容器，并定义了同于在该链上传播入站的出站的事件流的API； 一个ChannelIninializer的实现被注册到ServerBootstrap中或这Client的BootStrap中； 当 ChannelInitializer.initChannel() 方法被调用时，ChannelInitializer将在 ChannelPipeline 中安装一组自定义的 ChannelHandler ； ChannelInitializer将它自己从 ChannelPipeline 中移除； 从一个客户端应用程序角度来看，当事件的运动方向是从客户端到服务器，我们称之为出站，反之则称之为入站； 数据出站运动，数据讲从ChannelOutboundHandler链的尾端开始流动，直到它到达链的头部为止，此时数据到达了网络传输层，通常情况下会触发一个写操作。 BootStrap和ServerBootstrap 类别 Bootstrap ServerBootstrap 网络编程中的作用 连接到远程主机和端口 绑定到一个本地端口 EventLoopGroup的数目 1 2（也可以1个） 上图中，客户端创建了一个EventLoopGroup，服务器端使用了两个EventLoopGroup，其中一个EventLoopGroup用来接收客户端发来的请求，另一个EventLoop用来处理连接任务。 示例服务器端 12345678910111213141516171819202122EventLoopGroup bossGroup = new EpollEventLoopGroup(1);EventLoopGroup workerGroup = new EpollEventLoopGroup(4);try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(EpollServerSocketChannel.class) //保持长连接状态 .childOption(ChannelOption.SO_KEEPALIVE, true) .childOption(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new HttpSnoopServerInitializer()); ChannelFuture ch = b.bind(PORT).sync(); if (ch.isSuccess()){ logger.info(\"Http server start on port :{}\", PORT ); } ch.channel().closeFuture().sync();} finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully();} 客户端 123456789EventLoopGroup eventLoopGroup = new EpollEventLoopGroup(8);Bootstrap bootstrap = new Bootstrap() .group(eventLoopGroup) .option(ChannelOption.SO_KEEPALIVE, true) .option(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .channel(EpollSocketChannel.class) .handler(new RpcClientInitializer());Channel channel = bootstrap.connect(\"127.0.0.1\", port).sync().channel();","link":"/2018/07/20/netty-components-design/"},{"title":"Netty中Future与Promise的实现分析","text":"从Java 1.5开始，JDK就提供了Callable和Future，通过它们可以在任务异步执行完毕之后获取任务的执行结果。 Netty扩展了JDK中的Future机制，下面我们来看一张Netty中Future和Promise类关系图： 最上面的Future是JDK提供的Future接口，我们看一下里面有哪些方法： 123456789101112131415161718192021222324252627282930package java.util.concurrent;/** * A {@code Future} represents the result of an asynchronous * computation. Methods are provided to check if the computation is * complete, to wait for its completion, and to retrieve the result of * the computation. The result can only be retrieved using method * {@code get} when the computation has completed, blocking if * necessary until it is ready. Cancellation is performed by the * {@code cancel} method. Additional methods are provided to * determine if the task completed normally or was cancelled. Once a * computation has completed, the computation cannot be cancelled. * If you would like to use a {@code Future} for the sake * of cancellability but not provide a usable result, you can * declare types of the form {@code Future&lt;?&gt;} and * return {@code null} as a result of the underlying task. */public interface Future&lt;V&gt; { //尝试取消执行的任务 boolean cancel(boolean mayInterruptIfRunning); //判断任务是否取消 boolean isCancelled(); //判断任务是否执行完成 boolean isDone(); //等待直到任务执行完成，并且返回结果 V get() throws InterruptedException, ExecutionException; //等待最大超时时间，如果执行完成则返回结果，否则抛出超时异常 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} 并发编程中，我们通常会用到一组非阻塞的模型：Promise，Future 和 Callback。其中的 Future 表示一个可能还没有实际完成的异步任务的结果，针对这个结果可以添加 Callback 以便在任务执行成功或失败后做出对应的操作，而Promise交由任务执行者，任务执行者通过 Promise 可以标记任务完成或者失败。 这一套模型是很多异步非阻塞架构的基础。 因为netty中也有类似调用者和执行部件以异步的方式交互通信结果的需求（要知道eventloop本质上是一个ScheduledExecutorService，ExecutorService是一种“提交-执行”模型实现，也存在线程间异步方式通信和线程安全问题），所以netty自己实现了一套。 Netty中所有的IO操作都是异步的（比如write(Object)，因为Netty中一个EventLoop要服务于多个SocketChannel，所以通过socketChannel.xx只是提交一个任务，何时返回结果是不确定的），而不像传统的BIO那样阻塞等待操作完成，来获取执行结果。 事实上，Netty Future的建议操作模式就是赤裸裸的通知，执行部件改变状态时，会执行注册在future上的Listener（变相的观察者模式）。 scala在语言层面提供对Promise，Future和Callback模型的支持，https://bitbucket.org/qiyi/commons-future.git作者自定义实现了该模型，去除了Netty的Future模型对EventLoop的依赖。 Netty中的Future下面的Netty Future继承jdk提供的Future接口，添加了一些自己的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * The result of an asynchronous operation. */@SuppressWarnings(\"ClassNameSameAsAncestorName\")public interface Future&lt;V&gt; extends java.util.concurrent.Future&lt;V&gt; { boolean isSuccess(); boolean isCancellable(); Throwable cause(); Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); Future&lt;V&gt; sync() throws InterruptedException; Future&lt;V&gt; syncUninterruptibly(); Future&lt;V&gt; await() throws InterruptedException; Future&lt;V&gt; awaitUninterruptibly(); boolean await(long timeout, TimeUnit unit) throws InterruptedException; boolean await(long timeoutMillis) throws InterruptedException; boolean awaitUninterruptibly(long timeout, TimeUnit unit); boolean awaitUninterruptibly(long timeoutMillis); V getNow(); @Override boolean cancel(boolean mayInterruptIfRunning);} a future is a read-only placeholder view of a variable, while a promise is a writable。Promise是可写的Future，提供写操作相关的接口，用于设置IO操作的结果。Future，Promise，callback抽象出一套调用者与执行部件间的通信模型（不只是netty中），Future像是给调用者用的（拿结果），Promise像是给执行部件用的（设置结果），它们简化了调用者和执行部件对其的调用（调用者get，执行部件set），但本身要封装很多事。比如Future必须是一个线程安全的类（大部分时候，调用者和执行部件身处两个线程），比如执行callback（或者listener）。 Netty Promise执行ListenerNetty中的Promise通常由EventLoop创建，也就是Promise通常会绑定executor。为何呢？因为Netty保证Listener的执行，一定是在channel对应的EventLoop中(????)。","link":"/2018/09/06/netty-future-and-promise/"},{"title":"Netty 入门","text":"Netty is a NIO client server framework which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server. 特征 不同的传输类型（blocking and non-blocking socket ）使用统一的API 拥有灵活的易扩展的事件模型 高低自定义的线程模型-single thread, one or more thread pools such as SEDA 高吞吐量，低时延 更少的资源占用 最小化不必要的内存拷贝 完全支持SSL/TLS和StartTLS 入门示例添加依赖123456&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.23.Final&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; Server端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.serialization.ClassResolvers;import io.netty.handler.codec.serialization.ObjectDecoder;import io.netty.handler.codec.serialization.ObjectEncoder;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 13:44 2018/5/11. */public class NettyServer { public void start(Integer port) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(4); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup).channel(NioServerSocketChannel.class) .localAddress(port) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline() .addLast(new ObjectDecoder(1024*1024, ClassResolvers.weakCachingConcurrentResolver(this.getClass().getClassLoader())) ) .addLast(new ObjectEncoder()) .addLast(new SimpleChannelInboundHandler&lt;Object&gt;() { @Override protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"Receive message:\" + msg); ctx.writeAndFlush(\"Hello \" + msg); } }); } }); ChannelFuture channelFuture = bootstrap.bind().sync(); channelFuture.channel().closeFuture().sync(); bossGroup.shutdownGracefully().sync(); workGroup.shutdownGracefully().sync(); } public static void main(String[] args) { try { NettyServer server = new NettyServer(); server.start(20000); } catch (InterruptedException e) { e.printStackTrace(); } }} Client端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import io.netty.bootstrap.Bootstrap;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.serialization.ClassResolvers;import io.netty.handler.codec.serialization.ObjectDecoder;import io.netty.handler.codec.serialization.ObjectEncoder;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 13:53 2018/5/11. */public class NettyClient { public Channel channel; public void start(String host, Integer port) throws InterruptedException { EventLoopGroup workGroup = new NioEventLoopGroup(4); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(workGroup) .channel(NioSocketChannel.class) .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { // Using Java Object serializable, you can also use other serializable frameworks like thrift, Protobuf and so on. ch.pipeline() .addLast(new ObjectDecoder(1024*1024, ClassResolvers.weakCachingConcurrentResolver(this.getClass().getClassLoader())) ) .addLast(new ObjectEncoder()) .addLast(new SimpleChannelInboundHandler&lt;Object&gt;() { @Override protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"Receive msg: \" + msg); } }); } }); // Connect to the server sync channel = bootstrap.connect(host, port).sync().channel(); } public static void main(String[] args) { try { NettyClient nettyClient = new NettyClient(); nettyClient.start(\"127.0.0.1\", 20000); if (nettyClient.channel != null &amp;&amp; nettyClient.channel.isActive()){ System.out.println(\"Send message to server\"); nettyClient.channel.writeAndFlush(\"Junlan\"); } } catch (InterruptedException e) { e.printStackTrace(); } }}","link":"/2018/05/10/netty-introduction/"},{"title":"netty-object-pool","text":"","link":"/2019/06/04/netty-object-pool/"},{"title":"Netty服务端接收连接过程分析","text":"前面《Netty服务端启动流程分析》这篇文章主要介绍了Netty服务端的启动过程，那么这里有个问题：启动服务端之后，有新的连接向服务端发起请求，服务端是如何接收并处理这些连接请求的？带着这个问题我将结合netty源码分析Netty服务端接收连接的过程。 这篇文章我将主要讲解一下几个部分： 1、netty如何接收新的请求 2、netty如何给新的请求分配reactor线程 3、netty如何给每个新连接天剑ChannelHandler 检测到有新连接进入我们已经知道，当服务端绑启动之后，服务端的channel已经注册到boos reactor线程中，reactor不断检测有新的事件，直到检测出有accept事件发生； NioEventLoop.java 1234567private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) { final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); int readyOps = k.readyOps(); if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { unsafe.read(); }} 上面这段代码是reactor线程三部曲中的第二部曲，表示boos reactor线程已经轮询到 SelectionKey.OP_ACCEPT 事件，说明有新的连接进入，此时将调用channel的 unsafe来进行实际的操作 关于 unsafe，这篇文章我不打算细讲，下面是netty作者对于unsafe的解释 Unsafe operations that should never be called from user-code. These methods are only provided to implement the actual transport. 你只需要了解一个大概的概念，就是所有的channel底层都会有一个与unsafe绑定，每种类型的channel实际的操作都由unsafe来实现 而从上一篇文章，服务端的启动过程中，我们已经知道，服务端对应的channel的unsafe是 NioMessageUnsafe，那么，我们进入到它的read方法，进入新连接处理的第二步 注册到worker reactor线程NioMessageUnsafe.java 1234567891011121314151617181920212223private final List&lt;Object&gt; readBuf = new ArrayList&lt;Object&gt;();public void read() { assert eventLoop().inEventLoop(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); do { int localRead = doReadMessages(readBuf); if (localRead == 0) { break; } if (localRead &lt; 0) { closed = true; break; } } while (allocHandle.continueReading()); int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) { pipeline.fireChannelRead(readBuf.get(i)); } readBuf.clear(); pipeline.fireChannelReadComplete();} 我省去了非关键部分的代码，可以看到，一上来，就用一条断言确定该read方法必须是reactor线程调用，然后拿到channel对应的pipeline和 RecvByteBufAllocator.Handle(先不解释) 接下来，调用 doReadMessages 方法不断地读取消息，用 readBuf 作为容器，这里，其实可以猜到读取的是一个个连接，然后调用 pipeline.fireChannelRead()，将每条新连接经过一层服务端channel的洗礼 之后清理容器，触发 pipeline.fireChannelReadComplete()，整个过程清晰明了，不含一丝杂质，下面我们具体看下这两个方法： 1.doReadMessages(List) 2.pipeline.fireChannelRead(NioSocketChannel) doReadMessages(List)123456789101112131415161718192021@Overrideprotected int doReadMessages(List&lt;Object&gt; buf) throws Exception { SocketChannel ch = SocketUtils.accept(javaChannel()); try { if (ch != null) { buf.add(new NioSocketChannel(this, ch)); return 1; } } catch (Throwable t) { logger.warn(\"Failed to create a new channel from an accepted socket.\", t); try { ch.close(); } catch (Throwable t2) { logger.warn(\"Failed to close a socket.\", t2); } } return 0;} 这段代码应该很熟悉，通过调用jdk底层nio的方法SocketUtils.accept(javaChannel());，由于netty中reactor线程第一步就扫描到有accept事件发生，因此，这里的accept方法是立即返回的，返回jdk底层nio创建的一条channel。 netty将jdk的 SocketChannel 封装成自定义的 NioSocketChannel，加入到list里面，这样外层就可以遍历该list，做后续处理； 关于NioSocketChannel的创建过程可以参考《Netty客户端连接过程源码分析》，在创建出一条NioSocketChannel之后，放置在List容器里，就开始进行下一步操作 pipeline.fireChannelRead(NioSocketChannel)关于pipline的介绍可以看另一篇文章《》，通过《Netty服务端启动流程分析》这篇文章我们知道，在服务端处理新连接的pipeline中，已经自动添加了一个pipeline处理器 ServerBootstrapAcceptor, 并已经将用户代码中设置的一系列的参数传入了构造函数，接下来，我们就来看下ServerBootstrapAcceptor； ServerBootstrapAcceptor.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private static class ServerBootstrapAcceptor extends ChannelInboundHandlerAdapter { private final EventLoopGroup childGroup; private final ChannelHandler childHandler; private final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] childOptions; private final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] childAttrs; private final Runnable enableAutoReadTask; ServerBootstrapAcceptor( final Channel channel, EventLoopGroup childGroup, ChannelHandler childHandler, Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] childOptions, Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] childAttrs) { this.childGroup = childGroup; this.childHandler = childHandler; this.childOptions = childOptions; this.childAttrs = childAttrs; // Task which is scheduled to re-enable auto-read. // It's important to create this Runnable before we try to submit it as otherwise the URLClassLoader may // not be able to load the class because of the file limit it already reached. // // See https://github.com/netty/netty/issues/1328 enableAutoReadTask = new Runnable() { @Override public void run() { channel.config().setAutoRead(true); } }; } @Override @SuppressWarnings(\"unchecked\") public void channelRead(ChannelHandlerContext ctx, Object msg) { final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: childAttrs) { child.attr((AttributeKey&lt;Object&gt;) e.getKey()).set(e.getValue()); } try { childGroup.register(child).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { forceClose(child, future.cause()); } } }); } catch (Throwable t) { forceClose(child, t); } }} 前面的 pipeline.fireChannelRead(NioSocketChannel); 最终通过head-&gt;unsafe-&gt;ServerBootstrapAcceptor的调用链，调用到这里的 ServerBootstrapAcceptor 的channelRead方法 注册读事件Referenceshttps://blog.csdn.net/u013160932/article/details/80474486 netty源码分析之新连接接入全解析","link":"/2019/02/18/netty-server-side-accept-connections/"},{"title":"Netty线程模型分析","text":"","link":"/2018/06/26/netty-thread-model/"},{"title":"Netty内置传输方式","text":"Netty中内置的传输方式主要包括：NIO、Epoll、OIO、Local和Embedded等方式，总结如下： 名称 包名 描述 NIO io.netty.channel.socket.io 使用java.nio.channels包作为基础，基于选择器的方式 Epoll io.netty.channel.epoll 由JNI驱动的epoll()和非阻塞IO，这种传输只有Linux才支持，比NIO传输速度更快，而且是完全非阻塞的 OIO io.netty.channel.socket.oio 使用java.net包作为基础 Local io.netty.channel.local 可以在VM内部通过管道进行通信的本地传输 Embedded io.netty.channel.socket.embedded Embedded 传输，允许使用 ChannelHandler 而又不需要一个真正的基于网络的传输，测试ChannelHandler实现的时候非常有用 基于NIO的传输 Epoll—基于Linux的本地非阻塞传输在Linux内核版2.5.44之后就引入了epoll，提供了比旧的POSIX select和poll系统调用更好的性能。如何应用程序运行在Linux系统智商，则可以利用基于Epoll的方式传输，只需要在代码中将NioEventLoopGroup替换为EpollEventLoopGroup，并且将NioServerSocketChannel.class替换为EpollServerSocketChannel.class。或者用如下方式判断系统是否支持Epoll： 1234567891011121314151617181920212223EventLoopGroup workGroup = Epoll.isAvailable() ? new EpollEventLoopGroup(4) : new NioEventLoopGroup(4);Bootstrap bootstrap = new Bootstrap();bootstrap.group(workGroup) .channel(Epoll.isAvailable() ? EpollSocketChannel.class : NioSocketChannel.class) .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { // Using Java Object serializable, you can also use other serializable frameworks like thrift, Protobuf and so on. ch.pipeline() .addLast(new ObjectDecoder(1024*1024, ClassResolvers.weakCachingConcurrentResolver(this.getClass().getClassLoader())) ) .addLast(new ObjectEncoder()) .addLast(new SimpleChannelInboundHandler&lt;Object&gt;() { @Override protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"Receive msg: \" + msg); } }); } });// Connect to the server syncchannel = bootstrap.connect(host, port).sync().channel(); OIO—阻塞I/O","link":"/2018/07/22/netty-transport-methods/"},{"title":"netty-writeAndFlush","text":"","link":"/2019/03/01/netty-writeAndFlush/"},{"title":"基于Spring Cloud搭建微服务架构完整示例","text":"ddd","link":"/2018/07/25/spring-cloud-microservice-demo/"},{"title":"algorithm-kmp","text":"","link":"/2019/09/09/algorithm-kmp/"},{"title":"MySQL索引结构中的B+树","text":"1. B树1. B树的定义B树也称B-树,它是一颗多路平衡查找树。我们描述一颗B树时需要指定它的阶数，阶数表示了一个结点最多有多少个孩子结点，一般用字母m表示阶数。当m取2时，就是我们常见的二叉搜索树。 一颗m阶的B树定义如下： 1）每个结点最多有m-1个关键字。 2）根结点最少可以只有1个关键字。 3）非根结点至少有Math.ceil(m/2)-1个关键字。 4）每个结点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。 5）所有叶子结点都位于同一层，或者说根结点到每个叶子结点的长度都相同。 上图是一颗阶数为4的B树。在实际应用中的B树的阶数m都非常大（通常大于100），所以即使存储大量的数据，B树的高度仍然比较小。每个结点中存储了关键字（key）和关键字对应的数据（data），以及孩子结点的指针。我们将一个key和其对应的data称为一个记录。但为了方便描述，除非特别说明，后续文中就用key来代替（key, value）键值对这个整体。在数据库中我们将B树（和B+树）作为索引结构，可以加快查询速速，此时B树中的key就表示键，而data表示了这个键对应的条目在硬盘上的逻辑地址。 2.B+树2.1 B+树的定义 各种资料上B+树的定义各有不同，一种定义方式是关键字个数和孩子结点个数相同。这里我们采取维基百科上所定义的方式，即关键字个数比孩子结点个数小1，这种方式是和B树基本等价的。上图就是一颗阶数为4的B+树。 除此之外B+树还有以下的要求。 1）B+树包含2种类型的结点：内部结点（也称索引结点）和叶子结点。根结点本身即可以是内部结点，也可以是叶子结点。根结点的关键字个数最少可以只有1个。 2）B+树与B树最大的不同是内部结点不保存数据，只用于索引，所有数据（或者说记录）都保存在叶子结点中。 3） m阶B+树表示了内部结点最多有m-1个关键字（或者说内部结点最多有m个子树），阶数m同时限制了叶子结点最多存储m-1个记录。 4）内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。 5）每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。 Reference MYSQL-B+TREE索引原理 B树和B+树的插入、删除图文详解","link":"/2019/07/15/mysql-b-tree/"},{"title":"Java编程如何高效利用CPU缓存？","text":"首先我们来看一个Java的例子: 12345678910111213141516171819202122232425262728/** * @author Shuai Junlan[shuaijunlan@gmail.com]. * @since Created in 1:43 PM 1/17/19. */public class ArrayTraverse { private static long[][] arrs = new long[1024*1024][8]; public static void main(String[] args) { long temp = 0; long start = System.currentTimeMillis(); // Vertical traverse for (int i = 0; i &lt; 8; i ++){ for (int j = 0; j &lt; 1024 * 1024; j++){ temp = arrs[j][i]; } } System.out.println(\"Vertical traverse spending time: \" + (System.currentTimeMillis() - start) + \"ms\"); start = System.currentTimeMillis(); // Horizontal traverse for (int i = 0; i &lt; 1024 * 1024; i++){ for (int j = 0; j &lt; 8; j++){ temp = arrs[i][j]; } } System.out.println(\"Horizontal traverse spending time: \" + (System.currentTimeMillis() - start) + \"ms\"); }} 上述代码中定义了一个二维数组，分别从横向遍历和纵向遍历了；两个方面来计算耗时，相信通过上面的代码大家也都能知道两种遍历方式耗时差距很大，结果确实是这样的： 12Vertical traverse spending time: 75msHorizontal traverse spending time: 13ms 看上面的输出结果，耗时差距确实很大，但是为什么会有这个大的差距呢？显然跟我们这篇文章的题目有关，那就是横向遍历充分利用了CPU高速缓存机制，使得遍历速度要快于纵向遍历，那么…… 什么是CPU缓存 在计算机系统中，CPU高速缓存（英语：CPU Cache，在本文中简称缓存）是用于减少处理器访问内存所需平均时间的部件。在金字塔式存储体系中它位于自顶向下的第二层，仅次于CPU寄存器。其容量远小于内存，但速度却可以接近处理器的频率。 当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在（命中），则不经访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器。 缓存之所以有效，主要是因为程序运行时对内存的访问呈现局部性（Locality）特征。这种局部性既包括空间局部性（Spatial Locality），也包括时间局部性（Temporal Locality）。有效利用这种局部性，缓存可以达到极高的命中率。 在处理器看来，缓存是一个透明部件。因此，程序员通常无法直接干预对缓存的操作。但是，确实可以根据缓存的特点对程序代码实施特定优化，从而更好地利用缓存。—From 维基百科【CPU缓存】 现在主流的多核CPU缓存架构采用了三级缓存模式，如下图： 每个core共享L3 Cache，为什么要设计三级缓存可以参考这么文章《[译] 为什么 CPU 有多层缓存》，下面我们来详细说说，缓存与RAM如何进行数据交换的，数据传输的基本单位是什么？。 Cache Line（缓存行）缓存行 (Cache Line) 便是 CPU Cache 中的最小单位，CPU Cache 由若干缓存行组成，一个缓存行的大小通常是 64 字节（这取决于 CPU），并且它有效地引用主内存中的一块地址。一个 Java 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。 试想一下你正在遍历一个长度为 16 的 long 数组 data[16]，原始数据自然存在于主内存中，访问过程描述如下 访问 data[0]，CPU core 尝试访问 CPU Cache，未命中。 尝试访问主内存，操作系统一次访问的单位是一个 Cache Line 的大小 — 64 字节，这意味着：既从主内存中获取到了 data[0] 的值，同时将 data[0] ~ data[7] 加入到了 CPU Cache 之中，for free~ 访问 data[1]~data[7]，CPU core 尝试访问 CPU Cache，命中直接返回。 访问 data[8]，CPU core 尝试访问 CPU Cache，未命中。 尝试访问主内存。重复步骤 2 CPU 缓存在顺序访问连续内存数据时挥发出了最大的优势。再回到文章的开头例子，为何横向遍历 arrs[1024 * 1024][8] 要比纵向遍历更快？此处得到了解答，正是更加友好地利用 CPU Cache 带来的优势，甚至有一个专门的词来修饰这种行为 —Mechanical Sympathy。 上面我们已经提到了，在多核CPU缓存架构中，缓存在多个线程共享某个缓存行的情况，这样就会导致False Sharing（伪共享）问题，下面我将详细介绍什么是False Sharing，以及为什么会产生False Sharing？ False Sharing（伪共享）如果两个或多个处理器正在向同一缓存行的不同部分中写入数据，那么很多缓存和总线通信可能会导致其他处理器上的旧行的每个缓存副本失效或进行更新。这称为 “伪共享” 或者也称为 “CPU 缓存行干扰”。和两个或多个线程共享同一数据（因此需要程序化的同步机制来确保按顺序访问）的真正共享不同，当两个或多个线程访问位于同一缓存行上的无关数据时，就会产生伪共享。 关于具体的伪共享是如何产生的可以参考这篇文章《CPU cache结构和缓存一致性（MESI协议）》和《伪共享（false sharing），并发编程无声的性能杀手》。 Java中是如何避免伪共享的呢？Java6 中实现字节填充1234public class PaddingObject{ public volatile long value = 0L; // 实际数据 public long p1, p2, p3, p4, p5, p6; // 填充} PaddingObject 类中需要保存一个 long 类型的 value 值，如果多线程操作同一个 CacheLine 中的 PaddingObject 对象，便无法完全发挥出 CPU Cache 的优势（想象一下你定义了一个 PaddingObject[] 数组，数组元素在内存中连续，却由于伪共享导致无法使用 CPU Cache 带来的沮丧）。 不知道你注意到没有，实际数据 value + 用于填充的 p1~p6 总共只占据了 7 * 8 = 56 个字节，而 Cache Line 的大小应当是 64 字节，这是有意而为之，在 Java 中，对象头还占据了 8 个字节，所以一个 PaddingObject 对象可以恰好占据一个 Cache Line。 Java7 中实现字节填充在 Java7 之后，一个 JVM 的优化给字节填充造成了一些影响，上面的代码片段 public long p1, p2, p3, p4, p5, p6; 会被认为是无效代码被优化掉，又回归到了伪共享的窘境之中。 为了避免 JVM 的自动优化，需要使用继承的方式来填充。 1234567abstract class AbstractPaddingObject{ protected long p1, p2, p3, p4, p5, p6;// 填充}public class PaddingObject extends AbstractPaddingObject{ public volatile long value = 0L; // 实际数据} Java8中实现字节填充Java8 中终于提供了字节填充的官方实现，这无疑使得 CPU Cache 更加可控了，无需担心 jdk 的无效字段优化，无需担心 Cache Line 在不同 CPU 下的大小究竟是不是 64 字节。使用 @Contended 注解可以完美的避免伪共享问题。 12345@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.FIELD, ElementType.TYPE})public @interface Contended { String value() default \"\";} 更多关于避免伪共享的一些Java实践可以参考《CPU Cache 与缓存行》。 最后在这篇文章我们主要介绍了CPU高速缓存架构，多核CPU带来的伪共享问题以及Java实战中是如何利用CPU缓存来提高性能。 在这里，我想到了一问题，在软件系统架构中经常会用到缓存，那么是如何设计这个缓存的？跟CPU缓存架构有什么异同点？也请各位知道的在下方评论区中留言。 REFERENCE 多核多处理器架构软件设计的注意事项 CPU Cache 与缓存行 细说Cache-L1/L2/L3/TLB","link":"/2019/01/17/cpu-cache/"},{"title":"Dubbo服务端接收请求及响应请求原理分析","text":"之前一篇文章《Dubbo服务提供者发布及注册过程源码分析》已经介绍了Dubbo服务端的服务注册及发布过程，这篇文章将会介绍Dubbo服务端是如何接受请求以及响应请求的。 本文还是以Consumer-Provider的Demo为例，分析接收请求及响应请求的具体流程，在Dubbo服务端发布服务之后，它将会监听一个端口等待接收客户端的请求，当接收到请求后，会经过入站处理器进行处理，我们知道在发布服务的时候设置了NettyServerHandler入站处理器，接收到请求之后，会经过NettyServerHandler#channelRead()方法来获取请求的消息，我们来看一下它的实现： 12345678910@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //以ctx.channel()为key，以NettyChannel为value，存储在ConcurrentHashMap中 NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try { handler.received(channel, msg); } finally { NettyChannel.removeChannelIfDisconnected(ctx.channel()); }} 下面先来看一张整个接收请求和处理请求的流程图，下面将会围绕这张图进行详细的分析： ) 来看一下HeaderExchangeHandler#received()方法： 123456789101112131415161718192021222324252627282930313233343536@Overridepublic void received(Channel channel, Object message) throws RemotingException { channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); final ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try { if (message instanceof Request) {//如果是你Request类型的消息 // handle request. Request request = (Request) message; if (request.isEvent()) {//事件类型的消息 handlerEvent(channel, request); } else { if (request.isTwoWay()) {//请求，需返回：第一种情况，使用handleRequest()处理 handleRequest(exchangeChannel, request); } else {//请求，不需返回：第二种情况，处理请求不需要响应 handler.received(exchangeChannel, request.getData()); } } } else if (message instanceof Response) {//如果是Response类型的消息：第三种情况 handleResponse(channel, (Response) message); } else if (message instanceof String) {//如果是String类型的消息 if (isClientSide(channel)) { Exception e = new Exception(\"Dubbo client can not supported string message: \" + message + \" in channel: \" + channel + \", url: \" + channel.getUrl()); logger.error(e.getMessage(), e); } else {//响应回显请求 String echo = handler.telnet(channel, (String) message); if (echo != null &amp;&amp; echo.length() &gt; 0) { channel.send(echo); } } } else {//其他情况 handler.received(exchangeChannel, message); } } finally { HeaderExchangeChannel.removeChannelIfDisconnected(channel); }} 下面我们来分析request-response的模式，也是就分析handleRequest()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657void handleRequest(final ExchangeChannel channel, Request req) throws RemotingException { //创建一个Response对象 Response res = new Response(req.getId(), req.getVersion()); //isBroken？是什么意思？，待进一步探究 if (req.isBroken()) { Object data = req.getData(); String msg; if (data == null) msg = null; else if (data instanceof Throwable) msg = StringUtils.toString((Throwable) data); else msg = data.toString(); res.setErrorMessage(\"Fail to decode request due to: \" + msg); res.setStatus(Response.BAD_REQUEST); channel.send(res); return; } // find handler by message class. Object msg = req.getData(); try { // handle data. //异步处理请求，使用CompletableFuture接收结果 //handler实例是在DubboProtocol类中通过匿名内部类实例化传递进来的，可以查看DubboProtocol的77行代码 CompletableFuture&lt;Object&gt; future = handler.reply(channel, msg); //执行完成，获取结果 if (future.isDone()) { res.setStatus(Response.OK); res.setResult(future.get()); //返回结果 channel.send(res); return; } //基于通知机制，获取结果 future.whenComplete((result, t) -&gt; { try { if (t == null) { res.setStatus(Response.OK); res.setResult(result); } else { res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(t)); } //返回结果 channel.send(res); } catch (RemotingException e) { logger.warn(\"Send result to consumer failed, channel is \" + channel + \", msg is \" + e); } finally { // HeaderExchangeChannel.removeChannelIfDisconnected(channel); } }); } catch (Throwable e) { //处理异常，返回结果 res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(e)); channel.send(res); }} 继续看DubboProtocol类中匿名内部类ExchangeHandlerAdapter#reply()方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Overridepublic CompletableFuture&lt;Object&gt; reply(ExchangeChannel channel, Object message) throws RemotingException { if (message instanceof Invocation) { Invocation inv = (Invocation) message; //获取调用者 Invoker&lt;?&gt; invoker = getInvoker(channel, inv); // need to consider backward-compatibility if it's a callback if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE))) { String methodsStr = invoker.getUrl().getParameters().get(\"methods\"); boolean hasMethod = false; if (methodsStr == null || !methodsStr.contains(\",\")) { hasMethod = inv.getMethodName().equals(methodsStr); } else { String[] methods = methodsStr.split(\",\"); for (String method : methods) { if (inv.getMethodName().equals(method)) { hasMethod = true; break; } } } if (!hasMethod) { logger.warn(new IllegalStateException(\"The methodName \" + inv.getMethodName() + \" not found in callback service interface ,invoke will be ignored.\" + \" please update the api interface. url is:\" + invoker.getUrl()) + \" ,invocation is :\" + inv); return null; } } //获取调用的上下文，底层使用ThreadLocal实现 RpcContext rpcContext = RpcContext.getContext(); boolean supportServerAsync = invoker.getUrl().getMethodParameter(inv.getMethodName(), Constants.ASYNC_KEY, false); if (supportServerAsync) { CompletableFuture&lt;Object&gt; future = new CompletableFuture&lt;&gt;(); rpcContext.setAsyncContext(new AsyncContextImpl(future)); } rpcContext.setRemoteAddress(channel.getRemoteAddress()); //发起调用 Result result = invoker.invoke(inv); if (result instanceof AsyncRpcResult) { return ((AsyncRpcResult) result).getResultFuture().thenApply(r -&gt; (Object) r); } else { return CompletableFuture.completedFuture(result); } } throw new RemotingException(channel, \"Unsupported request: \" + (message == null ? null : (message.getClass().getName() + \": \" + message)) + \", channel: consumer: \" + channel.getRemoteAddress() + \" --&gt; provider: \" + channel.getLocalAddress());} 最后获取结果执行channel.send()方法，向服务消费方返回数据 调用栈： 123456789101112&quot;DubboServerHandler-211.69.197.55:20881-thread-2@3215&quot; daemon prio=5 tid=0x1a nid=NA runnable java.lang.Thread.State: RUNNABLE at org.apache.dubbo.remoting.transport.netty4.NettyChannel.send(NettyChannel.java:101) at org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.send(HeaderExchangeChannel.java:89) at org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.send(HeaderExchangeChannel.java:78) at org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:103) at org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:196) at org.apache.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:51) at org.apache.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:57) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)","link":"/2018/09/24/dubbo-provider-request-and-response-analysis/"},{"title":"Java中Memory Mapped File原理分析","text":"在传统的文件读写方式中，会有两次数据拷贝，一次是从硬盘拷贝到操作系统内核，另一次是从操作系统内核拷贝到用户态的应用程序。而在内存映射文件中，一般情况下，只有一次拷贝，且内存分配在操作系统内核，应用程序访问的就是操作系统的内核内存空间，这显然要比普通的读写效率更高。 内存映射文件的另一个重要特点是，它可以被多个不同的应用程序共享，多个程序可以映射同一个文件，映射到同一块内存区域，一个程序对内存的修改，可以让其他程序也看到，这使得它特别适合用于不同应用程序之间的通信。比普通的基于loopback接口的Socket要快10倍。那么在Java语言中是如何实现Memory Mapped File的呢？ 在Java nio包中引入了MappedByteBuffer来实现Memory Mapped File，从继承结构上来看MappedByteBuffer继承自ByteBuffer，内部维护了一个逻辑地址address。 下面写个简单的示例来演示如何使用FileChannel和MappedByteBuffer： 12345678910111213141516171819/** * @author Shuai Junlan[shuaijunlan@gmail.com]. * @since Created in 3:03 PM 12/8/18. */public class MmapTest { public static void main(String[] args) throws IOException { File file = new File(\"test.txt\"); assert file.exists() || file.createNewFile(); FileChannel channel = new RandomAccessFile(file, \"rw\").getChannel(); MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 1000); for (int i = 0; i &lt; 1000; i++){ mappedByteBuffer.put((byte)i); } mappedByteBuffer.position(0); for (int i = 0; i &lt; 1000; i++){ System.out.println(mappedByteBuffer.get()); } }} 在上面的代码中可以看到，FileChannel通过调用map方法把文件映射到了虚拟内存，在Java中规定的最大映射大小为Integer.MAX_VALUE，如果文件太大可以进行分段映射，我们来分析一下map方法中各个参数的含义： mode:内存映射文件访问的方式，包括以下三种： 1.MapMode.READ_ONLY：只读，试图修改得到的缓冲区将导致抛出异常。 2.MapMode.READ_WRITE：读/写，对得到的缓冲区的更改最终将写入文件；但该更改对映射到同一文件的其他程序不一定是可见的。 3.MapMode.PRIVATE：私用，可读可写,但是修改的内容不会写入文件，只是buffer自身的改变，这种能力称之为copy on write。 position:被映射文件的其实位置； size:映射区域的大小，单位为byte，最大映射大小为Integer.MAX_VALUE； 进一步分析map过程的内部实现原理：第一步，通过RandomAccessFile获取FileChannel：12345678public final FileChannel getChannel() { synchronized (this) { if (channel == null) { channel = FileChannelImpl.open(fd, path, true, rw, this); } return channel; }} 该方法中使用了同步关键字，保证了多线程情况下只能初始化一个FileChannel实例。 第二步，使用FileChannel的map方法，把文件映射到用户虚拟内存空间，并返回逻辑地址1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192 public MappedByteBuffer map(MapMode mode, long position, long size) throws IOException {//省略参数检查 long addr = -1; int ti = -1; try { begin(); ti = threads.add(); if (!isOpen()) return null; long mapSize; int pagePosition; //加锁，保证线程安全 synchronized (positionLock) { long filesize; do { filesize = nd.size(fd); } while ((filesize == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); if (!isOpen()) return null; //如果映射范围超出文件的大小且不可写，则抛出异常 if (filesize &lt; position + size) { // Extend file size if (!writable) { throw new IOException(\"Channel not open for writing \" + \"- cannot extend file to required size\"); } int rv; //填充文件 do { rv = nd.allocate(fd, position + size); } while ((rv == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); if (!isOpen()) return null; } pagePosition = (int)(position % allocationGranularity); long mapPosition = position - pagePosition; mapSize = size + pagePosition; try { // If map0 did not throw an exception, the address is valid addr = map0(imode, mapPosition, mapSize); } catch (OutOfMemoryError x) { // An OutOfMemoryError may indicate that we've exhausted // memory so force gc and re-attempt map System.gc(); try { Thread.sleep(100); } catch (InterruptedException y) { Thread.currentThread().interrupt(); } try { addr = map0(imode, mapPosition, mapSize); } catch (OutOfMemoryError y) { // After a second OOME, fail throw new IOException(\"Map failed\", y); } } } // synchronized // On Windows, and potentially other platforms, we need an open // file descriptor for some mapping operations. FileDescriptor mfd; try { mfd = nd.duplicateForMapping(fd); } catch (IOException ioe) { unmap0(addr, mapSize); throw ioe; } assert (IOStatus.checkAll(addr)); assert (addr % allocationGranularity == 0); int isize = (int)size; Unmapper um = new Unmapper(addr, mapSize, isize, mfd); if ((!writable) || (imode == MAP_RO)) { return Util.newMappedByteBufferR(isize, addr + pagePosition, mfd, um); } else { return Util.newMappedByteBuffer(isize, addr + pagePosition, mfd, um); } } finally { threads.remove(ti); end(IOStatus.checkAll(addr)); } } map方法最终是通过调用native函数map0()完成文件映射： 1.如果第一次文件映射导致OOM，则手动处罚垃圾回收，休眠100ms后再尝试映射，如果失败则抛出异常； 2.通过newMappedByteBuffer（ReadWrite）或者newMappedByteBufferR（Read Only）方法初始化MappedByteBuffer实例，最终返回DirectByteBuffer的实例，该类是MappedByteBuffer的子类； 123456789101112131415161718192021222324252627282930313233343536373839404142static MappedByteBuffer newMappedByteBuffer(int size, long addr, FileDescriptor fd, Runnable unmapper){ MappedByteBuffer dbb; if (directByteBufferConstructor == null) initDBBConstructor(); try { dbb = (MappedByteBuffer)directByteBufferConstructor.newInstance( new Object[] { new Integer(size), new Long(addr), fd, unmapper }); } catch (InstantiationException | IllegalAccessException | InvocationTargetException e) { throw new InternalError(e); } return dbb;}private static void initDBBRConstructor() { AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { try { Class&lt;?&gt; cl = Class.forName(\"java.nio.DirectByteBufferR\"); Constructor&lt;?&gt; ctor = cl.getDeclaredConstructor( new Class&lt;?&gt;[] { int.class, long.class, FileDescriptor.class, Runnable.class }); ctor.setAccessible(true); directByteBufferRConstructor = ctor; } catch (ClassNotFoundException | NoSuchMethodException | IllegalArgumentException | ClassCastException x) { throw new InternalError(x); } return null; }});} 由于FileChannelImpl和DirectByteBuffer不在同一个包中，并切DirectByteBuffer类是默认的访问权限，因此无法直接在FileChannelImpl的map函数中直接实例化DirectByteBuffer，通过Util.java类的newMappedByteBuffer()方法去实例化，在上面的代码中，实例化的核心逻辑就是通过AccessController获取DirectByteBuffer类的构造函数进行实例化。 关于本地方法map0()，在JDK源码中找到了他的具体实现，如下： 1234567891011121314151617181920212223242526272829303132333435363738Java_sun_nio_ch_FileChannelImpl_map0(JNIEnv *env, jobject this, jint prot, jlong off, jlong len){ void *mapAddress = 0; jobject fdo = (*env)-&gt;GetObjectField(env, this, chan_fd); jint fd = fdval(env, fdo); int protections = 0; int flags = 0; if (prot == sun_nio_ch_FileChannelImpl_MAP_RO) { protections = PROT_READ; flags = MAP_SHARED; } else if (prot == sun_nio_ch_FileChannelImpl_MAP_RW) { protections = PROT_WRITE | PROT_READ; flags = MAP_SHARED; } else if (prot == sun_nio_ch_FileChannelImpl_MAP_PV) { protections = PROT_WRITE | PROT_READ; flags = MAP_PRIVATE; } mapAddress = mmap64( 0, /* Let OS decide location */ len, /* Number of bytes to map */ protections, /* File permissions */ flags, /* Changes are shared */ fd, /* File descriptor of mapped file */ off); /* Offset into file */ if (mapAddress == MAP_FAILED) { if (errno == ENOMEM) { JNU_ThrowOutOfMemoryError(env, \"Map failed\"); return IOS_THROWN; } return handle(env, -1, \"Map failed\"); } return ((jlong) (unsigned long) mapAddress);} get和put方法调用get和put方法对数据进行读写，最终其实是调用DirectByteBuffer类的get和put方法， 1234567public byte get() { return ((unsafe.getByte(ix(nextGetIndex()))));}public ByteBuffer put(byte x) { unsafe.putByte(ix(nextPutIndex()), ((x))); return this;} 通过上面的代码可以看出，底层都是通过调用Unsafe类的getByte和putByte方法来操作数据的。 第一次访问address所指向的内存区域，导致缺页中断，中断响应函数会在交换区中查找相对应的页面，如果找不到（也就是该文件从来没有被读入内存的情况），则从硬盘上将文件指定页读取到物理内存中（非jvm堆内存）。 如果在拷贝数据时，发现物理内存不够用，则会通过虚拟内存机制（swap）将暂时不用的物理页面交换到硬盘的虚拟内存中。 性能分析从代码层面上看，从硬盘上将文件读入内存，都要经过文件系统进行数据拷贝，并且数据拷贝操作是由文件系统和硬件驱动实现的，理论上来说，拷贝数据的效率是一样的。 但是通过内存映射的方法访问硬盘上的文件，效率要比read和write系统调用高，这是为什么？ read()是系统调用，首先将文件从硬盘拷贝到内核空间的一个缓冲区，再将这些数据拷贝到用户空间，实际上进行了两次数据拷贝； map()也是系统调用，但没有进行数据拷贝，当缺页中断发生时，直接将文件从硬盘拷贝到用户空间，只进行了一次数据拷贝。 所以，采用内存映射的读写效率要比传统的read/write性能高。 总结 MappedByteBuffer使用虚拟内存，因此分配(map)的内存大小不受JVM的-Xmx参数限制，但是也是有大小限制的。 如果当文件超出Integer.MAX_VALUE字节限制时，可以通过position参数重新map文件后面的内容。 MappedByteBuffer在处理大文件时的确性能很高，但也存在一些问题，如内存占用、文件关闭不确定，被其打开的文件只有在垃圾回收的才会被关闭，而且这个时间点是不确定的。 javadoc中也提到：A mapped byte buffer and the file mapping that it represents remain valid until the buffer itself is garbage-collected.","link":"/2018/12/08/java-memory-mapped-file/"},{"title":"深入理解Java SPI机制","text":"SPI的全名为Service Provider Interface，在java.util.ServiceLoader的文档:https://docs.oracle.com/javase/6/docs/api/java/util/ServiceLoader.html中有比较详细的介绍。究其思想，其实和Callback差不多。Callback的思想是我们在调用API的时候，我们可以写入一段逻辑代码传到API里面，API内部在合适的时候会调用它，从而实现某种程度上的“定制”。 典型的是Collections.sort(List&lt;T&gt; list,Comparator&lt;? super T&gt; c)这个方法，它的第二个参数是一个实现Comparator接口的实例。我们可以根据自己的排序规则写一个类，实现此接口，传入此方法，那么这个方法就会根据我们的规则对list进行排序。 Java SPI的具体约定如下当服务的提供者，提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。 基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。 JDK提供服务实现查找的一个工具类：java.util.ServiceLoader 实现一个Java SPI示例假设我们有一个日志服务ILogService，其只定义了一个warn方法用于输出日志信息，我们希望把它作为SPI，然后具体的实现由对应的服务提供者去实现。ILogService的定义如下: 123456789package cn.shuaijunlan.spi;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 7:13 PM 2018/08/04. */public interface ILogService { void warn(String msg);} 然后基于这个服务接口实现了两个类，分别是ConsoleLogServiceImpl、FileLogServiceImpl，代码如下： 123456789101112131415161718192021222324252627282930package cn.shuaijunlan.spi.impl;import cn.shuaijunlan.spi.ILogService;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 7:14 PM 2018/08/04. */public class ConsoleLogServiceImpl implements ILogService { @Override public void warn(String msg) { System.out.println(\"Console log:\"+ msg + \"!\"); }}=======================================================================================package cn.shuaijunlan.spi.impl;import cn.shuaijunlan.spi.ILogService;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 7:15 PM 2018/08/04. */public class FileLogServiceImpl implements ILogService { @Override public void warn(String msg) { System.out.println(\"File log:\" + msg +\"!\"); }} 根据SPI的规范我们的服务实现类必须有一个无参构造方法。我们的SPI服务提供者需要将其在classpath下的META-INF/services目录下以服务接口全路径名命名的文件中写对应的实现类的全路径名称，每一行代表一个实现，如果需要注释信息可以使用#进行注释，根据官方的要求，这个文件的编码格式必须是UTF-8。我们示例中的ILogService的全路径名是cn.shuaijunlan.spi.ILogService，所以我们需要在类路径下的META-INF/services目录下创建一个名称为cn.shuaijunlan.spi.ILogService文件。在本示例中我们一个提供了两个实现，所以该文件的内容如下： 1234# Console log &amp; File logcn.shuaijunlan.spi.impl.ConsoleLogServiceImplcn.shuaijunlan.spi.impl.FileLogServiceImpl ServiceLoader是实现了java.util.Iterator接口的，而且是基于我们所使用的服务的实现，所以可以通过ServiceLoader的实例来遍历其中的服务实现者，从而调用对应的服务提供者。测试函数如下： 12345678910111213141516171819package cn.shuaijunlan.spi;import java.util.Iterator;import java.util.ServiceLoader;/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 7:28 PM 2018/08/04. */public class Main { private static ServiceLoader&lt;ILogService&gt; services = ServiceLoader.load(ILogService.class); public static void main(String[] args) { Iterator&lt;ILogService&gt; iterator = services.iterator(); while (iterator.hasNext()){ iterator.next().warn(\"Hello SPI\"); } }} 控制台输出结果如下： 12Console log:Hello SPI!File log:Hello SPI! 基于SPI规范，我们最终实现了想要的结果。 ServiceLoader源码分析在调用ServiceLoader.load(ILogService.class);时，代码进入： 12345public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { //获取当前线程上下文类加载器 ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);} 执行之后，程序进入ServiceLoader.load(service, cl);方法 12345public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader){ return new ServiceLoader&lt;&gt;(service, loader);} 返回一个ServiceLoader的实例 在调用services.iterator();方法时，返回一个Iterator容器 123456789101112131415161718192021222324public Iterator&lt;S&gt; iterator() { return new Iterator&lt;S&gt;() { Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); //第一次执行hasNext方法时，knownProviders的size为0，会继续执行lookupIterator.hasNext()，最后进入到hasNextService方法中 public boolean hasNext() { if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); } public S next() { if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); } public void remove() { throw new UnsupportedOperationException(); } };} 我们来看hasNextService方法： 1234567891011121314151617181920212223242526private boolean hasNextService() { if (nextName != null) { return true; } if (configs == null) { try { //获取接口的全名 String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, \"Error locating configuration files\", x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } //获取所有实现类的全名，具体的解析函数查看parse函数 pending = parse(service, configs.nextElement()); } nextName = pending.next(); return true;} 当调用iterator.next()方法时，会进入到： 12345678910111213141516171819202122232425262728293031private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { //生成名称为cn的Class对象，不进行初始化 c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { //没找到类则会抛出异常 fail(service, \"Provider \" + cn + \" not found\"); } if (!service.isAssignableFrom(c)) { fail(service, \"Provider \" + cn + \" not a subtype\"); } try { //进行实例化 S p = service.cast(c.newInstance()); providers.put(cn, p); //返回实例 return p; } catch (Throwable x) { fail(service, \"Provider \" + cn + \" could not be instantiated\", x); } throw new Error(); // This cannot happen} 在上述分析中我们可以看到ServiceLoader不是一实例化以后立马就去读配置文件中的服务实现者，并且进行对应的实例化工作的，而是会等到需要通过其Iterator实现获取对应的服务提供者时才会加载对应的配置文件进行解析，具体来说是在调用Iterator的hasNext方法时会去加载配置文件进行解析，在调用next方法时会将对应的服务提供者进行实例化并进行缓存。所有的配置文件只加载一次，服务提供者也只实例化一次，如需要重新加载配置文件可调用ServiceLoader的reload方法。 框架案例1.common-logging apache最早提供的日志的门面接口。只有接口，没有实现。具体方案由各提供商实现，发现日志提供商是通过扫描 META-INF/services/org.apache.commons.logging.LogFactory配置文件，通过读取该文件的内容找到日志提供商实现类。只要我们的日志实现里包含了这个文件，并在文件里指定 LogFactory工厂接口的实现类即可。 2.jdbc jdbc4.0以前，开发人员还需要基于Class.forName(“xxx”)的方式来装载驱动，jdbc4也基于spi的机制来发现驱动提供商了，可以通过META-INF/services/java.sql.Driver文件里指定实现类的方式来暴露驱动提供者。 SPI不足之处 通过上面的解析，可以发现，我们使用SPI查找具体的实现的时候，需要遍历所有的实现，并实例化，然后我们在循环中才能找到我们需要实现。这应该也是最大的缺点，需要把所有的实现都实例化了，即便我们不需要，也都给实例化了。 获取某个实现类的方式不够灵活，只能通过Iterator的形式获取，不能根据某个参数来获取对应的实现类。 REFERENCES1.https://docs.oracle.com/javase/tutorial/sound/SPI-intro.html 2.https://cxis.me/2017/04/17/Java%E4%B8%ADSPI%E6%9C%BA%E5%88%B6%E6%B7%B1%E5%85%A5%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90","link":"/2018/08/03/java-spi-introduction/"},{"title":"Java线程池分析","text":"基于ThreadPoolExecutor构造线程池我们来看一下ThreadPoolExecutor类的构造函数，一共需要传入7个参数，下面的注释中有详细的解释： 12345678910111213141516171819202122232425262728293031public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { //先判断参数是否合法 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); //核心线程数量 this.corePoolSize = corePoolSize; //最大线程数量 this.maximumPoolSize = maximumPoolSize; //工作队列 this.workQueue = workQueue; //保活时间，unit为时间单位，转换为秒 this.keepAliveTime = unit.toNanos(keepAliveTime);、 //线程工厂 this.threadFactory = threadFactory; //拒绝策略 this.handler = handler;} 工作队列使用的是一种阻塞队列，关于阻塞队列的实现我将会在另一片文章中详细讲解。 提交任务提交任务的过程主要分为三步： 1234567891011121314151617181920212223242526272829303132333435/** Proceed in 3 steps:** 1. If fewer than corePoolSize threads are running, try to* start a new thread with the given command as its first* task. The call to addWorker atomically checks runState and* workerCount, and so prevents false alarms that would add* threads when it shouldn't, by returning false.** 2. If a task can be successfully queued, then we still need* to double-check whether we should have added a thread* (because existing ones died since last checking) or that* the pool shut down since entry into this method. So we* recheck state and if necessary roll back the enqueuing if* stopped, or start a new thread if there are none.** 3. If we cannot queue task, then we try to add a new* thread. If it fails, we know we are shut down or saturated* and so reject the task.*/int c = ctl.get();if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get();}if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false);}else if (!addWorker(command, false)) reject(command); 1.如果运行的线程数小于corePoolSize，则会调用addWorker()，检查runState和workerCount，并且创建一个新的线程，把任务给它当做第一个任务来执行，然后就返回。 2.如果任务成功的加入队列，然后我们仍然需要去再次检查是否我们应该添加一个thread（因为在之前一次检查之后可能会有thread终止），或者线程池停止了自从进入这个函数。因此我们需要重复检查状态，并且在线程池停止的情况下回滚入队操作，或者开启一个新的线程如果这没有线程。 3.如果任务不能加入队列（队列已满），则尝试创建一个新的线程（此时线程数量应该小于maximumPoolSize）。如果创建失败，我们知道可能是线程池停止或者线程数量达到了maximumPoolSize，因此会拒绝这个任务。 五种运行状态123456// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS; //接收新的任务并且处理队列中的任务private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; //不接受新的任务，但是会继续处理队列中的任务private static final int STOP = 1 &lt;&lt; COUNT_BITS; //不接受新的任务，也不处理队列中的任务，并且打断中正在处理的任务private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; //所有任务都终止，workerCount为零，线程状态过渡到TIDYING，将会执行terminated()方法private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; //terminated()函数执行完成 状态转换： 原始状态 目标状态 转变原因 RUNNING SHUTDOWN On invocation of shutdown(), perhaps implicitly in finalize() RUNNING or SHUTDOWN STOP On invocation of shutdownNow() SHUTDOWN TIDYING When both queue and pool are empty STOP TIDYING When pool is empty TIDYING TERMINATED When the terminated() hook method has completed 饱和策略分析当有界队列填满后，饱和策略开始发挥作用，所有饱和策略实现类都实现了RejectExecutionHandler接口，我们来看一下JDK提供了哪些饱和策略实现类： 从类的关系图中可以看出，JDK实现了DiscardPolicy、CallerRunsPolicy、DiscardOldestPolicy和AbortPolicy四种饱和策略，下面我们将会一一进行分析。 AbortPolicy1234567891011121314151617181920212223/** * A handler for rejected tasks that throws a * {@code RejectedExecutionException}. */public static class AbortPolicy implements RejectedExecutionHandler { /** * Creates an {@code AbortPolicy}. */ public AbortPolicy() { } /** * Always throws RejectedExecutionException. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task * @throws RejectedExecutionException always */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); }} 中止策略是默认的饱和策略，该则略将会抛出未检查的RejectedExecutionException，调用者可以捕获这个异常，然后根据需求编写自己的处理代码。 CallerRunsPolicy12345678910111213141516171819202122232425/** * A handler for rejected tasks that runs the rejected task * directly in the calling thread of the {@code execute} method, * unless the executor has been shut down, in which case the task * is discarded. */public static class CallerRunsPolicy implements RejectedExecutionHandler { /** * Creates a {@code CallerRunsPolicy}. */ public CallerRunsPolicy() { } /** * Executes task r in the caller's thread, unless the executor * has been shut down, in which case the task is discarded. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { r.run(); } }} 调用者运行策略实现了一种调节机制，该策略不抛弃任何任务，也不会抛出异常，而是将某些任务会退到调用者执行，从而降低新任务的流量。他不会在线程池中的某个线程中执行任务，而是在调用execute()方法的线程中执行该任务。 DiscardPolicy12345678910111213141516171819/** * A handler for rejected tasks that silently discards the * rejected task. */public static class DiscardPolicy implements RejectedExecutionHandler { /** * Creates a {@code DiscardPolicy}. */ public DiscardPolicy() { } /** * Does nothing, which has the effect of discarding task r. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { }} 抛弃策略，直接抛弃该提交的任务。 DiscardOldestPolicy123456789101112131415161718192021222324252627/** * A handler for rejected tasks that discards the oldest unhandled * request and then retries {@code execute}, unless the executor * is shut down, in which case the task is discarded. */public static class DiscardOldestPolicy implements RejectedExecutionHandler { /** * Creates a {@code DiscardOldestPolicy} for the given executor. */ public DiscardOldestPolicy() { } /** * Obtains and ignores the next task that the executor * would otherwise execute, if one is immediately available, * and then retries execution of task r, unless the executor * is shut down, in which case task r is instead discarded. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { e.getQueue().poll(); e.execute(r); } }} 抛弃最旧的策略，则会抛弃下一个将会执行的任务，然后尝试重新提交该任务。如果工作队列是一个优先级队列，那么该策略会导致抛弃优先级最高的任务，因此最好不要将优先级队列和DiscardOldestPolicy一起使用。 自定义线程工厂在ThreadPoolExecutor构造函数中可以看到，在构造线程池时，可以传入自定义的线程工厂，也可以使用默认的线程工厂。我们先来看一下默认的线程工厂的实现，它是Executors的静态内部类： 1234567891011121314151617181920212223242526272829303132333435/** * The default thread factory */static class DefaultThreadFactory implements ThreadFactory { //记录创建默认线程池的数量，类变量 private static final AtomicInteger poolNumber = new AtomicInteger(1); //线程组 private final ThreadGroup group; //记录创建线程的数量，实例变量 private final AtomicInteger threadNumber = new AtomicInteger(1); //线程名称前缀 private final String namePrefix; DefaultThreadFactory() {、 //这句话啥意思？ SecurityManager s = System.getSecurityManager(); //赋值线程组 group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) //??为什么这里判断是守护进程，还设置为false？？ t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY)//设置优先级 t.setPriority(Thread.NORM_PRIORITY); return t; }} 我们可以参考上面的默认线程工厂的实现方式，可以自定义任意的线程工厂。 Executors类分析在Executors类中主要提供了三种创建线程池的方法，分别是newCachedThreadPool()、newFixedThreadPool()和newSIngleThreadPool()，下面对这三种方式进行对比分析： 方法 corePoolSize maximumPoolSize keepAliveTime&amp;TimeUnit BlockingQueue newCachedThreadPool() 0 Integer.MAX_VALUE 60s SynchronousQueue newFixedThreadPool() nThreads nThreads 0ms LinkedBlockingQueue newSIngleThreadPool() 1 1 0ms LinkedBlockingQueue ScheduledThreadPool 在这里提两个问题： 1.为什么FixedThreadExecutor的corePoolSize和maximumPoolSize要设计成一样的？ 2.为什么CachedThreadExecutor的maximumPoolSize要设计成Integer.MAX_VALUE？ 对于问题一，因为线程池是先判断corePoolSize,再判断workQueue,最后判断maximumPoolSize，然而LinkedBlockingQueue是无界队列（Integer.MAX_VALUE），所以他是达不到判断maximumPoolSize这一步的，所以maximumPoolSize设置成多少，并没有多大关系。 对于问题二，因为SynchronousQueue设计的原因，如果maximumPoolSize不设计的很大，那么就很容易导致线程占满，然后抛出异常。 关闭线程池通过源码可以看到，停止线程池执行主要是两个方法，第一个是shutdown()，第二个是shutdownNow()方法，他们的主要区别是： 调用shutdown()方法，将会把线程池的状态标记为SHUTDOWN，通过前面的状态分析，我们知道这个状态下线程池将不会接收任何新的任务，并且会继续执行队列里的任务，直到所有任务执行完成，终 止线程池； 调用shutdownNow()方法，将会把线程池的状态标记为STOP，此时线程池也不会接收任何新的任务，并且立即停止正在执行任务的线程，将队列里的任务返回给调用者； 我们可以看到，使用shutdownNow()强行关闭的速度更快，但风险也更大，因为任务很可能执行一半就被停止了；而使用shutdown()正常关闭虽然速度慢，但却更安全，因为会一直等到队列中的任务全部执行完成后才关闭。 使用建议在阿里巴巴Java开发手册中，【强制】建议使用者不要通过Executors去创建线程池，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，从而规避资源耗尽的风险。","link":"/2018/10/11/java-thread-pool/"},{"title":"Netty客户端连接过程源码分析","text":"这篇文章主要分析Netty客户端连接服务端的过程，并结合Netty框架的源码，在Netty源码中我们看一下连接服务端的代码： 123456789101112131415161718192021222324// Configure the client.EventLoopGroup group = new NioEventLoopGroup();try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); if (sslCtx != null) { p.addLast(sslCtx.newHandler(ch.alloc(), HOST, PORT)); } //p.addLast(new LoggingHandler(LogLevel.INFO)); p.addLast(new EchoClientHandler()); } }); // Start the client. ChannelFuture f = b.connect(HOST, PORT).sync(); // Wait until the connection is closed. f.channel().closeFuture().sync(); 上面的代码中这句ChannelFuture f = b.connect(HOST, PORT).sync();才是发起连接，这句之前的代码是设置连接的一些属性，这里不详细讲解这个属性，这篇文章的核心是关于连接过程。 我们追踪代码，首先进入Bootstrap类的connect方法， 123456789101112/** * Connect a {@link Channel} to the remote peer. */public ChannelFuture connect(SocketAddress remoteAddress) { if (remoteAddress == null) { throw new NullPointerException(\"remoteAddress\"); } //验证handler、group、channelFactory是否为空 validate(); //执行连接 return doResolveAndConnect(remoteAddress, config.localAddress());} 验证的逻辑比较简单，核心部分是doResolveAndConnect(remoteAddress, config.localAddress());， 12345678910111213141516171819202122232425262728293031323334353637383940/** * @see #connect() */private ChannelFuture doResolveAndConnect(final SocketAddress remoteAddress, final SocketAddress localAddress) { //第一步、执行初始化channel，并注册channel final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.isDone()) { if (!regFuture.isSuccess()) { return regFuture; } //第二步、执行连接 return doResolveAndConnect0(channel, remoteAddress, localAddress, channel.newPromise()); } else { // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); //添加一个listener，当执行完成回调该listener regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { // Directly obtain the cause and do a null check so we only need one volatile read in case of a // failure. Throwable cause = future.cause(); if (cause != null) { // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); //第二步、执行连接 doResolveAndConnect0(channel, remoteAddress, localAddress, promise); } } }); return promise; }} 如果看了《Netty服务端启动流程分析》这篇文章，就会对这这段代码非常熟悉，它们的逻辑一模一样，总结来说就是两个过程： 1、初始化并注册channel：final ChannelFuture regFuture = initAndRegister(); 2、进一步执行连接：doResolveAndConnect0(channel, remoteAddress, localAddress, channel.newPromise()); 第一个过程在这篇文章就不详细讲了，可以参考《Netty服务端启动流程分析》这篇文章，下面来详细分析第二过程。 doResolveAndConnect0(channel, remoteAddress, localAddress, channel.newPromise());123456789101112131415161718192021222324252627282930313233343536373839404142434445private ChannelFuture doResolveAndConnect0(final Channel channel, SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) { try { final EventLoop eventLoop = channel.eventLoop(); final AddressResolver&lt;SocketAddress&gt; resolver = this.resolver.getResolver(eventLoop); if (!resolver.isSupported(remoteAddress) || resolver.isResolved(remoteAddress)) { // Resolver has no idea about what to do with the specified remote address or it's resolved already. doConnect(remoteAddress, localAddress, promise); return promise; } final Future&lt;SocketAddress&gt; resolveFuture = resolver.resolve(remoteAddress); if (resolveFuture.isDone()) { final Throwable resolveFailureCause = resolveFuture.cause(); if (resolveFailureCause != null) { // Failed to resolve immediately channel.close(); promise.setFailure(resolveFailureCause); } else { // Succeeded to resolve immediately; cached? (or did a blocking lookup) doConnect(resolveFuture.getNow(), localAddress, promise); } return promise; } // Wait until the name resolution is finished. resolveFuture.addListener(new FutureListener&lt;SocketAddress&gt;() { @Override public void operationComplete(Future&lt;SocketAddress&gt; future) throws Exception { if (future.cause() != null) { channel.close(); promise.setFailure(future.cause()); } else { doConnect(future.getNow(), localAddress, promise); } } }); } catch (Throwable cause) { promise.tryFailure(cause); } return promise;} 最终会执行doConnect方法： 123456789101112131415161718private static void doConnect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise connectPromise) { // This method is invoked before channelRegistered() is triggered. Give user handlers a chance to set up // the pipeline in its channelRegistered() implementation. final Channel channel = connectPromise.channel(); channel.eventLoop().execute(new Runnable() { @Override public void run() { if (localAddress == null) { channel.connect(remoteAddress, connectPromise); } else { channel.connect(remoteAddress, localAddress, connectPromise); } connectPromise.addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } });} 在该方法中，会在channel所关联到的eventLoop 线程中调用channel.connect方法，注意这里的channel是NioSocketChannel实例。 1234@Overridepublic ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) { return pipeline.connect(remoteAddress, localAddress, promise);} 这里的pipeline是DefaultChannelPipeline实例，继续看此pipeline的connect方法： 12345@Overridepublic final ChannelFuture connect( SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) { return tail.connect(remoteAddress, localAddress, promise);} 在博文Netty源码分析：ChannelPipeline中有关于tail的详细介绍，这里回顾下：tail是TailContext的实例，继承于AbstractChannelHandlerContext，TailContext并没有实现connect方法，因此这里调用的是其父类AbstractChannelHandlerContext的connect方法。 1234567891011121314151617181920212223242526@Overridepublic ChannelFuture connect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) { if (remoteAddress == null) { throw new NullPointerException(\"remoteAddress\"); } if (isNotValidPromise(promise, false)) { // cancelled return promise; } final AbstractChannelHandlerContext next = findContextOutbound(); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeConnect(remoteAddress, localAddress, promise); } else { safeExecute(executor, new Runnable() { @Override public void run() { next.invokeConnect(remoteAddress, localAddress, promise); } }, promise, null); } return promise;} 此函数中的这行代码：final AbstractChannelHandlerContext next = findContextOutbound();所完成的任务就是在pipeline所持有的以AbstractChannelHandlerContext为节点的双向链表中从尾节点tail开始向前寻找第一个outbound=true的handler节点。 看过上篇博文之后，我相信我们都知道这个outbound=ture的节点时哪一个？是head节点，为什么呢？在博文 Netty源码分析：ChannelPipeline中我们知道在DefaultChannelPipeline 的构造器中, 会实例化两个对象: head 和 tail, 并形成了双向链表的头和尾. head 是 HeadContext 的实例, 它实现了 ChannelOutboundHandler 接口, 即head实例的 outbound = true. 因此在调用上面 findContextOutbound()方法时, 找到的符合outbound=true的节点其实就是 head。 继续看，在pipelie的双向链表中找到第一个outbound=true的AbstractChannelHandlerContext节点head后，然后调用此节点的invokeConnect方法，该方法的代码如下， 1234567891011private void invokeConnect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) { if (invokeHandler()) { try { ((ChannelOutboundHandler) handler()).connect(this, remoteAddress, localAddress, promise); } catch (Throwable t) { notifyOutboundHandlerException(t, promise); } } else { connect(remoteAddress, localAddress, promise); }} 继续看，看HeadContext类中的connect方法，代码如下： 1234567@Overridepublic void connect( ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception { unsafe.connect(remoteAddress, localAddress, promise);} 继续看NioByteUnsafe类中的 connect方法（准确的说此方法是在AbstractNioUnsafe类中） 12345678910@Overridepublic final void connect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) { //... if (doConnect(remoteAddress, localAddress)) { fulfillConnectPromise(promise, wasActive); } else { //... }} 上面只保留了connect的关键代码，相关检查和连接失败的代码省略了，上面这个函数主要是调用了doConnect这个方法，需要注意的是，此方法并不是 AbstractNioUnsafe 的方法, 而是 AbstractNioChannel 的抽象方法. doConnect 方法是在 NioSocketChannel 中实现的。 NioSocketChannel类中的doConnect方法的代码如下： 1234567891011121314151617181920@Overrideprotected boolean doConnect(SocketAddress remoteAddress, SocketAddress localAddress) throws Exception { if (localAddress != null) { doBind0(localAddress); } boolean success = false; try { boolean connected = SocketUtils.connect(javaChannel(), remoteAddress); if (!connected) { selectionKey().interestOps(SelectionKey.OP_CONNECT); } success = true; return connected; } finally { if (!success) { doClose(); } }} 上面方法中javaChannel()方法返回的是NioSocketChannel实例初始化时所产生的Java NIO SocketChannel实例（更具体点为SocketChannelImpl实例）。 然后调用此实例的connect方法完成Java NIO层面上的Socket连接。 REFERENCES Netty源码分析：客户端连接","link":"/2019/01/31/netty-client-side-connection/"},{"title":"User Thread and Daemon Thread in Java","text":"在Java当中有两种线程，一种是User Thread，另一种是Daemon Thread。一般来说User Thread具有较高的优先级，它主要运行在前台，然而，Daemon Thread具有较低的优先级，主要运行在后台。 User ThreadUser Thread通常由应用或者用户创建的，JVM Instance等待所有的User Thread执行完成Tasks，直到所有的User Thread执行完成JVM才会退出。 Daemon ThreadDaemon Thread通常由JVM创建， 这些线程在后台运行，运行一些后台任务（包括，垃圾回收、内务任务等）。JVM 不会等待所有的Daemon Thrad执行完Tasks，只要所有的User Thread执行完Tasks，JVM就会退出。 User Thread VS Daemon Thread In Java User Threads Daemon Threads JVM waits for user threads to finish their work. It will not exit until all user threads finish their work. JVM will not wait for daemon threads to finish their work. It will exit as soon as all user threads finish their work. User threads are foreground threads. Daemon threads are background threads. User threads are high priority threads. Daemon threads are low priority threads. User threads are created by the application. Daemon threads, in most of time, are created by the JVM. User threads are mainly designed to do some specific task. Daemon threads are designed to support the user threads. JVM will not force the user threads to terminate. It will wait for user threads to terminate themselves. JVM will force the daemon threads to terminate if all user threads have finished their work. Some Things-To-Remember about user threads and daemon threads In Java : You can convert user thread into daemon thread explicitly by calling setDaemon() method of the thread. 123456789101112131415161718public class ThreadsInJava { //Main Thread public static void main(String[] args) { UserThread userThread = new UserThread(); //Creating the UserThread userThread.setDaemon(true); //Changing the thread as Daemon userThread.start(); //Starting the thread }}class UserThread extends Thread { @Override public void run() { for (int i = 0; i &lt; 1000; i++) { System.out.println(\"This is an user thread....\"); } }} You can’t set a daemon property after starting the thread. If you try to set the daemon property when the thread is active, It will throw a IllegalThreadStateException at run time. 123456789101112131415161718class UserThread extends Thread { @Override public void run() { for (int i = 0; i &lt; 1000; i++) { System.out.println(\"This is an user thread....\"); } }}public class ThreadsInJava { public static void main(String[] args) { UserThread userThread = new UserThread(); //Creating the UserThread userThread.start(); //Starting the thread userThread.setDaemon(true); //This statement will throw IllegalThreadStateException }} You can check whether the thread is user thread or a daemon thread by using isDaemon() method of Thread class. This method returns “true” for a daemon thread and “false” for a user thread. 12345678910111213141516171819202122class UserThread extends Thread { @Override public void run() { for (int i = 0; i &lt; 1000; i++) { System.out.println(\"This is an user thread....\"); } }}public class ThreadsInJava { public static void main(String[] args) { UserThread userThread = new UserThread(); //Creating the UserThread System.out.println(userThread.isDaemon()); //Output : false userThread.setDaemon(true); //changing the thread as Daemon userThread.start(); //Starting the thread System.out.println(userThread.isDaemon()); //Output : true }} Daemon property of a thread is inherited from it’s parent thread. i.e The thread created by user thread will be user thread and the thread created by daemon thread will be a daemon thread. 12345678910111213141516171819202122class Thread1 extends Thread { @Override public void run() { Thread t = new Thread(); //Creating a child thread System.out.println(t.isDaemon()); //Checking the Daemon property of a child thread }}public class ThreadsInJava { public static void main(String[] args) { Thread1 t1 = new Thread1(); //Creating the Thread1 t1.start(); //Starting the thread Thread1 t2 = new Thread1(); //Creating the Thread1 t2.setDaemon(true); //changing the thread as Daemon t2.start(); //Starting the thread }} The main thread or primary thread created by JVM is an user thread. Demonstration of User thread and daemon thread : In the below program, The task of daemon thread will not be completed. Program terminates as soon as user thread finishes it’s task. It will not wait for daemon thread to finish it’s task. 1234567891011121314151617181920212223242526272829303132333435/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 10:32 AM 2018/07/06. */class UserThread extends Thread { @Override public void run() { System.out.println(\"This is a user thread.....\"); }}class DaemonThread extends Thread { public DaemonThread() { setDaemon(true); } @Override public void run() { for (int i = 0; i &lt; 1000; i++) { System.out.println(\"This is daemon thread.....\" + i); } }}public class ThreadsInJava { public static void main(String[] args) { DaemonThread daemon = new DaemonThread(); //Creating the DaemonThread daemon.start(); //Starting the daemon thread UserThread userThread = new UserThread(); //Creating the UserThread userThread.start(); //Starting the user thread }} Conclusion1) User threads are created by the application (user) to perform some specific task. Where as daemon threads are mostly created by the JVM to perform some background tasks like garbage collection. 2) JVM will wait for user threads to finish their tasks. JVM will not exit until all user threads finish their tasks. On the other side, JVM will not wait for daemon threads to finish their tasks. It will exit as soon as all user threads finish their tasks. 3) User threads are high priority threads, They are designed mainly to execute some important task in an application. Where as daemon threads are less priority threads. They are designed to serve the user threads. 4) User threads are foreground threads. They always run in foreground and perform some specific task assigned to them. Where as daemon threads are background threads. They always run in background and act in a supporting role to user threads. 5) JVM will not force the user threads to terminate. It will wait for user threads to terminate themselves. On the other hand, JVM will force the daemon threads to terminate if all the user threads have finished their task. 6) User threads are chosen to do the core work of an application. The application is very much dependent on the user threads for it’s smooth execution. Where as daemon threads are chosen to do some supporting tasks. The application is less dependent on the daemon threads for it’s smooth running. REFERENCES Types Of Threads In Java Difference Between User Threads Vs Daemon Threads In Java","link":"/2018/07/04/user-thread-and-daemon-thread/"},{"title":"Dubbo集群容错机制","text":"在之前一篇文章《Dubbo消费者调用过程源码分析》讲到，在创建代理的时候会生成调用对象invoker，这个时候就会绑定集群策略，我们来看生成invoker的代码，在类ReferenceConfig#createProxy(Map&lt;String, String&gt; map)方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//直接在配置文件中配置url，实现直接通信（如果既配置了直连地址又配置了注册中心的地址，则自动忽略注册中心的地址）if (url != null &amp;&amp; url.length() &gt; 0) { // user specified URL, could be peer-to-peer address, or register center's address. String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length &gt; 0) { for (String u : us) { URL url = URL.valueOf(u); if (url.getPath() == null || url.getPath().length() == 0) { url = url.setPath(interfaceName); } if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); } else { urls.add(ClusterUtils.mergeUrl(url, map)); } } }} else { // assemble URL from register center's configuration //获取配置注册中心的url（可以有多个注册中心的url） List&lt;URL&gt; us = loadRegistries(false); if (us != null &amp;&amp; !us.isEmpty()) { for (URL u : us) { URL monitorUrl = loadMonitor(u); if (monitorUrl != null) { map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString())); } urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); } } //如果urls为空，则抛出异常 if (urls.isEmpty()) { throw new IllegalStateException(\"No such any registry to reference \" + interfaceName + \" on the consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", please config &lt;dubbo:registry address=\\\"...\\\" /&gt; to your spring config.\"); }}//当urls的长度为一时，可能为服务的直连地址也可能为注册中心的地址if (urls.size() == 1) { invoker = refprotocol.refer(interfaceClass, urls.get(0));} else {//有多个直连地址，或者多个注册中心的地址 List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) { //获取每个url对应的invoker invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { //获取最后一个注册中心的地址 registryURL = url; // use last registry url } } if (registryURL != null) { // registry url is available // use AvailableCluster only when register's cluster is available //当有注册中心的地址时，第一层使用AvailableCluster集群策略，第二层使用默认的集群策略 URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); invoker = cluster.join(new StaticDirectory(u, invokers)); } else { // not a registry url //如果没有注册中心地址，则使用默认的集群策略 invoker = cluster.join(new StaticDirectory(invokers)); }} 我们总结出三种生成集群策略的入口，当urls的长度为1时，此时该url可能为注册中心的地址也可能是服务的直连地址，则进一步执行invoker = refprotocol.refer(interfaceClass, urls.get(0));；当urls的长度不为1时，此时可能为多个注册中心的地址或者多个服务直连地址，当为多个注册中心的地址时，会执行： 12URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME);invoker = cluster.join(new StaticDirectory(u, invokers)); 当为多个直连地址时，则执行：invoker = cluster.join(new StaticDirectory(invokers));，下面将对这三种方式进行详细的分析。 Dubbo中提供了七种集群模式（FailoverCluster、FailfastCluster、FailsafeCluster、FailbackCluster、ForkingCluster、BroadcastCluster、AvailableCluster），来看一下它们的继承关系图： 下面将分别对每一种集群模式进行分析。 FailoverCluster1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Override@SuppressWarnings({\"unchecked\", \"rawtypes\"})public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers; checkInvokers(copyinvokers, invocation);//?? String methodName = RpcUtils.getMethodName(invocation); //获取重试次数 int len = getUrl().getMethodParameter(methodName, Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;= 0) { len = 1; } // retry loop. RpcException le = null; // last exception. //存放被调用过的invoker List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) { //Reselect before retry to avoid a change of candidate `invokers`. //NOTE: if `invokers` changed, then `invoked` also lose accuracy. if (i &gt; 0) { checkWhetherDestroyed(); copyinvokers = list(invocation); // check again checkInvokers(copyinvokers, invocation); } //根据负载均衡策略选择一个invoker Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); RpcContext.getContext().setInvokers((List) invoked); try { //调用invoke Result result = invoker.invoke(invocation); if (le != null &amp;&amp; logger.isWarnEnabled()) { logger.warn(\"Although retry the method \" + methodName + \" in the service \" + getInterface().getName() + \" was successful by the provider \" + invoker.getUrl().getAddress() + \", but there have been failed providers \" + providers + \" (\" + providers.size() + \"/\" + copyinvokers.size() + \") from the registry \" + directory.getUrl().getAddress() + \" on the consumer \" + NetUtils.getLocalHost() + \" using the dubbo version \" + Version.getVersion() + \". Last error is: \" + le.getMessage(), le); } return result; } catch (RpcException e) { //捕获到远程调用异常，则直接抛出异常 if (e.isBiz()) { // biz exception. throw e; } le = e; } catch (Throwable e) { le = new RpcException(e.getMessage(), e); } finally { providers.add(invoker.getUrl().getAddress()); } } throw new RpcException(le.getCode(), \"Failed to invoke the method \" + methodName + \" in the service \" + getInterface().getName() + \". Tried \" + len + \" times of the providers \" + providers + \" (\" + providers.size() + \"/\" + copyinvokers.size() + \") from the registry \" + directory.getUrl().getAddress() + \" on the consumer \" + NetUtils.getLocalHost() + \" using the dubbo version \" + Version.getVersion() + \". Last error is: \" + le.getMessage(), le.getCause() != null ? le.getCause() : le);} Failover集群容错机制，总的逻辑是，以方法重复次数为限制，每次调用如果失败，就利用负责均衡策略获取下一个提供者（invoker）,直到调用成功，或者最后方法超限，抛出异常，其中中间如果有业务异常，则不再重试，直接抛出异常。 FailfastCluster123456789101112131415161718192021@Overridepublic Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { checkInvokers(invokers, invocation); //通过负载均衡策略选择一个invoker Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); try { //只执行一次调用 return invoker.invoke(invocation); } catch (Throwable e) { if (e instanceof RpcException &amp;&amp; ((RpcException) e).isBiz()) { // biz exception. throw (RpcException) e; } throw new RpcException(e instanceof RpcException ? ((RpcException) e).getCode() : 0, \"Failfast invoke providers \" + invoker.getUrl() + \" \" + loadbalance.getClass().getSimpleName() + \" select from all providers \" + invokers + \" for service \" + getInterface().getName() + \" method \" + invocation.getMethodName() + \" on consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", but no luck to perform the invocation. Last error is: \" + e.getMessage(), e.getCause() != null ? e.getCause() : e); }} 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 FailsafeCluster1234567891011121314@Overridepublic Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { try { checkInvokers(invokers, invocation); //通过负载均衡策略选择一个invoker Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); //只执行一次调用 return invoker.invoke(invocation); } catch (Throwable e) { logger.error(\"Failsafe ignore exception: \" + e.getMessage(), e); //遇到异常则返回一个RpcResult return new RpcResult(); // ignore }} 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 FailbackCluster123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960private void addFailed(Invocation invocation, AbstractClusterInvoker&lt;?&gt; router) { if (retryFuture == null) { synchronized (this) { if (retryFuture == null) { //调度线程池，周期性（5秒一次）的调用retryFailed方法 retryFuture = scheduledExecutorService.scheduleWithFixedDelay(new Runnable() { @Override public void run() { // collect retry statistics try { //执行之前异常方法的调用 retryFailed(); } catch (Throwable t) { // Defensive fault tolerance logger.error(\"Unexpected error occur at collect statistic\", t); } } }, RETRY_FAILED_PERIOD, RETRY_FAILED_PERIOD, TimeUnit.MILLISECONDS); } } } //放入map failed.put(invocation, router);}void retryFailed() { if (failed.size() == 0) { return; } //遍历所有的失败执行 for (Map.Entry&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; entry : new HashMap&lt;&gt;(failed).entrySet()) { Invocation invocation = entry.getKey(); Invoker&lt;?&gt; invoker = entry.getValue(); try { //发起调用 invoker.invoke(invocation); //调用成功则从failed中删除 failed.remove(invocation); } catch (Throwable e) { logger.error(\"Failed retry to invoke method \" + invocation.getMethodName() + \", waiting again.\", e); } }}@Overrideprotected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { try { checkInvokers(invokers, invocation); //通过负载均衡策略选择一个invoker Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); return invoker.invoke(invocation); } catch (Throwable e) { //失败后，记录日志，不抛出异常 logger.error(\"Failback to invoke method \" + invocation.getMethodName() + \", wait for retry in background. Ignored exception: \" + e.getMessage() + \", \", e); //记录异常信息，key为调用的方法信息，value为invoker本身 addFailed(invocation, this); return new RpcResult(); // ignore }} 此策略失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 ForkingCluster123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Override@SuppressWarnings({\"unchecked\", \"rawtypes\"})public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { try { checkInvokers(invokers, invocation); final List&lt;Invoker&lt;T&gt;&gt; selected; //获取并行调用的个数 final int forks = getUrl().getParameter(Constants.FORKS_KEY, Constants.DEFAULT_FORKS); //超时时间 final int timeout = getUrl().getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (forks &lt;= 0 || forks &gt;= invokers.size()) { selected = invokers; } else { selected = new ArrayList&lt;&gt;(); //通过负载均衡策略，选出要并行调用的invoker，放入selected列表中 for (int i = 0; i &lt; forks; i++) { // TODO. Add some comment here, refer chinese version for more details. Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, selected); if (!selected.contains(invoker)) {//防止重复添加 //Avoid add the same invoker several times. selected.add(invoker); } } } RpcContext.getContext().setInvokers((List) selected); final AtomicInteger count = new AtomicInteger(); final BlockingQueue&lt;Object&gt; ref = new LinkedBlockingQueue&lt;&gt;(); //遍历selected列表，通过线程池并发调用 for (final Invoker&lt;T&gt; invoker : selected) { executor.execute(new Runnable() { @Override public void run() { try { Result result = invoker.invoke(invocation); //把结果放入阻塞队列 ref.offer(result); } catch (Throwable e) { int value = count.incrementAndGet(); //表示所有并发调用都抛出异常，才把异常加入阻塞队列尾部 //这就保证了，只要有一个调用成功，ref.poll()方法就能从队列头部取到返回结果 if (value &gt;= selected.size()) { ref.offer(e); } } } }); } try { //设定阻塞时间，从阻塞队列头部获取返回结果，如果是异常则抛出异常 Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS); if (ret instanceof Throwable) { Throwable e = (Throwable) ret; throw new RpcException(e instanceof RpcException ? ((RpcException) e).getCode() : 0, \"Failed to forking invoke provider \" + selected + \", but no luck to perform the invocation. Last error is: \" + e.getMessage(), e.getCause() != null ? e.getCause() : e); } return (Result) ret; } catch (InterruptedException e) { throw new RpcException(\"Failed to forking invoke provider \" + selected + \", but no luck to perform the invocation. Last error is: \" + e.getMessage(), e); } } finally { // clear attachments which is binding to current thread. RpcContext.getContext().clearAttachments(); }} 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。 BroadcastCluster12345678910111213141516171819202122232425@Override@SuppressWarnings({\"unchecked\", \"rawtypes\"})public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { checkInvokers(invokers, invocation); RpcContext.getContext().setInvokers((List) invokers); RpcException exception = null; Result result = null; //遍历调用所有的服务列表，并把结果覆盖以前的 for (Invoker&lt;T&gt; invoker : invokers) { try { result = invoker.invoke(invocation); } catch (RpcException e) { exception = e; logger.warn(e.getMessage(), e); } catch (Throwable e) { exception = new RpcException(e.getMessage(), e); logger.warn(e.getMessage(), e); } } //其中有一个失败，则直接抛异常 if (exception != null) { throw exception; } return result;} 这个策略通常用于通知所有提供者更新缓存或日志等本地资源信息。 AvailableClusterAvailable集群容错机制，主要逻辑是，简单的调用第一个可到达的服务，如果都不可达，则抛出异常： 12345678910111213141516@Overridepublic &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException { //没有通过继承AbstractClusterInvoker抽象类，而是直接实现它，也没有使用负载均衡策略，而是简单的选择一个可达的服务 return new AbstractClusterInvoker&lt;T&gt;(directory) { @Override public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { for (Invoker&lt;T&gt; invoker : invokers) { if (invoker.isAvailable()) {//获取第一个可达的服务提供方 return invoker.invoke(invocation); } } throw new RpcException(\"No provider available in \" + invokers); } };}","link":"/2018/09/18/dubbo-cluster-fault-tolerance/"},{"title":"Dubbo负载均衡策略分析","text":"Dubbo提供了四种负载均衡策略：Random LoadBalance（加权随机负载均衡）、RoundRobin LoadBalance（加权轮询负载均衡）、LeastActive LoadBalance（最少活跃数负载均衡）、ConsistentHash LoadBalance（一致性hash负载均衡），下面将分别分析这四种负载均衡策略的源码。 Random LoadBalance先来看一下RandomLoadBalance类的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041public class RandomLoadBalance extends AbstractLoadBalance { public static final String NAME = \"random\"; @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) { int length = invokers.size(); // Number of invokers int totalWeight = 0; // The sum of weights boolean sameWeight = true; // Every invoker has the same weight? for (int i = 0; i &lt; length; i++) { //获取权重 int weight = getWeight(invokers.get(i), invocation); //权重累积和 totalWeight += weight; // Sum //记录所有的invokers的weight是否是一样的 if (sameWeight &amp;&amp; i &gt; 0 &amp;&amp; weight != getWeight(invokers.get(i - 1), invocation)) { sameWeight = false; } } //如果不是所有的invoker权重都一样 if (totalWeight &gt; 0 &amp;&amp; !sameWeight) { // If (not every invoker has the same weight &amp; at least one invoker's weight&gt;0), select randomly based on totalWeight. //获取随机数的范围是[0, totalWeight) int offset = ThreadLocalRandom.current().nextInt(totalWeight); // Return a invoker based on the random value. for (int i = 0; i &lt; length; i++) { offset -= getWeight(invokers.get(i), invocation); if (offset &lt; 0) { //返回invoker return invokers.get(i); } } } //如果所有的invoker都是一样的weight，则直接获取随机数，并返回 //这里使用了ThreadLocalRandom做了优化 // If all invokers have the same weight value or totalWeight=0, return evenly. return invokers.get(ThreadLocalRandom.current().nextInt(length)); }} 随机加权轮询算法还是比较容易理解的，下面继续分析RoundRobin LoadBalance。 RoundRobin LoadBalance在理解加权轮询算法源码之前，我们先通过一个简单的示例来表达加权轮询算法的工作原理，如下图所示 假设某个服务有五个提供者，分别为A、B、C、D、E，他们的weight分别为5/3/6/1/4； 因此他们的weight总和sumWeight为19，maxWeight为6，minWeight为1； 设置一个sequence表示第几次调用这个服务，sequence从0开始，每次调用完对sequence进行加1； currentSequence表示当前的调用时sequence的值； 通过mod=currentSequence%sumWeight得到的值，对服务进行循环，每次循环，当mod为零时则表示选中当前服务并返回，如果mod不为零则对当前服务的weight减1，并且mod也减1，直到mod为零退出循环； 因此，通过上面的步骤，我们可以得出结论，当对服务进行19次调用时，提供者提供的顺序为：A、B、C、D、E、A、B、C、E、A、B、C、E、A、C、E、A、C、C； RoundRobinLoadBalance类源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class RoundRobinLoadBalance extends AbstractLoadBalance { public static final String NAME = \"roundrobin\"; private final ConcurrentMap&lt;String, AtomicPositiveInteger&gt; sequences = new ConcurrentHashMap&lt;String, AtomicPositiveInteger&gt;(); @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) { String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName(); int length = invokers.size(); // Number of invokers int maxWeight = 0; // The maximum weight int minWeight = Integer.MAX_VALUE; // The minimum weight final LinkedHashMap&lt;Invoker&lt;T&gt;, IntegerWrapper&gt; invokerToWeightMap = new LinkedHashMap&lt;Invoker&lt;T&gt;, IntegerWrapper&gt;(); int weightSum = 0; for (int i = 0; i &lt; length; i++) { int weight = getWeight(invokers.get(i), invocation); //选择一个最大的权重 maxWeight = Math.max(maxWeight, weight); // Choose the maximum weight //选择一个最小的权重 minWeight = Math.min(minWeight, weight); // Choose the minimum weight if (weight &gt; 0) { //形成一个invoker：weight的map invokerToWeightMap.put(invokers.get(i), new IntegerWrapper(weight)); //总的weight weightSum += weight; } } //为当前的key设置一个sequence AtomicPositiveInteger sequence = sequences.get(key); if (sequence == null) { sequences.putIfAbsent(key, new AtomicPositiveInteger()); sequence = sequences.get(key); } //获取当前的sequence int currentSequence = sequence.getAndIncrement(); if (maxWeight &gt; 0 &amp;&amp; minWeight &lt; maxWeight) { int mod = currentSequence % weightSum; for (int i = 0; i &lt; maxWeight; i++) { for (Map.Entry&lt;Invoker&lt;T&gt;, IntegerWrapper&gt; each : invokerToWeightMap.entrySet()) { final Invoker&lt;T&gt; k = each.getKey(); final IntegerWrapper v = each.getValue(); if (mod == 0 &amp;&amp; v.getValue() &gt; 0) { return k; } if (v.getValue() &gt; 0) { v.decrement(); mod--; } } } } // Round robin return invokers.get(currentSequence % length); } //自定义IntegerWrapper包装类 private static final class IntegerWrapper { private int value; public IntegerWrapper(int value) { this.value = value; } public int getValue() { return value; } public void setValue(int value) { this.value = value; } public void decrement() { this.value--; } }} LeastActive LoadBalance看一下LeastActiveLoadBalance类的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class LeastActiveLoadBalance extends AbstractLoadBalance { public static final String NAME = \"leastactive\"; @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) { int length = invokers.size(); // Number of invokers int leastActive = -1; // The least active value of all invokers int leastCount = 0; // The number of invokers having the same least active value (leastActive) int[] leastIndexs = new int[length]; // The index of invokers having the same least active value (leastActive) int totalWeight = 0; // The sum of weights int firstWeight = 0; // Initial value, used for comparision boolean sameWeight = true; // Every invoker has the same weight value? for (int i = 0; i &lt; length; i++) { Invoker&lt;T&gt; invoker = invokers.get(i); int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive(); // Active number int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT); // Weight if (leastActive == -1 || active &lt; leastActive) { // Restart, when find a invoker having smaller least active value. leastActive = active; // Record the current least active value leastCount = 1; // Reset leastCount, count again based on current leastCount leastIndexs[0] = i; // Reset totalWeight = weight; // Reset firstWeight = weight; // Record the weight the first invoker sameWeight = true; // Reset, every invoker has the same weight value? } else if (active == leastActive) { // If current invoker's active value equals with leaseActive, then accumulating. leastIndexs[leastCount++] = i; // Record index number of this invoker totalWeight += weight; // Add this invoker's weight to totalWeight. // If every invoker has the same weight? if (sameWeight &amp;&amp; i &gt; 0 &amp;&amp; weight != firstWeight) { sameWeight = false; } } } // assert(leastCount &gt; 0) if (leastCount == 1) { // If we got exactly one invoker having the least active value, return this invoker directly. return invokers.get(leastIndexs[0]); } if (!sameWeight &amp;&amp; totalWeight &gt; 0) { // If (not every invoker has the same weight &amp; at least one invoker's weight&gt;0), select randomly based on totalWeight. int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight); // Return a invoker based on the random value. for (int i = 0; i &lt; leastCount; i++) { int leastIndex = leastIndexs[i]; offsetWeight -= getWeight(invokers.get(leastIndex), invocation); if (offsetWeight &lt;= 0) return invokers.get(leastIndex); } } // If all invokers have the same weight value or totalWeight=0, return evenly. return invokers.get(leastIndexs[ThreadLocalRandom.current().nextInt(leastCount)]); }} ConsistentHash LoadBalance看一下ConsistentHasLoadBalance类的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public class ConsistentHashLoadBalance extends AbstractLoadBalance { public static final String NAME = \"consistenthash\"; private final ConcurrentMap&lt;String, ConsistentHashSelector&lt;?&gt;&gt; selectors = new ConcurrentHashMap&lt;String, ConsistentHashSelector&lt;?&gt;&gt;(); @SuppressWarnings(\"unchecked\") @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) { String methodName = RpcUtils.getMethodName(invocation); String key = invokers.get(0).getUrl().getServiceKey() + \".\" + methodName; int identityHashCode = System.identityHashCode(invokers); ConsistentHashSelector&lt;T&gt; selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key); if (selector == null || selector.identityHashCode != identityHashCode) { selectors.put(key, new ConsistentHashSelector&lt;T&gt;(invokers, methodName, identityHashCode)); selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key); } return selector.select(invocation); } private static final class ConsistentHashSelector&lt;T&gt; { private final TreeMap&lt;Long, Invoker&lt;T&gt;&gt; virtualInvokers; private final int replicaNumber; private final int identityHashCode; private final int[] argumentIndex; ConsistentHashSelector(List&lt;Invoker&lt;T&gt;&gt; invokers, String methodName, int identityHashCode) { this.virtualInvokers = new TreeMap&lt;Long, Invoker&lt;T&gt;&gt;(); this.identityHashCode = identityHashCode; URL url = invokers.get(0).getUrl(); this.replicaNumber = url.getMethodParameter(methodName, \"hash.nodes\", 160); String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, \"hash.arguments\", \"0\")); argumentIndex = new int[index.length]; for (int i = 0; i &lt; index.length; i++) { argumentIndex[i] = Integer.parseInt(index[i]); } for (Invoker&lt;T&gt; invoker : invokers) { String address = invoker.getUrl().getAddress(); for (int i = 0; i &lt; replicaNumber / 4; i++) { byte[] digest = md5(address + i); for (int h = 0; h &lt; 4; h++) { long m = hash(digest, h); virtualInvokers.put(m, invoker); } } } } public Invoker&lt;T&gt; select(Invocation invocation) { String key = toKey(invocation.getArguments()); byte[] digest = md5(key); return selectForKey(hash(digest, 0)); } private String toKey(Object[] args) { StringBuilder buf = new StringBuilder(); for (int i : argumentIndex) { if (i &gt;= 0 &amp;&amp; i &lt; args.length) { buf.append(args[i]); } } return buf.toString(); } private Invoker&lt;T&gt; selectForKey(long hash) { Map.Entry&lt;Long, Invoker&lt;T&gt;&gt; entry = virtualInvokers.ceilingEntry(hash); if (entry == null) { entry = virtualInvokers.firstEntry(); } return entry.getValue(); } private long hash(byte[] digest, int number) { return (((long) (digest[3 + number * 4] &amp; 0xFF) &lt;&lt; 24) | ((long) (digest[2 + number * 4] &amp; 0xFF) &lt;&lt; 16) | ((long) (digest[1 + number * 4] &amp; 0xFF) &lt;&lt; 8) | (digest[number * 4] &amp; 0xFF)) &amp; 0xFFFFFFFFL; } private byte[] md5(String value) { MessageDigest md5; try { md5 = MessageDigest.getInstance(\"MD5\"); } catch (NoSuchAlgorithmException e) { throw new IllegalStateException(e.getMessage(), e); } md5.reset(); byte[] bytes; try { bytes = value.getBytes(\"UTF-8\"); } catch (UnsupportedEncodingException e) { throw new IllegalStateException(e.getMessage(), e); } md5.update(bytes); return md5.digest(); } }} 更新（2018/10/12）因为之前的RoundRobin LoadBalance算法存在性能问题，参考ISSUEhttps://github.com/apache/incubator-dubbo/issues/2578。现在最新版本对其进行了优化，优化思路如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class RoundRobinLoadBalance extends AbstractLoadBalance { public static final String NAME = \"roundrobin\"; private final ConcurrentMap&lt;String, AtomicPositiveInteger&gt; sequences = new ConcurrentHashMap&lt;String, AtomicPositiveInteger&gt;(); private final ConcurrentMap&lt;String, AtomicPositiveInteger&gt; indexSeqs = new ConcurrentHashMap&lt;String, AtomicPositiveInteger&gt;(); @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) { String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName(); int length = invokers.size(); // Number of invokers int maxWeight = 0; // The maximum weight int minWeight = Integer.MAX_VALUE; // The minimum weight final List&lt;Invoker&lt;T&gt;&gt; nonZeroWeightedInvokers = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; length; i++) { int weight = getWeight(invokers.get(i), invocation); maxWeight = Math.max(maxWeight, weight); // Choose the maximum weight minWeight = Math.min(minWeight, weight); // Choose the minimum weight if (weight &gt; 0) { nonZeroWeightedInvokers.add(invokers.get(i)); } } AtomicPositiveInteger sequence = sequences.get(key); if (sequence == null) { sequences.putIfAbsent(key, new AtomicPositiveInteger()); sequence = sequences.get(key); } if (maxWeight &gt; 0 &amp;&amp; minWeight &lt; maxWeight) { AtomicPositiveInteger indexSeq = indexSeqs.get(key); if (indexSeq == null) { indexSeqs.putIfAbsent(key, new AtomicPositiveInteger(-1)); indexSeq = indexSeqs.get(key); } length = nonZeroWeightedInvokers.size(); while (true) { int index = indexSeq.incrementAndGet() % length; int currentWeight; if (index == 0) { currentWeight = sequence.incrementAndGet() % maxWeight; } else { currentWeight = sequence.get() % maxWeight; } if (getWeight(nonZeroWeightedInvokers.get(index), invocation) &gt; currentWeight) { return nonZeroWeightedInvokers.get(index); } } } // Round robin return invokers.get(sequence.getAndIncrement() % length); }} https://colobu.com/2016/12/04/smooth-weighted-round-robin-algorithm/","link":"/2018/09/10/dubbo-loadbalance-strategy/"},{"title":"Netty核心组件之ChannelPipeline","text":"netty在服务端端口绑定和新连接建立的过程中会建立相应的channel，而与channel的动作密切相关的是pipeline这个概念，pipeline像是可以看作是一条流水线，原始的原料(字节流)进来，经过加工，最后输出，在前面的文章《Netty服务端启动流程分析》中已经讲到在创建实例化channel的时候，会初始化它的各种属性，其中就包括pipline，因此这篇文章将从pipline初始化为入口点来分析pipline的运作流程。 AbstractChannel.java 123456789101112/** * Creates a new instance. * * @param parent * the parent of this channel. {@code null} if there's no parent. */protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();} 通过调用newChannelPipline()函数，来创建pipline 123456/** * Returns a new {@link DefaultChannelPipeline} instance. */protected DefaultChannelPipeline newChannelPipeline() { return new DefaultChannelPipeline(this);} 我们来看下DefaultChannelPipeline的构造函数： 123456789101112protected DefaultChannelPipeline(Channel channel) { this.channel = ObjectUtil.checkNotNull(channel, \"channel\"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); //创建tail节点 tail = new TailContext(this); //创建head节点 head = new HeadContext(this); head.next = tail; tail.prev = head;} 因此最开始的pipline的结构如下所示 pipline添加节点12345678910111213141516171819202122232425262728293031323334353637@Overridepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; //同步代码块，保证线程安全 synchronized (this) { // 1、检查是否有重复的handler checkMultiplicity(handler); // 2、创建节点 newCtx = newContext(group, filterName(name, handler), handler); // 3、添加节点 addLast0(newCtx); // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) { newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; } EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) { newCtx.setAddPending(); executor.execute(new Runnable() { @Override public void run() { callHandlerAdded0(newCtx); } }); return this; } } // 4、回调用户方法 callHandlerAdded0(newCtx); return this;} 检查是否有重复的handler在用户代码添加一条handler的时候，首先会查看该handler有没有添加过 1234567891011private static void checkMultiplicity(ChannelHandler handler) { if (handler instanceof ChannelHandlerAdapter) { ChannelHandlerAdapter h = (ChannelHandlerAdapter) handler; if (!h.isSharable() &amp;&amp; h.added) { throw new ChannelPipelineException( h.getClass().getName() + \" is not a @Sharable handler, so can't be added or removed multiple times.\"); } h.added = true; }} netty使用一个成员变量added标识一个channel是否已经添加，上面这段代码很简单，如果当前要添加的Handler是非共享的，并且已经添加过，那就抛出异常，否则，标识该handler已经添加 由此可见，一个Handler如果是sharable的，就可以无限次被添加到pipeline中，我们客户端代码如果要让一个Handler被共用，只需要加一个@Sharable标注即可，如下 1234@Sharablepublic class BusinessHandler { } 而如果Handler是sharable的，一般就通过spring的注入的方式使用，不需要每次都new 一个 isSharable() 方法正是通过该Handler对应的类是否标注@Sharable来实现的 ChannelHandlerAdapter#isSharable() 12345678910111213141516171819202122/** * Return {@code true} if the implementation is {@link Sharable} and so can be added * to different {@link ChannelPipeline}s. */public boolean isSharable() { /** * Cache the result of {@link Sharable} annotation detection to workaround a condition. We use a * {@link ThreadLocal} and {@link WeakHashMap} to eliminate the volatile write/reads. Using different * {@link WeakHashMap} instances per {@link Thread} is good enough for us and the number of * {@link Thread}s are quite limited anyway. * * See &lt;a href=\"https://github.com/netty/netty/issues/2289\"&gt;#2289&lt;/a&gt;. */ Class&lt;?&gt; clazz = getClass(); Map&lt;Class&lt;?&gt;, Boolean&gt; cache = InternalThreadLocalMap.get().handlerSharableCache(); Boolean sharable = cache.get(clazz); if (sharable == null) { sharable = clazz.isAnnotationPresent(Sharable.class); cache.put(clazz, sharable); } return sharable;} 这里也可以看到，netty为了性能优化到极致，还使用了ThreadLocal来缓存Handler的状态，高并发海量连接下，每次有新连接添加Handler都会创建调用此方法。 创建节点回到主流程，看创建上下文这段代码 1newCtx = newContext(group, filterName(name, handler), handler); 这里我们需要先分析 filterName(name, handler) 这段代码，这个函数用于给handler创建一个唯一性的名字 1234567private String filterName(String name, ChannelHandler handler) { if (name == null) { return generateName(handler); } checkDuplicateName(name); return name;} 显然，我们传入的name为null，netty就给我们生成一个默认的name，否则，检查是否有重名，检查通过的话就返回 netty创建默认name的规则为 简单类名#0，下面我们来看些具体是怎么实现的 1234567891011121314151617181920212223242526272829303132private static final FastThreadLocal&lt;Map&lt;Class&lt;?&gt;, String&gt;&gt; nameCaches = new FastThreadLocal&lt;Map&lt;Class&lt;?&gt;, String&gt;&gt;() { @Override protected Map&lt;Class&lt;?&gt;, String&gt; initialValue() throws Exception { return new WeakHashMap&lt;Class&lt;?&gt;, String&gt;(); }};private String generateName(ChannelHandler handler) { // 先查看缓存中是否有生成过默认name Map&lt;Class&lt;?&gt;, String&gt; cache = nameCaches.get(); Class&lt;?&gt; handlerType = handler.getClass(); String name = cache.get(handlerType); // 没有生成过，就生成一个默认name，加入缓存 if (name == null) { name = generateName0(handlerType); cache.put(handlerType, name); } // 生成完了，还要看默认name有没有冲突 if (context0(name) != null) { String baseName = name.substring(0, name.length() - 1); for (int i = 1;; i ++) { String newName = baseName + i; if (context0(newName) == null) { name = newName; break; } } } return name;} netty使用一个 FastThreadLocal(后面的文章会细说)变量来缓存Handler的类和默认名称的映射关系，在生成name的时候，首先查看缓存中有没有生成过默认name(简单类名#0)，如果没有生成，就调用generateName0()生成默认name，然后加入缓存 接下来还需要检查name是否和已有的name有冲突，调用context0()，查找pipeline里面有没有对应的context 12345678910private AbstractChannelHandlerContext context0(String name) { AbstractChannelHandlerContext context = head.next; while (context != tail) { if (context.name().equals(name)) { return context; } context = context.next; } return null;} context0()方法链表遍历每一个 ChannelHandlerContext，只要发现某个context的名字与待添加的name相同，就返回该context，最后抛出异常，可以看到，这个其实是一个线性搜索的过程 如果context0(name) != null 成立，说明现有的context里面已经有了一个默认name，那么就从 简单类名#1 往上一直找，直到找到一个唯一的name，比如简单类名#3 如果用户代码在添加Handler的时候指定了一个name，那么要做到事仅仅为检查一下是否有重复 12345private void checkDuplicateName(String name) { if (context0(name) != null) { throw new IllegalArgumentException(\"Duplicate handler name: \" + name); }} 处理完name之后，就进入到创建context的过程，由前面的调用链得知，group为null，因此childExecutor(group)也返回null DefaultChannelPipeline 12345678910private AbstractChannelHandlerContext newContext(EventExecutorGroup group, String name, ChannelHandler handler) { return new DefaultChannelHandlerContext(this, childExecutor(group), name, handler);}private EventExecutor childExecutor(EventExecutorGroup group) { if (group == null) { return null; } //..} DefaultChannelHandlerContext 12345678DefaultChannelHandlerContext( DefaultChannelPipeline pipeline, EventExecutor executor, String name, ChannelHandler handler) { super(pipeline, executor, name, isInbound(handler), isOutbound(handler)); if (handler == null) { throw new NullPointerException(\"handler\"); } this.handler = handler;} 构造函数中，DefaultChannelHandlerContext将参数回传到父类，保存Handler的引用，进入到其父类 AbstractChannelHandlerContext 12345678AbstractChannelHandlerContext(DefaultChannelPipeline pipeline, EventExecutor executor, String name, boolean inbound, boolean outbound) { this.name = ObjectUtil.checkNotNull(name, \"name\"); this.pipeline = pipeline; this.executor = executor; this.inbound = inbound; this.outbound = outbound;} netty中用两个字段来表示这个channelHandlerContext属于inBound还是outBound，或者两者都是，两个boolean是通过下面两个小函数来判断(见上面一段代码) DefaultChannelHandlerContext 1234567private static boolean isInbound(ChannelHandler handler) { return handler instanceof ChannelInboundHandler;}private static boolean isOutbound(ChannelHandler handler) { return handler instanceof ChannelOutboundHandler;} 通过instanceof关键字根据接口类型来判断，因此，如果一个Handler实现了两类接口，那么他既是一个inBound类型的Handler，又是一个outBound类型的Handler，比如下面这个类 常用的，将decode操作和encode操作合并到一起的codec，一般会继承 MessageToMessageCodec，而MessageToMessageCodec就是继承ChannelDuplexHandler MessageToMessageCodec 12345678public abstract class MessageToMessageCodec&lt;INBOUND_IN, OUTBOUND_IN&gt; extends ChannelDuplexHandler { protected abstract void encode(ChannelHandlerContext ctx, OUTBOUND_IN msg, List&lt;Object&gt; out) throws Exception; protected abstract void decode(ChannelHandlerContext ctx, INBOUND_IN msg, List&lt;Object&gt; out) throws Exception; } context 创建完了之后，接下来终于要将创建完毕的context加入到pipeline中去了 添加节点1234567private void addLast0(AbstractChannelHandlerContext newCtx) { AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; // 1 newCtx.next = tail; // 2 prev.next = newCtx; // 3 tail.prev = newCtx; // 4} 用下面这幅图可见简单的表示这段过程，说白了，其实就是一个双向链表的插入操作 操作完毕，该context就加入到pipeline中 到这里，pipeline添加节点的操作就完成了，你可以根据此思路掌握所有的addxxx()系列方法 回调用户方法 AbstractChannelHandlerContext 1234private void callHandlerAdded0(final AbstractChannelHandlerContext ctx) { ctx.handler().handlerAdded(ctx); ctx.setAddComplete();} 到了第四步，pipeline中的新节点添加完成，于是便开始回调用户代码 ctx.handler().handlerAdded(ctx);，常见的用户代码如下 AbstractChannelHandlerContext 1234567public class DemoHandler extends SimpleChannelInboundHandler&lt;...&gt; { @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { // 节点被添加完毕之后回调到此 // do something }} 接下来，设置该节点的状态 AbstractChannelHandlerContext 12345678final void setAddComplete() { for (;;) { int oldState = handlerState; if (oldState == REMOVE_COMPLETE || HANDLER_STATE_UPDATER.compareAndSet(this, oldState, ADD_COMPLETE)) { return; } }} 用cas修改节点的状态至：REMOVE_COMPLETE（说明该节点已经被移除） 或者 ADD_COMPLETE。 pipline删除节点netty 有个最大的特性之一就是Handler可插拔，做到动态编织pipeline，比如在首次建立连接的时候，需要通过进行权限认证，在认证通过之后，就可以将此context移除，下次pipeline在传播事件的时候就就不会调用到权限认证处理器 下面是权限认证Handler最简单的实现，第一个数据包传来的是认证信息，如果校验通过，就删除此Handler，否则，直接关闭连接 1234567891011121314public class AuthHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf data) throws Exception { if (verify(authDataPacket)) { ctx.pipeline().remove(this); } else { ctx.close(); } } private boolean verify(ByteBuf byteBuf) { //... }} 重点就在 ctx.pipeline().remove(this) 这段代码 123456@Overridepublic final ChannelPipeline remove(ChannelHandler handler) { remove(getContextOrDie(handler)); return this;} remove操作相比add简单不少，分为三个步骤： 1.找到待删除的节点 2.调整双向链表指针删除 3.回调用户函数 找到待删除的节点 DefaultChannelPipeline 1234567891011121314151617181920212223242526272829private AbstractChannelHandlerContext getContextOrDie(ChannelHandler handler) { AbstractChannelHandlerContext ctx = (AbstractChannelHandlerContext) context(handler); if (ctx == null) { throw new NoSuchElementException(handler.getClass().getName()); } else { return ctx; }}@Overridepublic final ChannelHandlerContext context(ChannelHandler handler) { if (handler == null) { throw new NullPointerException(\"handler\"); } AbstractChannelHandlerContext ctx = head.next; for (;;) { if (ctx == null) { return null; } if (ctx.handler() == handler) { return ctx; } ctx = ctx.next; }} 这里为了找到Handler对应的context，照样是通过依次遍历双向链表的方式，直到某一个context的Handler和当前Handler相同，便找到了该节点 调整双向链表指针删除 DefaultChannelPipeline 123456789101112131415161718private AbstractChannelHandlerContext remove(final AbstractChannelHandlerContext ctx) { assert ctx != head &amp;&amp; ctx != tail; synchronized (this) { // 2.调整双向链表指针删除 remove0(ctx); } // 3.回调用户函数 callHandlerRemoved0(ctx); return ctx;}private static void remove0(AbstractChannelHandlerContext ctx) { AbstractChannelHandlerContext prev = ctx.prev; AbstractChannelHandlerContext next = ctx.next; prev.next = next; // 1 next.prev = prev; // 2} 经历的过程要比添加节点要简单，可以用下面一幅图来表示 最后的结果为 结合这两幅图，可以很清晰地了解权限验证Handler的工作原理，另外，被删除的节点因为没有对象引用到，果过段时间就会被gc自动回收 回调用户函数1234567private void callHandlerRemoved0(final AbstractChannelHandlerContext ctx) { try { ctx.handler().handlerRemoved(ctx); } finally { ctx.setRemoved(); }} 到了第三步，pipeline中的节点删除完成，于是便开始回调用户代码 ctx.handler().handlerRemoved(ctx);，常见的代码如下 AbstractChannelHandlerContext 1234567public class DemoHandler extends SimpleChannelInboundHandler&lt;...&gt; { @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { // 节点被删除完毕之后回调到此，可做一些资源清理 // do something }} 最后，将该节点的状态设置为removed 123final void setRemoved() { handlerState = REMOVE_COMPLETE;} removexxx系列的其他方法族大同小异，你可以根据上面的思路展开其他的系列方法，这里不再赘述 总结 1.以新连接创建为例，新连接创建的过程中创建channel，而在创建channel的过程中创建了该channel对应的pipeline，创建完pipeline之后，自动给该pipeline添加了两个节点，即ChannelHandlerContext，ChannelHandlerContext中有用pipeline和channel所有的上下文信息。 2.pipeline是双向个链表结构，添加和删除节点均只需要调整链表结构 3.pipeline中的每个节点包着具体的处理器ChannelHandler，节点根据ChannelHandler的类型是ChannelInboundHandler还是ChannelOutboundHandler来判断该节点属于in还是out或者两者都是 Reference netty源码分析之pipeline","link":"/2019/02/18/netty-channelpipeline/"},{"title":"Netty服务端启动流程分析","text":"前言Netty 服务端启动和交互的逻辑的底层实现是借助于Java NIO ServerSocketChannel来实现，Java NIO ServerSocketChannel作为服务端的绑定端口、接受客户端的连接，这篇文章将详细介绍Netty服务端的启动流程，从源码的角度一步步分析。 doBind(final SocketAddress localAddress)方法12345678910111213141516171819202122232425262728293031323334353637private ChannelFuture doBind(final SocketAddress localAddress) { //1.初始化和注册Channel final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); //2.绑定端口 doBind0(regFuture, channel, localAddress, promise); return promise; } else { // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; }} doBind这个函数是我们要分析的重点，这个函数的主要工作有如下几点： 1、通过initAndRegister()方法得到一个ChannelFuture的实例regFuture。 2、通过regFuture.cause()方法判断是否在执行initAndRegister方法时产生来异常。如果产生来异常，则直接返回，如果没有产生异常则进行第3步。 3、通过regFuture.isDone()来判断initAndRegister方法是否执行完毕，如果执行完毕来返回true，然后调用doBind0进行socket绑定。如果没有执行完毕则返回false进行第4步。 4、regFuture会添加一个ChannelFutureListener监听，当initAndRegister执行完成时，调用operationComplete方法并执行doBind0进行socket绑定。 第3、4点想干的事就是一个：调用doBind0方法进行socket绑定。 下面将分成4部分对每行代码具体做了哪些工作进行详细分析。 第1部分，initAndRegister()12345678910111213141516171819202122232425262728293031323334353637383940414243final ChannelFuture initAndRegister() { Channel channel = null; try { //创建一个channel并初始化 channel = channelFactory.newChannel(); //init逻辑，如果是服务端则调用@ServerBootStrap的init方法，如果是客户端则调用Bootstrap的init方法 /** * init逻辑： * 如果是服务端则调用{@link ServerBootstrap#init(Channel channel)}方法， * 如果是客户端则调用{@link Bootstrap#init(Channel channel)}方法 */ init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(\"too many open files\")) channel.unsafe().closeForcibly(); // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); } ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } // If we are here and the promise is not failed, it's one of the following cases: // 1) If we attempted registration from the event loop, the registration has been completed at this point. // i.e. It's safe to attempt bind() or connect() now because the channel has been registered. // 2) If we attempted registration from the other thread, the registration request has been successfully // added to the event loop's task queue for later execution. // i.e. It's safe to attempt bind() or connect() now: // because bind() or connect() will be executed *after* the scheduled registration task is executed // because register(), bind(), and connect() are all bound to the same thread. return regFuture;} 在initAndRegister()函数中，通过函数名字也能看出来主要就三个过程： 1.创建channel 1channel = channelFactory.newChannel(); 2.初始化channel 1init(channel); 3.向group注册channel： 1ChannelFuture regFuture = config().group().register(channel); 下面我们来分别分析下上面的三个过程： 一、创建channel：channelFactory.newChannel();我们知道b.channel(NioServerSocketChannel.class)的功能为：设置父类属性channelFactory为： ReflectiveChannelFactory类的对象。其中这里ReflectiveChannelFactory对象中包括一个clazz属性为：NioServerSocketChannel.class。 因此，channel = channelFactory.newChannel();就是调用的ReflectiveChannelFactory类中的newChannel()方法，该方法的源码为： 12345678@Overridepublic T newChannel() { try { return clazz.getConstructor().newInstance(); } catch (Throwable t) { throw new ChannelException(\"Unable to create Channel from class \" + clazz, t); }} 通过这个方法，我们可以得出结论，是通过反射机制来产生一个NioServerSocketChannel类的实例。 下面将看下NioServerSocketChannel类的构造函数做了哪些工作。 调用它的无参构造函数： 123456/** * Create a new instance */public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER));} 无参构造函数中SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider()。 函数newSocket的功能为：利用SelectorProvider产生一个SocketChannelImpl对象。 123456789101112131415161718private static ServerSocketChannel newSocket(SelectorProvider provider) { try { /** * Use the {@link SelectorProvider} to open {@link SocketChannel} and so remove condition in * {@link SelectorProvider#provider()} which is called by each ServerSocketChannel.open() otherwise. * * See &lt;a href=\"https://github.com/netty/netty/issues/2308\"&gt;#2308&lt;/a&gt;. */ return provider.openServerSocketChannel(); } catch (IOException e) { throw new ChannelException( \"Failed to open a server socket.\", e); }}public ServerSocketChannel openServerSocketChannel() throws IOException { return new ServerSocketChannelImpl(this);} 然后继续调用有参构造函数以及父类的构造函数，调用过程如下： 1234567/** * Create a new instance using the given {@link ServerSocketChannel}. */public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());} 父类AbstractNioMessageChannel构造函数 123456/** * @see AbstractNioChannel#AbstractNioChannel(Channel, SelectableChannel, int) */protected AbstractNioMessageChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent, ch, readInterestOp);} 父类AbstractNioChannel构造函数 1234567891011121314151617181920212223242526/** * Create a new instance * * @param parent the parent {@link Channel} by which this instance was created. May be {@code null} * @param ch the underlying {@link SelectableChannel} on which it operates * @param readInterestOp the ops to set to receive data from the {@link SelectableChannel} */protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try { ch.configureBlocking(false); } catch (IOException e) { try { ch.close(); } catch (IOException e2) { if (logger.isWarnEnabled()) { logger.warn( \"Failed to close a partially initialized socket.\", e2); } } throw new ChannelException(\"Failed to enter non-blocking mode.\", e); }} 父类AbstractChannel构造函数 123456789101112/** * Creates a new instance. * * @param parent * the parent of this channel. {@code null} if there's no parent. */protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();} 通过分析NioServerSocketChannel实例化过程，调用那么多的构造函数其实主要干了五件事情： 1、产生来一个SocketChannelImpl类的实例，并设置为非阻塞的 1ch.configureBlocking(false); 2、设置了config属性 1config = new NioServerSocketChannelConfig(this, javaChannel().socket()); 3、设置SelectionKey.OP_ACCEPT事件 1this.readInterestOp = readInterestOp;//SelectionKey.OP_ACCEPT 4、设置unsafe属性 12345unsafe = newUnsafe();@Overrideprotected AbstractNioUnsafe newUnsafe() { return new NioMessageUnsafe();} 主要作用为：用来负责底层的connect、register、read和write等操作。 5、设置pipeline属性 1pipeline = new DefaultChannelPipeline(this); 每个Channel都有自己的pipeline，当有请求事件发生时，pipeline负责调用相应的hander进行处理。 这些属性在后面都会用到，至于NioServerSocketChannel 对象中的unsafe、pipeline属性的具体实现后面进行分析。 结论：final Channel channel = channelFactory().newChannel();这行代码的作用为通过反射产生来一个NioServerSocketChannel类的实例，其中这个NioServerSocketChannel类对象有这样几个属性：SocketChannel、NioServerSocketChannelConfig 、SelectionKey.OP_ACCEPT事件、NioMessageUnsafe、DefaultChannelPipeline 二、初始化channel：init(channel);因为这篇文章是分析Netty服务端的启动流程，因此会进入ServerBootstrap#init()方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Overridevoid init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) { setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(\"unchecked\") AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) { currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); } synchronized (childAttrs) { currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); } p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } });} 该函数的功能主要功能包括如下几点： 1.设置channel的options 1private final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = new LinkedHashMap&lt;ChannelOption&lt;?&gt;, Object&gt;(); options可能如下： 1234567891011121314151617181920212223242526272829public &lt;T&gt; boolean setOption(ChannelOption&lt;T&gt; option, T value) { validate(option, value); if (option == CONNECT_TIMEOUT_MILLIS) { setConnectTimeoutMillis((Integer) value); } else if (option == MAX_MESSAGES_PER_READ) { setMaxMessagesPerRead((Integer) value); } else if (option == WRITE_SPIN_COUNT) { setWriteSpinCount((Integer) value); } else if (option == ALLOCATOR) { setAllocator((ByteBufAllocator) value); } else if (option == RCVBUF_ALLOCATOR) { setRecvByteBufAllocator((RecvByteBufAllocator) value); } else if (option == AUTO_READ) { setAutoRead((Boolean) value); } else if (option == AUTO_CLOSE) { setAutoClose((Boolean) value); } else if (option == WRITE_BUFFER_HIGH_WATER_MARK) { setWriteBufferHighWaterMark((Integer) value); } else if (option == WRITE_BUFFER_LOW_WATER_MARK) { setWriteBufferLowWaterMark((Integer) value); } else if (option == MESSAGE_SIZE_ESTIMATOR) { setMessageSizeEstimator((MessageSizeEstimator) value); } else { return false; } return true;} 2.设置channel的attrs 如果没有设置，则attrs为空，该属性在ServerBootstrap类中的定义如下 1private final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = new LinkedHashMap&lt;AttributeKey&lt;?&gt;, Object&gt;(); 3.设置handler到channel的pipeline上 12345final ChannelPipeline pipeline = ch.pipeline();ChannelHandler handler = config.handler();if (handler != null) { pipeline.addLast(handler);} 4.在pipeline上添加来一个ChannelInitializer对象，其中重写来initChannel方法。该方法通过p.addLast()向serverChannel的流水线处理器中加入了一个 ServerBootstrapAcceptor 从名字上就可以看出来，这是一个接入器，专门接受新请求，把新的请求扔给某个事件循环器 1234567ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); }}); 看到这里，我们发现其实init只是初始化了一些基本的配置和属性，以及在pipeline上加入了一个接入器，用来专门接受新连接，并没有启动服务. 看到这里，我们发现其实init只是初始化了一些基本的配置和属性，以及在pipeline上加入了一个接入器，用来专门接受新连接，并没有启动服务. 三、注册channel：config().group().register(channel);前面的分析我们知道group为：NioEvenLoopGroup，其继承MultithreadEventLoopGroup，该类中的register方法如下： 1234@Overridepublic ChannelFuture register(Channel channel) { return next().register(channel);} next()方法的代码如下，其功能为选择下一个NioEventLoop对象，这里的next方法调用了父类MultithreadEventExecutorGroup的next方法 1234@Overridepublic EventExecutor next() { return chooser.next();} NioEventLoopGroup分析中，我们在MultithreadEventExecutorGroup类的构造函数中看到：根据线程个数nThreads是否为2的幂次方来选择chooser，其中这两个chooser为： PowerOfTwoEventExecutorChooser、GenericEventExecutorChooser。 小结：由于NioEventLoopGroup中维护着多个NioEventLoop，next方法回调用chooser策略找到下一个NioEventLoop，并执行该对象的register方法进行注册。 由于NioEventLoop extends SingleThreadEventLoop，NioEventLoop没有重写该方法，因此看 SingleThreadEventLoop类中的register方法： 1234567891011@Overridepublic ChannelFuture register(Channel channel) { return register(new DefaultChannelPromise(channel, this));}@Overridepublic ChannelFuture register(final ChannelPromise promise) { ObjectUtil.checkNotNull(promise, \"promise\"); promise.channel().unsafe().register(this, promise); return promise;} 。。。。。。 因此，channel.unsafe().register(this, promise)这行代码调用的是AbstractUnsafe类中的register方法，具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637@Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) { if (eventLoop == null) { throw new NullPointerException(\"eventLoop\"); } if (isRegistered()) { promise.setFailure(new IllegalStateException(\"registered to an event loop already\")); return; } if (!isCompatible(eventLoop)) { promise.setFailure( new IllegalStateException(\"incompatible event loop type: \" + eventLoop.getClass().getName())); return; } AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) { register0(promise); } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { logger.warn( \"Force-closing a channel whose registration task was not accepted by an event loop: {}\", AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); } }} register()方法的核心实现思路为： 1、通过调用eventLoop.inEventLoop()方法判断当前线程是否为该EventLoop中拥有的线程，如果是，则直接注册，如果不是，说明该EventLoop在等待并没有执行权，则进行第2步。 AbstractEventExecutor 1234@Overridepublic boolean inEventLoop() { return inEventLoop(Thread.currentThread());} SingleThreadEventExecutor 1234@Overridepublic boolean inEventLoop(Thread thread) { return thread == this.thread;} 2、既然该EventLoop中的线程此时没有执行权，但是我们可以提交一个任务到该线程中，等该EventLoop的线程有执行权的时候就自然而然的会执行此任务，而该任务负责调用register0方法，这样也就达到了调用register0方法的目的。具体为：任务OneTimeTask子类被提交到NioEventLoop线程中执行，然后调用此任务的run方法，进而调用register0方法，其中promise = new DefaultChannelPromise(channel, this)。 下面看register0()这个方法，具体实现如下： 1234567891011121314151617181920212223242526272829303132333435363738private void register0(ChannelPromise promise) { try { // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) { if (firstRegistration) { pipeline.fireChannelActive(); } else if (config().isAutoRead()) { // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); } } } catch (Throwable t) { // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); }} 在上面的代码中，是通过调用doRegister()方法完成NioServerSocketChannel的注册，该方法的具体代码如下： 123456789101112131415161718192021@Overrideprotected void doRegister() throws Exception { boolean selected = false; for (;;) { try { selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { // Force the Selector to select now as the \"canceled\" SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; } else { // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; } } }} 第2部分，doBind0(regFuture, channel, localAddress, promise)1234567891011121314151617private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) { // This method is invoked before channelRegistered() is triggered. Give user handlers a chance to set up // the pipeline in its channelRegistered() implementation. channel.eventLoop().execute(new Runnable() { @Override public void run() { if (regFuture.isSuccess()) { channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } });} 会执行channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE)这行代码，这行代码完成的功能为：实现channel与端口的绑定。 AbstractChannel 1234@Overridepublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) { return pipeline.bind(localAddress, promise);} 在该方法中直接调用了pipeline的bind方法，通过前面的分析我们知道这里的pipeline是DefaultChannelPipeline的实例。 1234@Overridepublic final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) { return tail.bind(localAddress, promise);} 继续看tail实例的bind()方法，调用的是TailContext的父类AbstractChannelHandlerContext的bind()方法 123456789101112131415161718192021222324@Overridepublic ChannelFuture bind(final SocketAddress localAddress, final ChannelPromise promise) { if (localAddress == null) { throw new NullPointerException(\"localAddress\"); } if (isNotValidPromise(promise, false)) { // cancelled return promise; } final AbstractChannelHandlerContext next = findContextOutbound(); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeBind(localAddress, promise); } else { safeExecute(executor, new Runnable() { @Override public void run() { next.invokeBind(localAddress, promise); } }, promise, null); } return promise;} 上面bind函数中的这行代码：final AbstractChannelHandlerContext next = findContextOutbound();所完成的任务就是在pipeline所持有的以AbstractChannelHandlerContext为节点的双向链表中从尾节点tail开始向前寻找第一个outbound=true的handler节点。 findContextOutbound方法找到的 AbstractChannelHandlerContext 对象其实就是 head。然后调用invokeBind()方法： 1234567891011private void invokeBind(SocketAddress localAddress, ChannelPromise promise) { if (invokeHandler()) { try { ((ChannelOutboundHandler) handler()).bind(this, localAddress, promise); } catch (Throwable t) { notifyOutboundHandlerException(t, promise); } } else { bind(localAddress, promise); }} 继续调用HeadContext类的bind()方法： 123456@Overridepublic void bind( ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception { unsafe.bind(localAddress, promise);} 通过前面的分析我们知道unsafe是NioMessageUnsafe的示例，bind方法是继承自AbstractUnsafe类： 1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic final void bind(final SocketAddress localAddress, final ChannelPromise promise) { assertEventLoop(); if (!promise.setUncancellable() || !ensureOpen(promise)) { return; } // See: https://github.com/netty/netty/issues/576 if (Boolean.TRUE.equals(config().getOption(ChannelOption.SO_BROADCAST)) &amp;&amp; localAddress instanceof InetSocketAddress &amp;&amp; !((InetSocketAddress) localAddress).getAddress().isAnyLocalAddress() &amp;&amp; !PlatformDependent.isWindows() &amp;&amp; !PlatformDependent.maybeSuperUser()) { // Warn a user about the fact that a non-root user can't receive a // broadcast packet on *nix if the socket is bound on non-wildcard address. logger.warn( \"A non-root user can't receive a broadcast packet if the socket \" + \"is not bound to a wildcard address; binding to a non-wildcard \" + \"address (\" + localAddress + \") anyway as requested.\"); } boolean wasActive = isActive(); try { doBind(localAddress); } catch (Throwable t) { safeSetFailure(promise, t); closeIfClosed(); return; } if (!wasActive &amp;&amp; isActive()) { invokeLater(new Runnable() { @Override public void run() { pipeline.fireChannelActive(); } }); } safeSetSuccess(promise);} 上面的核心代码就是：doBind(localAddress);需要注意的是，此doBind方法是在NioServerSocketChannel类中的doBind方法，不是其他类中的。 NioServerSocketChannel类中的doBind方法代码如下： 12345678@Overrideprotected void doBind(SocketAddress localAddress) throws Exception { if (PlatformDependent.javaVersion() &gt;= 7) { javaChannel().bind(localAddress, config.getBacklog()); } else { javaChannel().socket().bind(localAddress, config.getBacklog()); }} 上面方法中javaChannel()方法返回的是NioServerSocketChannel实例初始化时所产生的Java NIO ServerSocketChannel实例（更具体点为ServerSocketChannelImple实例）。 等价于语句serverSocketChannel.socket().bind(localAddress)完成了指定端口的绑定，这样就开始监听此端口。 __如果对Java NIO层面的服务端绑定端口对端口的监听、客户端的连接以及交互不太清晰，可以看博文Java NIO 之 ServerSocketChannel/SocketChannel __，这里介绍了 Java NIO 层面的服务端对端口的监听、客户端与服务端之间的连接以及客户端于服务端之间的交互。 说到这里本来应该就结束了，但是还有如下的一点需要说明：即绑定端口成功后，是这里调用了我们自定义handler的channelActive方法。更多可以结合博文： 这样就真正的完成了端口的绑定。在绑定之前，isActive()方法返回false，绑定之后返回true。 这样就进入了如下的if条件的代码块中： 12345678if (!wasActive &amp;&amp; isActive()) { invokeLater(new Runnable() { @Override public void run() { pipeline.fireChannelActive(); } });} 进而开始执行 pipeline.fireChannelActive();这行代码 ，这行代码的具体调用链如下所示： 12DefaultChannelPipeline#fireChannelActive(); ---&gt; AbstractChannelHandlerContext#invokeChannelActive() 总结整个流程还是挺复杂的，把Netty服务端的启动流程大体梳理了一遍，还有很多小细节没有具体分析，在接下来的学习过程中我还会继续完善这篇文章。 REFERENCES Netty源码分析：服务端启动全过程","link":"/2019/01/24/netty-server-side-bootstrap-process/"},{"title":"Dubbo SPI机制源码分析","text":"Dubbo是微内核架构，还是开闭原则的应用，把核心流程架构固定，但是流程的各个节点对重新改进是开放的。具体的实现机制就是SPI(Service Provider Interface)机制，Dubbo基于Java SPI机制（不了解Java SPI机制的可以参考这篇文章《深入理解Java SPI机制》），在其基础上做了改进和扩展。 根据SPI规范，接口由框架定义，具体实现可以由不同的厂商提供，在Dubbo jar包可以发现在/META-INF/dubbo/internal目录下有许多接口命名的文件，文件里面的内容就是文件名代表的接口的各种实现类，这就是Dubbo SPI机制的配置基础，以org.apache.dubbo.rpc.Protocol文件为例，内容如下（dubbo-2.7.0-SNAPSHOT 版本）： 12345678910111213141516filter=org.apache.dubbo.rpc.protocol.ProtocolFilterWrapperlistener=org.apache.dubbo.rpc.protocol.ProtocolListenerWrappermock=org.apache.dubbo.rpc.support.MockProtocoldubbo=org.apache.dubbo.rpc.protocol.dubbo.DubboProtocolinjvm=org.apache.dubbo.rpc.protocol.injvm.InjvmProtocolrmi=org.apache.dubbo.rpc.protocol.rmi.RmiProtocolhessian=org.apache.dubbo.rpc.protocol.hessian.HessianProtocolhttp=org.apache.dubbo.rpc.protocol.http.HttpProtocolorg.apache.dubbo.rpc.protocol.webservice.WebServiceProtocolthrift=org.apache.dubbo.rpc.protocol.thrift.ThriftProtocolmemcached=org.apache.dubbo.rpc.protocol.memcached.MemcachedProtocolredis=org.apache.dubbo.rpc.protocol.redis.RedisProtocolrest=org.apache.dubbo.rpc.protocol.rest.RestProtocolregistry=org.apache.dubbo.registry.integration.RegistryProtocolqos=org.apache.dubbo.qos.protocol.QosProtocolWrapper 在Dubbo SPI机制中，org.apache.dubbo.rpc.Protocol接口由以上那么多的具体实现，=前面是扩展名，后面是扩展类的实现； SPI的启动的入口类是ExtensionLoader，这个类没定义public构造函数，只有一个privae的，而且public的静态方法也只有一个public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type)，这个方法也是SPI的入口方法，若想获取某个接口类型的扩展，先必须获取其对应的ExtensionLoader 12345678910111213141516171819202122232425262728293031323334//私有构造器private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; //objectFactory 对象 ，ExtensionFactory本身也是spi的 //如果是ExtensionFactory本身的ExtensionLoader实例，objectFactory字段为null //否则，是ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()；关于getAdaptiveExtension()方法返回的实例，后面会看到 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());}private static &lt;T&gt; boolean withExtensionAnnotation(Class&lt;T&gt; type) { return type.isAnnotationPresent(SPI.class);}//获取某个接口的ExtensionLoader@SuppressWarnings(\"unchecked\")public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) { if (type == null) throw new IllegalArgumentException(\"Extension type == null\"); if (!type.isInterface()) { throw new IllegalArgumentException(\"Extension type(\" + type + \") is not interface!\"); } //判断接口是否有SPI注解，Dubbo里所有需要SPI扩展的接口都需要添加@SPI注解 if (!withExtensionAnnotation(type)) { throw new IllegalArgumentException(\"Extension type(\" + type + \") is not extension, because WITHOUT @\" + SPI.class.getSimpleName() + \" Annotation!\"); } //判断是否已经存在 ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) { //利用私有构造器创建ExtensionLoader，并且放入缓存 EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); } return loader;} 创建了ExtensionLoader实例，我们就可以通过SPI机制获取想要的接口扩展类实例了，下面就以org.apache.dubbo.rpc.Protocol接口获取名为Dubbo的扩展实例为例： 1ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(DubboProtocol.NAME); 跟进getExtension方法： 12345678910111213141516171819202122232425262728293031323334/** * Find the extension with the given name. If the specified name is not found, then {@link IllegalStateException} * will be thrown. */@SuppressWarnings(\"unchecked\")public T getExtension(String name) { if (name == null || name.length() == 0) throw new IllegalArgumentException(\"Extension name == null\"); //获取默认扩展 if (\"true\".equals(name)) { return getDefaultExtension(); } //指定扩展实例，判断是否已经缓存 Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) { //创建Holder实例，放入缓存 cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); } Object instance = holder.get(); //加锁技巧，保证线程安全 if (instance == null) { synchronized (holder) { instance = holder.get(); if (instance == null) { //根据扩展名，获取具体扩展实例，放入缓存holder中 instance = createExtension(name); holder.set(instance); } } } //返回具体的扩展实例 return (T) instance;} 这里有两个获取扩展的相关方法，一个是getDefaultExtension()获取默认扩展，另一个是createExtension(name)根据扩展名获取扩展实例，下面分析这两个方法的具体实现： 12345678910111213141516171819202122232425262728293031323334353637383940/*** * 这个方法，总结起来有3个步骤， * 1，通过扩展名，找到扩展实现类，这过程可能触发spi文件加载解析 * 2，利用反射机制，获取扩展类实例，并完成依赖注入 * 3，如果接口扩展有包装类，实例化包装类 * 最后返回经由以上3步流程后，产生的对象。 * 这3步，前一步都是后一步的基础，要顺序完成 */@SuppressWarnings(\"unchecked\")private T createExtension(String name) { //根据扩展名，获取扩展实现类的class（完成第1步） Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) { throw findException(name); } try { //从缓存里，获取实现类的实例 T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { //利用newInstance()反射，构造类实例，病放入缓存 EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } //完成接口实现类依赖注入，依赖组件先从SPI机制构造查找，再从Spring容器查找（完成第2步） injectExtension(instance); //如果这接口的实现，还有wrapper类，（有接口类型的构造函数） //还有把当前实例instance，注入到包装类，包装类有多个，依次层层，循环构造注入 //最后返回的是，最后一个包装类实例，这也是dubbo的aop实现机制（完成第3步） Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) { for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } return instance; } catch (Throwable t) { throw new IllegalStateException(\"Extension instance(name: \" + name + \", class: \" + type + \") could not be instantiated: \" + t.getMessage(), t); }} 第一步，加载扩展实现类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//获取某个接口所有实现，按照扩展名：扩展实现，存储在map中private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() { Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) { synchronized (cachedClasses) { classes = cachedClasses.get(); if (classes == null) { classes = loadExtensionClasses(); cachedClasses.set(classes); } } } return classes;}// synchronized in getExtensionClasses//加载类路径中的spi配置文件，构造cachedClassesprivate Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() { final SPI defaultAnnotation = type.getAnnotation(SPI.class); //获取spi 注解 SPI(value=\"xxx\")，默认实现xxx if (defaultAnnotation != null) { String value = defaultAnnotation.value(); if ((value = value.trim()).length() &gt; 0) { String[] names = NAME_SEPARATOR.split(value); //默认实现只能有一个 if (names.length &gt; 1) { throw new IllegalStateException(\"more than 1 default extension name on extension \" + type.getName() + \": \" + Arrays.toString(names)); } //获取spi默认实现值 if (names.length == 1) cachedDefaultName = names[0]; } } Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;(); //读取三个目录下的spi 配置文件;/META-INF/dubbo/internal, /META-INF/dubbo, /META-INF/services //构造 扩展名:实现类 map loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName()); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); return extensionClasses;}private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir, String type) { //拼接接口名作为文件名，例如：/META-INF/dubbo/internal/org.apache.dubbo.rpc.Protocol String fileName = dir + type; try { Enumeration&lt;java.net.URL&gt; urls; //获取加载ClassLoader类的类加载器 ClassLoader classLoader = findClassLoader(); if (classLoader != null) { urls = classLoader.getResources(fileName); } else { urls = ClassLoader.getSystemResources(fileName); } if (urls != null) { while (urls.hasMoreElements()) { java.net.URL resourceURL = urls.nextElement(); //加载资源 loadResource(extensionClasses, classLoader, resourceURL); } } } catch (Throwable t) { logger.error(\"Exception when load extension class(interface: \" + type + \", description file: \" + fileName + \").\", t); }} 我们继续来看loadResource()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL) { try { BufferedReader reader = new BufferedReader(new InputStreamReader(resourceURL.openStream(), \"utf-8\")); try { String line; //读取文件每一行 while ((line = reader.readLine()) != null) { final int ci = line.indexOf('#'); if (ci &gt;= 0) line = line.substring(0, ci); line = line.trim(); if (line.length() &gt; 0) { try { String name = null; int i = line.indexOf('='); if (i &gt; 0) { //name 是扩展名 name = line.substring(0, i).trim(); //扩展实现类全名 line = line.substring(i + 1).trim(); } if (line.length() &gt; 0) { //根据line加载类 loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name); } } catch (Throwable t) { IllegalStateException e = new IllegalStateException(\"Failed to load extension class(interface: \" + type + \", class line: \" + line + \") in \" + resourceURL + \", cause: \" + t.getMessage(), t); exceptions.put(line, e); } } } } finally { reader.close(); } } catch (Throwable t) { logger.error(\"Exception when load extension class(interface: \" + type + \", class file: \" + resourceURL + \") in \" + resourceURL, t); }}private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name) throws NoSuchMethodException { //盘判断实现类是否实现了type接口 if (!type.isAssignableFrom(clazz)) { throw new IllegalStateException(\"Error when load extension class(interface: \" + type + \", class line: \" + clazz.getName() + \"), class \" + clazz.getName() + \"is not subtype of interface.\"); } //判断实现类是否有Adaptive注解 if (clazz.isAnnotationPresent(Adaptive.class)) { if (cachedAdaptiveClass == null) { //赋值 cachedAdaptiveClass = clazz; } else if (!cachedAdaptiveClass.equals(clazz)) { //一个接口的SPI实现，只能有一个实现类是Adaptive的 throw new IllegalStateException(\"More than 1 adaptive class found: \" + cachedAdaptiveClass.getClass().getName() + \", \" + clazz.getClass().getName()); } } else if (isWrapperClass(clazz)) { //判断是否为包装类 //一个接口的SPI实现可以有多个包装类 Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) { cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; } wrappers.add(clazz); } else { clazz.getConstructor(); if (name == null || name.length() == 0) { name = findAnnotationName(clazz); if (name.length() == 0) { throw new IllegalStateException(\"No such extension name for the class \" + clazz.getName() + \" in the config \" + resourceURL); } } String[] names = NAME_SEPARATOR.split(name); if (names != null &amp;&amp; names.length &gt; 0) { //？？？ //实现类是否有Active注解 Activate activate = clazz.getAnnotation(Activate.class); if (activate != null) { //如果有，加入cachedActivates map（扩展名：实现类class） cachedActivates.put(names[0], activate); } else { // support com.alibaba.dubbo.common.extension.Activate com.alibaba.dubbo.common.extension.Activate oldActivate = clazz.getAnnotation(com.alibaba.dubbo.common.extension.Activate.class); if (oldActivate != null) { cachedActivates.put(names[0], oldActivate); } } for (String n : names) { if (!cachedNames.containsKey(clazz)) { //实现类:扩展名 map 放入缓存 cachedNames.put(clazz, n); } Class&lt;?&gt; c = extensionClasses.get(n); if (c == null) { //Adaptive 和wapper类都不在extensionClasses里!!! extensionClasses.put(n, clazz); } else if (c != clazz) { throw new IllegalStateException(\"Duplicate extension \" + type.getName() + \" name \" + n + \" on \" + c.getName() + \" and \" + clazz.getName()); } } } }}private boolean isWrapperClass(Class&lt;?&gt; clazz) { try { //实现类里，是否有，参数是接口类型的（比如 com.alibaba.dubbo.rpc.Protocol类型，并且1个参数）的构造函数 //表示它是个接口包装类 clazz.getConstructor(type); return true; } catch (NoSuchMethodException e) { return false; }} 第二步，依赖注入流程分析首先来看injectExtension(T instance)的实现： 123456789101112131415161718192021222324252627282930313233//实例对象，字段依赖注入。字段类型可以是spi 接口类型，或者是Spring bean 类型// 依赖注入的字段对象，是通过ExtensionLoader的objectFactory属性完成的，// objectFacotry 会根据先后通过spi机制和从spring 容器里获取属性对象并注入。// objectFactory 是在ExtensionLoader私有构造函数中赋值private T injectExtension(T instance) { try { if (objectFactory != null) { for (Method method : instance.getClass().getMethods()) { if (method.getName().startsWith(\"set\") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) { //获取所有public类型，并且只有一个参数的以set开头的方法 Class&lt;?&gt; pt = method.getParameterTypes()[0]; try { //根据驼峰命名法，根据方法名，构造set方法要赋值的属性名 String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : \"\"; //通过getExtension的方法获取属性对象，所以还要看getExtension的实现。 Object object = objectFactory.getExtension(pt, property); if (object != null) { //利用反射机制，赋值对象属性 method.invoke(instance, object); } } catch (Exception e) { logger.error(\"fail to inject via method \" + method.getName() + \" of interface \" + type.getName() + \": \" + e.getMessage(), e); } } } } } catch (Exception e) { logger.error(e.getMessage(), e); } return instance;} 看下ExtensionLoader定义的私有构造函数，可以看到objectFactory是通过ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()赋值的，它是ExtensionFactory接口的Adaptive扩展实现，看下getAdaptiveExtension()方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//获取一个SPI接口的Adaptive(实现类有Adaptive注解的)类型扩展实现public T getAdaptiveExtension() { //先取缓存 Object instance = cachedAdaptiveInstance.get(); if (instance == null) { if (createAdaptiveInstanceError == null) { synchronized (cachedAdaptiveInstance) { instance = cachedAdaptiveInstance.get(); if (instance == null) { try { //缓存不在，就创建Adaptive扩展实例 instance = createAdaptiveExtension(); //对象放入缓存中 cachedAdaptiveInstance.set(instance); } catch (Throwable t) { createAdaptiveInstanceError = t; throw new IllegalStateException(\"fail to create adaptive instance: \" + t.toString(), t); } } } } else { throw new IllegalStateException(\"fail to create adaptive instance: \" + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); } } return (T) instance;}@SuppressWarnings(\"unchecked\")private T createAdaptiveExtension() { try { //获取AdaptiveExtensionClass的class 通过反射获取实例，同时要走依赖注入流程 //AdaptiveExtensionClass 已在spi 文件解析时赋值 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); } catch (Exception e) { throw new IllegalStateException(\"Can not create adaptive extension \" + type + \", cause: \" + e.getMessage(), e); }}private Class&lt;?&gt; getAdaptiveExtensionClass() { //如果有必要，触发spi加载流程， //找到类上有Adaptive注解的class,赋值给cachedAdaptiveClass getExtensionClasses(); if (cachedAdaptiveClass != null) { return cachedAdaptiveClass; } //Adaptive注解不在扩展实现类上，而是在待扩展接口方法上 //这种情况，就是dubbo动态生成生成java类字串，动态编译生成想要的class //这个下面再分析下 return cachedAdaptiveClass = createAdaptiveExtensionClass();} 目前ExtensionFactory接口3个实现类，只有AdaptiveExtensionFactory类是Adaptive的： 123456789101112131415161718192021222324252627282930/** * AdaptiveExtensionFactory */@Adaptivepublic class AdaptiveExtensionFactory implements ExtensionFactory { private final List&lt;ExtensionFactory&gt; factories; //无参构造函数中，把其他实现类实例加入到factories list中 public AdaptiveExtensionFactory() { ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class); List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;(); //getSupportedExtensions()返回的是 非包装类扩展，非Adaptive扩展，防止无限循环 for (String name : loader.getSupportedExtensions()) { list.add(loader.getExtension(name)); } factories = Collections.unmodifiableList(list); } @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) { for (ExtensionFactory factory : factories) { T extension = factory.getExtension(type, name); if (extension != null) { return extension; } } return null; }} 另外两个实现类是SpiExtensionFactory、SpringExtensionFactory： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * SpiExtensionFactory */public class SpiExtensionFactory implements ExtensionFactory { //SPI机制获取type扩展接口 @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) { if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) { ExtensionLoader&lt;T&gt; loader = ExtensionLoader.getExtensionLoader(type); if (!loader.getSupportedExtensions().isEmpty()) { //获取的是接口的Adaptive实现 return loader.getAdaptiveExtension(); } } return null; }}/** * SpringExtensionFactory */public class SpringExtensionFactory implements ExtensionFactory { private static final Logger logger = LoggerFactory.getLogger(SpringExtensionFactory.class); private static final Set&lt;ApplicationContext&gt; contexts = new ConcurrentHashSet&lt;ApplicationContext&gt;(); //手动将spring容器传入 public static void addApplicationContext(ApplicationContext context) { contexts.add(context); } public static void removeApplicationContext(ApplicationContext context) { contexts.remove(context); } // currently for test purpose public static void clearContexts() { contexts.clear(); } @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) { //SPI should be get from SpiExtensionFactory if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) { return null; } //遍历spring容器 for (ApplicationContext context : contexts) { if (context.containsBean(name)) { Object bean = context.getBean(name); if (type.isInstance(bean)) { return (T) bean; } } } logger.warn(\"No spring extension(bean) named:\" + name + \", try to find an extension(bean) of type \" + type.getName()); for (ApplicationContext context : contexts) { try { return context.getBean(type); } catch (NoUniqueBeanDefinitionException multiBeanExe) { throw multiBeanExe; } catch (NoSuchBeanDefinitionException noBeanExe) { if (logger.isDebugEnabled()) { logger.debug(\"Error when get spring extension(bean) for type:\" + type.getName(), noBeanExe); } } } logger.warn(\"No spring extension(bean) named:\" + name + \", type:\" + type.getName() + \" found, stop get bean.\"); return null; }} 第三步，实例化包装类流程分析代码上面createExtension方法里已贴出，为了更好的理解，我们可以看下Protocol接口的实现中，ProtocolFIlterWrapper和ProtocolListenerWrapper两个包装类，可以看到他们都有参数为Protocol类型的public构造函数，实例化时，把上层的protocol对象作为参数传入构造函数作为内部属性，同时包装类本身会实现Protocol接口，所以这就可以做些类似aop的操作，如ProtocolFilterWrapper： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * ListenerProtocol */public class ProtocolFilterWrapper implements Protocol { private final Protocol protocol; public ProtocolFilterWrapper(Protocol protocol) { if (protocol == null) { throw new IllegalArgumentException(\"protocol == null\"); } this.protocol = protocol; } //实例化过滤器链 private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) { Invoker&lt;T&gt; last = invoker; List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (!filters.isEmpty()) { for (int i = filters.size() - 1; i &gt;= 0; i--) { final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() { @Override public Class&lt;T&gt; getInterface() { return invoker.getInterface(); } @Override public URL getUrl() { return invoker.getUrl(); } @Override public boolean isAvailable() { return invoker.isAvailable(); } @Override public Result invoke(Invocation invocation) throws RpcException { return filter.invoke(next, invocation); } @Override public void destroy() { invoker.destroy(); } @Override public String toString() { return invoker.toString(); } }; } } return last; } @Override public int getDefaultPort() { return protocol.getDefaultPort(); } //暴露过程前执行过滤器链 @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException { if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) { return protocol.export(invoker); } return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER)); } //调用前执行过滤器链 @Override public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { return protocol.refer(type, url); } return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER); } @Override public void destroy() { protocol.destroy(); }} 到此Dubbo SPI机制的三个步骤分析完了。 上面提到的Adaptive类的另一种配置方式，即Adaptive注解配置在方法上，dubbo里，配置Adaptive类有两种方式，一种在就扣实现里，类本身有Adaptive注解，还有一种配置实在接口定义的方法级上有Adaptive注解，这两种方式第一种优先，没有第一种，dubbo自动完成第二种Adaptive类的生成，以Protocol接口为例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@SPI(\"dubbo\")public interface Protocol { /** * 获取缺省端口，当用户没有配置端口时使用。 * * @return 缺省端口 */ int getDefaultPort(); /** * 暴露远程服务：&lt;br&gt; * 1. 协议在接收请求时，应记录请求来源方地址信息：RpcContext.getContext().setRemoteAddress();&lt;br&gt; * 2. export()必须是幂等的，也就是暴露同一个URL的Invoker两次，和暴露一次没有区别。&lt;br&gt; * 3. export()传入的Invoker由框架实现并传入，协议不需要关心。&lt;br&gt; * * @param &lt;T&gt; 服务的类型 * @param invoker 服务的执行体 * @return exporter 暴露服务的引用，用于取消暴露 * @throws RpcException 当暴露服务出错时抛出，比如端口已占用 */ @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; /** * 引用远程服务：&lt;br&gt; * 1. 当用户调用refer()所返回的Invoker对象的invoke()方法时，协议需相应执行同URL远端export()传入的Invoker对象的invoke()方法。&lt;br&gt; * 2. refer()返回的Invoker由协议实现，协议通常需要在此Invoker中发送远程请求。&lt;br&gt; * 3. 当url中有设置check=false时，连接失败不能抛出异常，并内部自动恢复。&lt;br&gt; * * @param &lt;T&gt; 服务的类型 * @param type 服务的类型 * @param url 远程服务的URL地址 * @return invoker 服务的本地代理 * @throws RpcException 当连接服务提供方失败时抛出 */ @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; /** * 释放协议：&lt;br&gt; * 1. 取消该协议所有已经暴露和引用的服务。&lt;br&gt; * 2. 释放协议所占用的所有资源，比如连接和端口。&lt;br&gt; * 3. 协议在释放后，依然能暴露和引用新的服务。&lt;br&gt; */ void destroy();} 在export和refer方法上所有Adaptive注解，根据上面的分析，我们跟踪一下createAdaptiveExtensionClass方法： 123456789private Class&lt;?&gt; createAdaptiveExtensionClass() { //生成Adaptive；类源码 String code = createAdaptiveExtensionClassCode(); ClassLoader classLoader = findClassLoader(); //通过SPI获取java 编译器 org.apache.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(org.apache.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); //编译源码返回class return compiler.compile(code, classLoader);} createAdaptiveExtensionClassCode();方法就是实现字符串拼接, 不同的接口，生成的code会有不同，默认使用javassist对代码进行编译。 这里贴出Protocal生成的Adaptive类的源代码。体现的思想是，所谓Adaptive方法，其实现，内部的对象类型都是参数（url）和spi机制动态决定的。 1234567891011121314151617181920212223242526272829303132333435package org.apache.dubbo.rpc;import org.apache.dubbo.common.extension.ExtensionLoader;public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol { public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException { if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); } public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); } public void destroy() { throw new UnsupportedOperationException(\"method public abstract void org.apache.dubbo.rpc.Protocol.destroy() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); } public int getDefaultPort() { throw new UnsupportedOperationException(\"method public abstract int org.apache.dubbo.rpc.Protocol.getDefaultPort() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); }}","link":"/2018/08/09/dubbo-spi-analysis/"},{"title":"基于Spring构建Dubbo源码分析","text":"从Dubbo 2.7.0的项目依赖来看，依赖的Spring Framework版本是4.3.16.RELEASE： 12345678910&lt;properties&gt; &lt;spring_version&gt;4.3.16.RELEASE&lt;/spring_version&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-framework-bom&lt;/artifactId&gt; &lt;version&gt;${spring_version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; Dubbo是基于Spring构建和运行的，兼容Spring配置，Dubbo利用了SpringFramework的Extensible XML authoring 特性，扩展了Spring标签，关于如何利用Spring扩展标签，可以参考官方文档 《Extensible XML authoring》： 编写xml，描述需要扩展的标签的配置属性，dubbo实现放在jar包META-INF/dubbo.xsd文件里 同时通过编写META-INF/spring.handlers文件，提供给spring，内容如下： 12http\\://dubbo.apache.org/schema/dubbo=org.apache.dubbo.config.spring.schema.DubboNamespaceHandlerhttp\\://code.alibabatech.com/schema/dubbo=org.apache.dubbo.config.spring.schema.DubboNamespaceHandler 编写一个NamespaceHandler接口实现类，dubbo中的实现类是DubboNamespaceHandler，同时通过编写META-INF/spring.schemas文件提供给Spring，内容如下： 12http\\://dubbo.apache.org/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsdhttp\\://code.alibabatech.com/schema/dubbo/dubbo.xsd=META-INF/compat/dubbo.xsd 编写一个或多个BeanDefinitionParser实现类，用来解析扩展的元素，Dubbo实现类是DubboBeanDefinitionParaser 把以上解析组件注册给Spring 解析DubboNamespaceHandler实现首先来看一下DubboNamespaceHandler类的源代码： 12345678910111213141516171819202122public class DubboNamespaceHandler extends NamespaceHandlerSupport { static { Version.checkDuplicate(DubboNamespaceHandler.class); } @Override public void init() { //注册每个标签对应的解析类 registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser(\"annotation\", new AnnotationBeanDefinitionParser()); }} 上面提到的10个扩展标签，分别对应10个配置类，类的层次关系如下图(右键–&gt;Open image in new tab)： 如上图可以看出，主要基类是AbstractConfig和AbstractMethodConfig，而AbstractConfig又是所有类的基类，这10个配置类中ReferenceBean，ServiceBean，AnnotationBean 3个类又都实现了若干spring接口，这3个类算是利用spring完成dubbo调用的驱动类，后面要分别看源码。 解析DubboBeanDefinitionParser类这个类实现了BeanDefinitionParser接口，这是个Spring的原生接口，里面只有一个方法： 12345678910111213141516171819public interface BeanDefinitionParser { /** * Parse the specified {@link Element} and register the resulting * {@link BeanDefinition BeanDefinition(s)} with the * {@link org.springframework.beans.factory.xml.ParserContext#getRegistry() BeanDefinitionRegistry} * embedded in the supplied {@link ParserContext}. * &lt;p&gt;Implementations must return the primary {@link BeanDefinition} that results * from the parse if they will ever be used in a nested fashion (for example as * an inner tag in a {@code &lt;property/&gt;} tag). Implementations may return * {@code null} if they will &lt;strong&gt;not&lt;/strong&gt; be used in a nested fashion. * @param element the element that is to be parsed into one or more {@link BeanDefinition BeanDefinitions} * @param parserContext the object encapsulating the current state of the parsing process; * provides access to a {@link org.springframework.beans.factory.support.BeanDefinitionRegistry} * @return the primary {@link BeanDefinition} */ BeanDefinition parse(Element element, ParserContext parserContext);} 根据接口的定义，这个方法实现，需要解析Element元素成原生的BeanDefinition类对象，然后利用ParserContext对象的getRegistry()返回的注册器来注册解析后的BeanDefinition类的对象，最后返回这个BeanDefination类对象，下面是Dubbo的实现，主要是完成Spring配置到Spring容器内部BeanDefination转化的过程，下面来分析parse()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177@SuppressWarnings(\"unchecked\")private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) { RootBeanDefinition beanDefinition = new RootBeanDefinition(); beanDefinition.setBeanClass(beanClass); beanDefinition.setLazyInit(false); String id = element.getAttribute(\"id\"); if ((id == null || id.length() == 0) &amp;&amp; required) { String generatedBeanName = element.getAttribute(\"name\"); if (generatedBeanName == null || generatedBeanName.length() == 0) { if (ProtocolConfig.class.equals(beanClass)) { generatedBeanName = \"dubbo\"; } else { generatedBeanName = element.getAttribute(\"interface\"); } } if (generatedBeanName == null || generatedBeanName.length() == 0) { generatedBeanName = beanClass.getName(); } id = generatedBeanName; int counter = 2; while (parserContext.getRegistry().containsBeanDefinition(id)) { id = generatedBeanName + (counter++); } } if (id != null &amp;&amp; id.length() &gt; 0) { if (parserContext.getRegistry().containsBeanDefinition(id)) { throw new IllegalStateException(\"Duplicate spring bean id \" + id); } parserContext.getRegistry().registerBeanDefinition(id, beanDefinition); beanDefinition.getPropertyValues().addPropertyValue(\"id\", id); } if (ProtocolConfig.class.equals(beanClass)) { for (String name : parserContext.getRegistry().getBeanDefinitionNames()) { BeanDefinition definition = parserContext.getRegistry().getBeanDefinition(name); PropertyValue property = definition.getPropertyValues().getPropertyValue(\"protocol\"); if (property != null) { Object value = property.getValue(); if (value instanceof ProtocolConfig &amp;&amp; id.equals(((ProtocolConfig) value).getName())) { definition.getPropertyValues().addPropertyValue(\"protocol\", new RuntimeBeanReference(id)); } } } } else if (ServiceBean.class.equals(beanClass)) { String className = element.getAttribute(\"class\"); if (className != null &amp;&amp; className.length() &gt; 0) { RootBeanDefinition classDefinition = new RootBeanDefinition(); classDefinition.setBeanClass(ReflectUtils.forName(className)); classDefinition.setLazyInit(false); parseProperties(element.getChildNodes(), classDefinition); beanDefinition.getPropertyValues().addPropertyValue(\"ref\", new BeanDefinitionHolder(classDefinition, id + \"Impl\")); } } else if (ProviderConfig.class.equals(beanClass)) { parseNested(element, parserContext, ServiceBean.class, true, \"service\", \"provider\", id, beanDefinition); } else if (ConsumerConfig.class.equals(beanClass)) { parseNested(element, parserContext, ReferenceBean.class, false, \"reference\", \"consumer\", id, beanDefinition); } Set&lt;String&gt; props = new HashSet&lt;String&gt;(); ManagedMap parameters = null; for (Method setter : beanClass.getMethods()) { String name = setter.getName(); if (name.length() &gt; 3 &amp;&amp; name.startsWith(\"set\") &amp;&amp; Modifier.isPublic(setter.getModifiers()) &amp;&amp; setter.getParameterTypes().length == 1) { Class&lt;?&gt; type = setter.getParameterTypes()[0]; String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), \"-\"); props.add(property); Method getter = null; try { getter = beanClass.getMethod(\"get\" + name.substring(3), new Class&lt;?&gt;[0]); } catch (NoSuchMethodException e) { try { getter = beanClass.getMethod(\"is\" + name.substring(3), new Class&lt;?&gt;[0]); } catch (NoSuchMethodException e2) { } } if (getter == null || !Modifier.isPublic(getter.getModifiers()) || !type.equals(getter.getReturnType())) { continue; } if (\"parameters\".equals(property)) { parameters = parseParameters(element.getChildNodes(), beanDefinition); } else if (\"methods\".equals(property)) { parseMethods(id, element.getChildNodes(), beanDefinition, parserContext); } else if (\"arguments\".equals(property)) { parseArguments(id, element.getChildNodes(), beanDefinition, parserContext); } else { String value = element.getAttribute(property); if (value != null) { value = value.trim(); if (value.length() &gt; 0) { if (\"registry\".equals(property) &amp;&amp; RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(value)) { RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress(RegistryConfig.NO_AVAILABLE); beanDefinition.getPropertyValues().addPropertyValue(property, registryConfig); } else if (\"registry\".equals(property) &amp;&amp; value.indexOf(',') != -1) { parseMultiRef(\"registries\", value, beanDefinition, parserContext); } else if (\"provider\".equals(property) &amp;&amp; value.indexOf(',') != -1) { parseMultiRef(\"providers\", value, beanDefinition, parserContext); } else if (\"protocol\".equals(property) &amp;&amp; value.indexOf(',') != -1) { parseMultiRef(\"protocols\", value, beanDefinition, parserContext); } else { Object reference; if (isPrimitive(type)) { if (\"async\".equals(property) &amp;&amp; \"false\".equals(value) || \"timeout\".equals(property) &amp;&amp; \"0\".equals(value) || \"delay\".equals(property) &amp;&amp; \"0\".equals(value) || \"version\".equals(property) &amp;&amp; \"0.0.0\".equals(value) || \"stat\".equals(property) &amp;&amp; \"-1\".equals(value) || \"reliable\".equals(property) &amp;&amp; \"false\".equals(value)) { // backward compatibility for the default value in old version's xsd value = null; } reference = value; } else if (\"protocol\".equals(property) &amp;&amp; ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(value) &amp;&amp; (!parserContext.getRegistry().containsBeanDefinition(value) || !ProtocolConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) { if (\"dubbo:provider\".equals(element.getTagName())) { logger.warn(\"Recommended replace &lt;dubbo:provider protocol=\\\"\" + value + \"\\\" ... /&gt; to &lt;dubbo:protocol name=\\\"\" + value + \"\\\" ... /&gt;\"); } // backward compatibility ProtocolConfig protocol = new ProtocolConfig(); protocol.setName(value); reference = protocol; } else if (\"onreturn\".equals(property)) { int index = value.lastIndexOf(\".\"); String returnRef = value.substring(0, index); String returnMethod = value.substring(index + 1); reference = new RuntimeBeanReference(returnRef); beanDefinition.getPropertyValues().addPropertyValue(\"onreturnMethod\", returnMethod); } else if (\"onthrow\".equals(property)) { int index = value.lastIndexOf(\".\"); String throwRef = value.substring(0, index); String throwMethod = value.substring(index + 1); reference = new RuntimeBeanReference(throwRef); beanDefinition.getPropertyValues().addPropertyValue(\"onthrowMethod\", throwMethod); } else if (\"oninvoke\".equals(property)) { int index = value.lastIndexOf(\".\"); String invokeRef = value.substring(0, index); String invokeRefMethod = value.substring(index + 1); reference = new RuntimeBeanReference(invokeRef); beanDefinition.getPropertyValues().addPropertyValue(\"oninvokeMethod\", invokeRefMethod); } else { if (\"ref\".equals(property) &amp;&amp; parserContext.getRegistry().containsBeanDefinition(value)) { BeanDefinition refBean = parserContext.getRegistry().getBeanDefinition(value); if (!refBean.isSingleton()) { throw new IllegalStateException(\"The exported service ref \" + value + \" must be singleton! Please set the \" + value + \" bean scope to singleton, eg: &lt;bean id=\\\"\" + value + \"\\\" scope=\\\"singleton\\\" ...&gt;\"); } } reference = new RuntimeBeanReference(value); } beanDefinition.getPropertyValues().addPropertyValue(property, reference); } } } } } } NamedNodeMap attributes = element.getAttributes(); int len = attributes.getLength(); for (int i = 0; i &lt; len; i++) { Node node = attributes.item(i); String name = node.getLocalName(); if (!props.contains(name)) { if (parameters == null) { parameters = new ManagedMap(); } String value = node.getNodeValue(); parameters.put(name, new TypedStringValue(value, String.class)); } } if (parameters != null) { beanDefinition.getPropertyValues().addPropertyValue(\"parameters\", parameters); } return beanDefinition;} ReferenceBean类ReferenceBean类主要完成早适当的时机（Spring Bean初始化完成或者用户通过Spring容器获取bean）根据服务调用方法配置，生成服务调用代理工作，ReferenceBean类继承如下： 可以看到ReferenceBean实现了FactoryBean、ApplicationContextAware、FactoryBean、InitializingBean及DisposableBean四个接口，通过Spring的回调机制，完成Spring容器的传入，获取Bean类型，Bean初始化和Destory定制等操作，ReferenceBean类里的具体实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140//实现ApplicationContextAware接口的方法，在bean初始化时，回传bean所在容器的引用@Overridepublic void setApplicationContext(ApplicationContext applicationContext) { this.applicationContext = applicationContext; SpringExtensionFactory.addApplicationContext(applicationContext);}//实现FactoryBean接口的方法，返回一个Bean实例，在使用Spring API从容器中获取一个bean时调用，//这里返回的是reference的代理的代理类实例@Overridepublic Object getObject() throws Exception { return get();}//实现FactoryBean接口的方法，返回一个bean的类型@Overridepublic Class&lt;?&gt; getObjectType() { return getInterfaceClass();}//实现FactoryBean接口的方法，返回一个bean是否是单例@Override@Parameter(excluded = true)public boolean isSingleton() { return true;}//实现InitializingBean的接口方法，在bean所有属性都赋值后，由spring回调执行//这个方法里可以做些初始化定制@Override@SuppressWarnings({\"unchecked\"})public void afterPropertiesSet() throws Exception { if (getConsumer() == null) { //BeanFactoryUtils.beansOfTypeIncludingAncestors()是Spring的一个工具类 //返回指定容器里，ConsumerConfig.class类及其子类的Bean，如果还没初始化，会触发初始化的过程，依赖注入的概念a Map&lt;String, ConsumerConfig&gt; consumerConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ConsumerConfig.class, false, false); if (consumerConfigMap != null &amp;&amp; consumerConfigMap.size() &gt; 0) { ConsumerConfig consumerConfig = null; //遍历map，默认设置ConsumerConfig for (ConsumerConfig config : consumerConfigMap.values()) { if (config.isDefault() == null || config.isDefault().booleanValue()) { if (consumerConfig != null) { throw new IllegalStateException(\"Duplicate consumer configs: \" + consumerConfig + \" and \" + config); } consumerConfig = config; } } //设置ConsumerConfig if (consumerConfig != null) { setConsumer(consumerConfig); } } } //设置ApplicationConfig if (getApplication() == null &amp;&amp; (getConsumer() == null || getConsumer().getApplication() == null)) { Map&lt;String, ApplicationConfig&gt; applicationConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ApplicationConfig.class, false, false); if (applicationConfigMap != null &amp;&amp; applicationConfigMap.size() &gt; 0) { ApplicationConfig applicationConfig = null; for (ApplicationConfig config : applicationConfigMap.values()) { if (config.isDefault() == null || config.isDefault().booleanValue()) { if (applicationConfig != null) { throw new IllegalStateException(\"Duplicate application configs: \" + applicationConfig + \" and \" + config); } applicationConfig = config; } } if (applicationConfig != null) { setApplication(applicationConfig); } } } //设置ModuleConfig if (getModule() == null &amp;&amp; (getConsumer() == null || getConsumer().getModule() == null)) { Map&lt;String, ModuleConfig&gt; moduleConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ModuleConfig.class, false, false); if (moduleConfigMap != null &amp;&amp; moduleConfigMap.size() &gt; 0) { ModuleConfig moduleConfig = null; for (ModuleConfig config : moduleConfigMap.values()) { if (config.isDefault() == null || config.isDefault().booleanValue()) { if (moduleConfig != null) { throw new IllegalStateException(\"Duplicate module configs: \" + moduleConfig + \" and \" + config); } moduleConfig = config; } } if (moduleConfig != null) { setModule(moduleConfig); } } } //设置注册中心 if ((getRegistries() == null || getRegistries().isEmpty()) &amp;&amp; (getConsumer() == null || getConsumer().getRegistries() == null || getConsumer().getRegistries().isEmpty()) &amp;&amp; (getApplication() == null || getApplication().getRegistries() == null || getApplication().getRegistries().isEmpty())) { //多个注册中心 Map&lt;String, RegistryConfig&gt; registryConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, RegistryConfig.class, false, false); if (registryConfigMap != null &amp;&amp; registryConfigMap.size() &gt; 0) { List&lt;RegistryConfig&gt; registryConfigs = new ArrayList&lt;RegistryConfig&gt;(); for (RegistryConfig config : registryConfigMap.values()) { if (config.isDefault() == null || config.isDefault().booleanValue()) { registryConfigs.add(config); } } if (registryConfigs != null &amp;&amp; !registryConfigs.isEmpty()) { super.setRegistries(registryConfigs); } } } //设置监控中心 if (getMonitor() == null &amp;&amp; (getConsumer() == null || getConsumer().getMonitor() == null) &amp;&amp; (getApplication() == null || getApplication().getMonitor() == null)) { Map&lt;String, MonitorConfig&gt; monitorConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, MonitorConfig.class, false, false); if (monitorConfigMap != null &amp;&amp; monitorConfigMap.size() &gt; 0) { MonitorConfig monitorConfig = null; for (MonitorConfig config : monitorConfigMap.values()) { if (config.isDefault() == null || config.isDefault().booleanValue()) { if (monitorConfig != null) { throw new IllegalStateException(\"Duplicate monitor configs: \" + monitorConfig + \" and \" + config); } monitorConfig = config; } } if (monitorConfig != null) { setMonitor(monitorConfig); } } } //是否bean创建后就初始化代理 Boolean b = isInit(); if (b == null &amp;&amp; getConsumer() != null) { b = getConsumer().isInit(); } if (b != null &amp;&amp; b.booleanValue()) //立即初始化代理 getObject(); }}//DisposableBean的方法，做销毁处理@Overridepublic void destroy() { // do nothing} ServiceBean类ServiceBean类主要完成在适当时机（Spring容器初始化完成或者服务实例初始化完成）根据服务提供方的配置暴露发布服务的工作，ServiceBean类继承关系如下： 可以看到ServiceBean及其基类实现了BeanNameAware、ApplicationContextAware、ApplicationListener、DisposableBean、InitializingBean接口，通过Spring回调机制完成Spring容器引用传入，bean初始化和destory过程定制，以及监听并处理Spring事件的操作，ServiceBean类具体实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205//传入bean所在容器的引用@Overridepublic void setApplicationContext(ApplicationContext applicationContext) { this.applicationContext = applicationContext; //把Spring容器传入SpringExtensionFactory SpringExtensionFactory.addApplicationContext(applicationContext); //获取容易addApplicationListener方法，把当前类加入到容器监听队列 if (applicationContext != null) { SPRING_CONTEXT = applicationContext; try { Method method = applicationContext.getClass().getMethod(\"addApplicationListener\", ApplicationListener.class); // backward compatibility to spring 2.0.1 method.invoke(applicationContext, this); supportedApplicationListener = true; } catch (Throwable t) { if (applicationContext instanceof AbstractApplicationContext) { try { Method method = AbstractApplicationContext.class.getDeclaredMethod(\"addListener\", ApplicationListener.class); // backward compatibility to spring 2.0.1 if (!method.isAccessible()) { method.setAccessible(true); } method.invoke(applicationContext, this); //设置监听器后设为true supportedApplicationListener = true; } catch (Throwable t2) { } } } }}//设置beanName值@Overridepublic void setBeanName(String name) { this.beanName = name;}/** * Gets associated {@link Service} * * @return associated {@link Service} */public Service getService() { return service;}//实现ApplicationListener接口方法，接受并处理在容器初始化完成时发布的ContextRefreshedEvent事件//即容器初始化完成后暴露服务@Overridepublic void onApplicationEvent(ContextRefreshedEvent event) { if (isDelay() &amp;&amp; !isExported() &amp;&amp; !isUnexported()) { if (logger.isInfoEnabled()) { logger.info(\"The service ready on spring started. service: \" + getInterface()); } //执行暴露过程 export(); }}//判断是否延迟暴露private boolean isDelay() { Integer delay = getDelay(); ProviderConfig provider = getProvider(); if (delay == null &amp;&amp; provider != null) { delay = provider.getDelay(); } return supportedApplicationListener &amp;&amp; (delay == null || delay == -1);}//InitializinBean接口方法，Bean属性初始化后，操作处理@Override@SuppressWarnings({\"unchecked\", \"deprecation\"})public void afterPropertiesSet() throws Exception { // 设置ProviderConfig if (getProvider() == null) { Map&lt;String, ProviderConfig&gt; providerConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProviderConfig.class, false, false); if (providerConfigMap != null &amp;&amp; providerConfigMap.size() &gt; 0) { Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false); if ((protocolConfigMap == null || protocolConfigMap.size() == 0) &amp;&amp; providerConfigMap.size() &gt; 1) { // backward compatibility List&lt;ProviderConfig&gt; providerConfigs = new ArrayList&lt;ProviderConfig&gt;(); for (ProviderConfig config : providerConfigMap.values()) { if (config.isDefault() != null &amp;&amp; config.isDefault()) { providerConfigs.add(config); } } if (!providerConfigs.isEmpty()) { setProviders(providerConfigs); } } else { ProviderConfig providerConfig = null; for (ProviderConfig config : providerConfigMap.values()) { if (config.isDefault() == null || config.isDefault()) { if (providerConfig != null) { throw new IllegalStateException(\"Duplicate provider configs: \" + providerConfig + \" and \" + config); } providerConfig = config; } } if (providerConfig != null) { setProvider(providerConfig); } } } } //设置ApplicationConfig if (getApplication() == null &amp;&amp; (getProvider() == null || getProvider().getApplication() == null)) { Map&lt;String, ApplicationConfig&gt; applicationConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ApplicationConfig.class, false, false); if (applicationConfigMap != null &amp;&amp; applicationConfigMap.size() &gt; 0) { ApplicationConfig applicationConfig = null; for (ApplicationConfig config : applicationConfigMap.values()) { if (config.isDefault() == null || config.isDefault()) { if (applicationConfig != null) { throw new IllegalStateException(\"Duplicate application configs: \" + applicationConfig + \" and \" + config); } applicationConfig = config; } } if (applicationConfig != null) { setApplication(applicationConfig); } } } //设置模块 if (getModule() == null &amp;&amp; (getProvider() == null || getProvider().getModule() == null)) { Map&lt;String, ModuleConfig&gt; moduleConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ModuleConfig.class, false, false); if (moduleConfigMap != null &amp;&amp; moduleConfigMap.size() &gt; 0) { ModuleConfig moduleConfig = null; for (ModuleConfig config : moduleConfigMap.values()) { if (config.isDefault() == null || config.isDefault()) { if (moduleConfig != null) { throw new IllegalStateException(\"Duplicate module configs: \" + moduleConfig + \" and \" + config); } moduleConfig = config; } } if (moduleConfig != null) { setModule(moduleConfig); } } } //设置注册中心 if ((getRegistries() == null || getRegistries().isEmpty()) &amp;&amp; (getProvider() == null || getProvider().getRegistries() == null || getProvider().getRegistries().isEmpty()) &amp;&amp; (getApplication() == null || getApplication().getRegistries() == null || getApplication().getRegistries().isEmpty())) { Map&lt;String, RegistryConfig&gt; registryConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, RegistryConfig.class, false, false); if (registryConfigMap != null &amp;&amp; registryConfigMap.size() &gt; 0) { List&lt;RegistryConfig&gt; registryConfigs = new ArrayList&lt;RegistryConfig&gt;(); for (RegistryConfig config : registryConfigMap.values()) { if (config.isDefault() == null || config.isDefault()) { registryConfigs.add(config); } } if (!registryConfigs.isEmpty()) { super.setRegistries(registryConfigs); } } } //设置监控中心 if (getMonitor() == null &amp;&amp; (getProvider() == null || getProvider().getMonitor() == null) &amp;&amp; (getApplication() == null || getApplication().getMonitor() == null)) { Map&lt;String, MonitorConfig&gt; monitorConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, MonitorConfig.class, false, false); if (monitorConfigMap != null &amp;&amp; monitorConfigMap.size() &gt; 0) { MonitorConfig monitorConfig = null; for (MonitorConfig config : monitorConfigMap.values()) { if (config.isDefault() == null || config.isDefault()) { if (monitorConfig != null) { throw new IllegalStateException(\"Duplicate monitor configs: \" + monitorConfig + \" and \" + config); } monitorConfig = config; } } if (monitorConfig != null) { setMonitor(monitorConfig); } } } //服务协议，可以有多个 if ((getProtocols() == null || getProtocols().isEmpty()) &amp;&amp; (getProvider() == null || getProvider().getProtocols() == null || getProvider().getProtocols().isEmpty())) { Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false); if (protocolConfigMap != null &amp;&amp; protocolConfigMap.size() &gt; 0) { List&lt;ProtocolConfig&gt; protocolConfigs = new ArrayList&lt;ProtocolConfig&gt;(); for (ProtocolConfig config : protocolConfigMap.values()) { if (config.isDefault() == null || config.isDefault()) { protocolConfigs.add(config); } } if (!protocolConfigs.isEmpty()) { super.setProtocols(protocolConfigs); } } } //设置服务路径（类全名） if (getPath() == null || getPath().length() == 0) { if (beanName != null &amp;&amp; beanName.length() &gt; 0 &amp;&amp; getInterface() != null &amp;&amp; getInterface().length() &gt; 0 &amp;&amp; beanName.startsWith(getInterface())) { setPath(beanName); } } //是否延迟暴露 if (!isDelay()) { //暴露服务 export(); }} AnnotationBean类这个类使得dubbo具有自动包扫描功能支持dubbo通过注解配置service和Reference bean（有些属性不能注解配置），病完成ServiceBean和ReferenceBean相同的功能，类图如下： 可以看到AnnotationBean类实现了接口DisposableBean、BeanFactoryPostProcessor、BeanPostProcessor、ApplicationContextAware，同样用过Spring接口方法回调，实现Bean实例的初始化预处理。 AnnotationBean类是基于ClassPathBeanDefinationScanner类实现的，看下org.springframework.context.annotation.ClassPathBeanDefinationScanner类官方解释ClassPathBeanDefinationScanner： 1234A bean definition scanner that detects bean candidates on the classpath, registering corresponding bean definitions with a given registry (BeanFactory or ApplicationContext).Candidate classes are detected through configurable type filters. The default filters include classes that are annotated with Spring&apos;s @Component, @Repository, @Service, or @Controller stereotype.Also supports Java EE 6&apos;s ManagedBean and JSR-330&apos;s Named annotations, if available. 大概意思就是，ClassPathBeanDefinitionScanner将会扫描classpath下的bean，并且向注册器注册（BeanFactory或者ApplicationContext）bean definition，通过配置的过滤器检测bean，默认会检测被@Component, @Repository, @Service, or @Controller注解的类。 下面来分析AnnotationBean类的核心代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266//设置扫描的包名，以逗号分隔包名public void setPackage(String annotationPackage) { this.annotationPackage = annotationPackage; this.annotationPackages = (annotationPackage == null || annotationPackage.length() == 0) ? null : Constants.COMMA_SPLIT_PATTERN.split(annotationPackage);}//实现Spring回调接口方法，传入容器引用@Overridepublic void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext;}//实现BeanFactoryPostProcessor接口，这个方法会在所有的bean definitions已加载，但是还没有实例化之前回调执行//可以在Bean初始化之前定制化一些操作，这里做的是调用org.springframework.context.annotation.ClassPathBeanDefinitionScanner的scan方法//扫描注册由Service(Dubbo定义)注解的Bean，都是用反射完成的@Overridepublic void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { if (annotationPackage == null || annotationPackage.length() == 0) { return; } if (beanFactory instanceof BeanDefinitionRegistry) { try { // init scanner //利用反射构造ClassPathBeanDefinitionScanner实例，用的这个构造方法， // useDefaultFilters=true 默认扫描 spring 4种的注解 // public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters) { // this(registry, useDefaultFilters, getOrCreateEnvironment(registry)); // } Class&lt;?&gt; scannerClass = ReflectUtils.forName(\"org.springframework.context.annotation.ClassPathBeanDefinitionScanner\"); Object scanner = scannerClass.getConstructor(new Class&lt;?&gt;[]{BeanDefinitionRegistry.class, boolean.class}).newInstance((BeanDefinitionRegistry) beanFactory, true); // add filter //通过filter 添加新要扫描的注解，也是用的反射 这里是 AnnotationTypeFilte Class&lt;?&gt; filterClass = ReflectUtils.forName(\"org.springframework.core.type.filter.AnnotationTypeFilter\"); Object filter = filterClass.getConstructor(Class.class).newInstance(Service.class); //获取添加filter的方法，并调用 Method addIncludeFilter = scannerClass.getMethod(\"addIncludeFilter\", ReflectUtils.forName(\"org.springframework.core.type.filter.TypeFilter\")); addIncludeFilter.invoke(scanner, filter); // scan packages //获取ClassPathBeanDefinitionScanner的scan()方法，开始扫描 String[] packages = Constants.COMMA_SPLIT_PATTERN.split(annotationPackage); Method scan = scannerClass.getMethod(\"scan\", String[].class); scan.invoke(scanner, new Object[]{packages}); } catch (Throwable e) { // spring 2.0 } }}//实现DisposableBean接口，在bean析构时，调用相关方法，释放资源@Overridepublic void destroy() { // This will only be called for singleton scope bean, and expected to be called by spring shutdown hook when BeanFactory/ApplicationContext destroys. // We will guarantee dubbo related resources being released with dubbo shutdown hook. // for (ServiceConfig&lt;?&gt; serviceConfig : serviceConfigs) { // try { // serviceConfig.unexport(); // } catch (Throwable e) { // logger.error(e.getMessage(), e); // } // } for (ReferenceConfig&lt;?&gt; referenceConfig : referenceConfigs.values()) { try { referenceConfig.destroy(); } catch (Throwable e) { logger.error(e.getMessage(), e); } }}//实现BeanPostProcessor接口方法，在Bean初始化之后，比如在afterPropertiesSet后由Spring回调执行//这个方法完成类似ServiceBean的工作@Overridepublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { //检查是否匹配包名 if (!isMatchPackage(bean)) { return bean; } //手动创建ServiceBean并暴露服务 Service service = bean.getClass().getAnnotation(Service.class); if (service != null) { ServiceBean&lt;Object&gt; serviceConfig = new ServiceBean&lt;Object&gt;(service); serviceConfig.setRef(bean); if (void.class.equals(service.interfaceClass()) &amp;&amp; \"\".equals(service.interfaceName())) { if (bean.getClass().getInterfaces().length &gt; 0) { serviceConfig.setInterface(bean.getClass().getInterfaces()[0]); } else { throw new IllegalStateException(\"Failed to export remote service class \" + bean.getClass().getName() + \", cause: The @Service undefined interfaceClass or interfaceName, and the service class unimplemented any interfaces.\"); } } if (applicationContext != null) { serviceConfig.setApplicationContext(applicationContext); if (service.registry().length &gt; 0) { List&lt;RegistryConfig&gt; registryConfigs = new ArrayList&lt;RegistryConfig&gt;(); for (String registryId : service.registry()) { if (registryId != null &amp;&amp; registryId.length() &gt; 0) { registryConfigs.add(applicationContext.getBean(registryId, RegistryConfig.class)); } } serviceConfig.setRegistries(registryConfigs); } if (service.provider().length() &gt; 0) { serviceConfig.setProvider(applicationContext.getBean(service.provider(), ProviderConfig.class)); } if (service.monitor().length() &gt; 0) { serviceConfig.setMonitor(applicationContext.getBean(service.monitor(), MonitorConfig.class)); } if (service.application().length() &gt; 0) { serviceConfig.setApplication(applicationContext.getBean(service.application(), ApplicationConfig.class)); } if (service.module().length() &gt; 0) { serviceConfig.setModule(applicationContext.getBean(service.module(), ModuleConfig.class)); } if (service.provider().length() &gt; 0) { serviceConfig.setProvider(applicationContext.getBean(service.provider(), ProviderConfig.class)); } if (service.protocol().length &gt; 0) { List&lt;ProtocolConfig&gt; protocolConfigs = new ArrayList&lt;ProtocolConfig&gt;(); for (String protocolId : service.protocol()) { if (protocolId != null &amp;&amp; protocolId.length() &gt; 0) { protocolConfigs.add(applicationContext.getBean(protocolId, ProtocolConfig.class)); } } serviceConfig.setProtocols(protocolConfigs); } if (service.tag().length() &gt; 0) { serviceConfig.setTag(service.tag()); } try { serviceConfig.afterPropertiesSet(); } catch (RuntimeException e) { throw e; } catch (Exception e) { throw new IllegalStateException(e.getMessage(), e); } } serviceConfigs.add(serviceConfig); serviceConfig.export(); } return bean;}//实现BeanPostProcessor接口方法，在Bean初始化前，比如在afterPropertiesSet前，由Spring回调执行//这个方法完成类似ReferenceBean的工作@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { if (!isMatchPackage(bean)) { return bean; } //因为Dubbo Reference注解只能在类的字段或者方法上 //通过Bean的set方法上找dubbo注解 Method[] methods = bean.getClass().getMethods(); for (Method method : methods) { String name = method.getName(); if (name.length() &gt; 3 &amp;&amp; name.startsWith(\"set\") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers()) &amp;&amp; !Modifier.isStatic(method.getModifiers())) { try { Reference reference = method.getAnnotation(Reference.class); if (reference != null) { Object value = refer(reference, method.getParameterTypes()[0]); if (value != null) { method.invoke(bean, value); } } } catch (Throwable e) { logger.error(\"Failed to init remote service reference at method \" + name + \" in class \" + bean.getClass().getName() + \", cause: \" + e.getMessage(), e); } } } //通过bean的字段上找dubbo注解 Field[] fields = bean.getClass().getDeclaredFields(); for (Field field : fields) { try { if (!field.isAccessible()) { field.setAccessible(true); } Reference reference = field.getAnnotation(Reference.class); if (reference != null) { Object value = refer(reference, field.getType()); if (value != null) { field.set(bean, value); } } } catch (Throwable e) { logger.error(\"Failed to init remote service reference at filed \" + field.getName() + \" in class \" + bean.getClass().getName() + \", cause: \" + e.getMessage(), e); } } return bean;}//通过解析Reference注解里的值，去构造服务调用配置，最后调用创建代理的方法private Object refer(Reference reference, Class&lt;?&gt; referenceClass) { //method.getParameterTypes()[0] String interfaceName; if (!\"\".equals(reference.interfaceName())) { interfaceName = reference.interfaceName(); } else if (!void.class.equals(reference.interfaceClass())) { interfaceName = reference.interfaceClass().getName(); } else if (referenceClass.isInterface()) { interfaceName = referenceClass.getName(); } else { throw new IllegalStateException(\"The @Reference undefined interfaceClass or interfaceName, and the property type \" + referenceClass.getName() + \" is not a interface.\"); } String key = reference.group() + \"/\" + interfaceName + \":\" + reference.version(); ReferenceBean&lt;?&gt; referenceConfig = referenceConfigs.get(key); if (referenceConfig == null) { referenceConfig = new ReferenceBean&lt;Object&gt;(reference); if (void.class.equals(reference.interfaceClass()) &amp;&amp; \"\".equals(reference.interfaceName()) &amp;&amp; referenceClass.isInterface()) { referenceConfig.setInterface(referenceClass); } if (applicationContext != null) { referenceConfig.setApplicationContext(applicationContext); if (reference.registry().length &gt; 0) { List&lt;RegistryConfig&gt; registryConfigs = new ArrayList&lt;RegistryConfig&gt;(); for (String registryId : reference.registry()) { if (registryId != null &amp;&amp; registryId.length() &gt; 0) { registryConfigs.add(applicationContext.getBean(registryId, RegistryConfig.class)); } } referenceConfig.setRegistries(registryConfigs); } if (reference.consumer().length() &gt; 0) { referenceConfig.setConsumer(applicationContext.getBean(reference.consumer(), ConsumerConfig.class)); } if (reference.monitor().length() &gt; 0) { referenceConfig.setMonitor(applicationContext.getBean(reference.monitor(), MonitorConfig.class)); } if (reference.application().length() &gt; 0) { referenceConfig.setApplication(applicationContext.getBean(reference.application(), ApplicationConfig.class)); } if (reference.module().length() &gt; 0) { referenceConfig.setModule(applicationContext.getBean(reference.module(), ModuleConfig.class)); } if (reference.consumer().length() &gt; 0) { referenceConfig.setConsumer(applicationContext.getBean(reference.consumer(), ConsumerConfig.class)); } try { referenceConfig.afterPropertiesSet(); } catch (RuntimeException e) { throw e; } catch (Exception e) { throw new IllegalStateException(e.getMessage(), e); } } referenceConfigs.putIfAbsent(key, referenceConfig); referenceConfig = referenceConfigs.get(key); } return referenceConfig.get();}private boolean isMatchPackage(Object bean) { if (annotationPackages == null || annotationPackages.length == 0) { return true; } String beanClassName = bean.getClass().getName(); for (String pkg : annotationPackages) { if (beanClassName.startsWith(pkg)) { return true; } } return false;}","link":"/2018/08/13/dubbo-basing-on-spring-framework-analysis/"},{"title":"Dubbo服务提供者发布及注册过程源码分析","text":"Dubbo服务端在启动服务时会经历怎样的调用过程？在收到消费者发送的请求后会经历怎样的调用过程？这篇文章主要针对以上两个调用过程并结合Dubbo源码进行分析。 我们采用的是Consumer-Provider的Demo提供的示例，并按照《Dubbo消费者调用过程源码分析》中的分析思路，下面将对两种过程进行进一步分析，先来看一张服务发布过程的时序图(图片太大建议在新的窗口打开查看)，对服务发布与注册有个大致的了解： Dubbo服务发布过程首先来看一下服务发布过程调用栈，我们将围绕这个调用栈一步步进行分析： 12345678910111213141516171819202122232425262728293031323334353637383940414243&quot;main@1&quot; prio=5 tid=0x1 nid=NA runnable java.lang.Thread.State: RUNNABLE at org.apache.dubbo.remoting.transport.netty4.NettyServer.doOpen(NettyServer.java:97) at org.apache.dubbo.remoting.transport.AbstractServer.&lt;init&gt;(AbstractServer.java:63) at org.apache.dubbo.remoting.transport.netty4.NettyServer.&lt;init&gt;(NettyServer.java:65) at org.apache.dubbo.remoting.transport.netty4.NettyTransporter.bind(NettyTransporter.java:32) at org.apache.dubbo.remoting.Transporter$Adaptive.bind(Transporter$Adaptive.java:-1) at org.apache.dubbo.remoting.Transporters.bind(Transporters.java:56) at org.apache.dubbo.remoting.exchange.support.header.HeaderExchanger.bind(HeaderExchanger.java:44) at org.apache.dubbo.remoting.exchange.Exchangers.bind(Exchangers.java:70) at org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol.createServer(DubboProtocol.java:306) at org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol.openServer(DubboProtocol.java:283) - locked &lt;0x9ee&gt; (a org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol) at org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol.export(DubboProtocol.java:267) at org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper.export(ProtocolListenerWrapper.java:57) at org.apache.dubbo.qos.protocol.QosProtocolWrapper.export(QosProtocolWrapper.java:63) at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper.export(ProtocolFilterWrapper.java:100) at org.apache.dubbo.rpc.Protocol$Adaptive.export(Protocol$Adaptive.java:-1) at org.apache.dubbo.registry.integration.RegistryProtocol.doLocalExport(RegistryProtocol.java:170) - locked &lt;0x9e2&gt; (a java.util.concurrent.ConcurrentHashMap) at org.apache.dubbo.registry.integration.RegistryProtocol.export(RegistryProtocol.java:133) at org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper.export(ProtocolListenerWrapper.java:55) at org.apache.dubbo.qos.protocol.QosProtocolWrapper.export(QosProtocolWrapper.java:61) at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper.export(ProtocolFilterWrapper.java:98) at org.apache.dubbo.rpc.Protocol$Adaptive.export(Protocol$Adaptive.java:-1) at org.apache.dubbo.config.ServiceConfig.doExportUrlsFor1Protocol(ServiceConfig.java:513) at org.apache.dubbo.config.ServiceConfig.doExportUrls(ServiceConfig.java:358) at org.apache.dubbo.config.ServiceConfig.doExport(ServiceConfig.java:317) - locked &lt;0x848&gt; (a org.apache.dubbo.config.spring.ServiceBean) at org.apache.dubbo.config.ServiceConfig.export(ServiceConfig.java:216) at org.apache.dubbo.config.spring.ServiceBean.onApplicationEvent(ServiceBean.java:123) at org.apache.dubbo.config.spring.ServiceBean.onApplicationEvent(ServiceBean.java:49) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) - locked &lt;0xab7&gt; (a java.lang.Object) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:83) at cn.shuaijunlan.dubbo.learning.main.Main.main(Main.java:13) 关于Dubbo是如何基于Spring解析xml文件中配置的ServiceBean这里不再赘述，可以参考我之前写的文章《基于Spring构建Dubbo源码分析》，这里将从发布服务的起始点开始将其，我们来看下ServiceBean类的部分函数实现： 123456789101112//这个函数是实现了ApplicationListener接口的onApplicationEvent(E event)函数//@Overridepublic void onApplicationEvent(ContextRefreshedEvent event) { if (isDelay() &amp;&amp; !isExported() &amp;&amp; !isUnexported()) { if (logger.isInfoEnabled()) { logger.info(\"The service ready on spring started. service: \" + getInterface()); } //发布服务的起始点 export(); }} 上面调用的export()函数的实现在其子类ServiceConfig中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131//这是一个同步方法，保证了多线程环境下的安全性public synchronized void export() { //获取export和delay属性 if (provider != null) { if (export == null) { export = provider.getExport(); } if (delay == null) { delay = provider.getDelay(); } } if (export != null &amp;&amp; !export) { return; } //判断是否延迟发布 if (delay != null &amp;&amp; delay &gt; 0) { //延迟delay时间后执行 delayExportExecutor.schedule(new Runnable() { @Override public void run() { doExport(); } }, delay, TimeUnit.MILLISECONDS); } else { //发布服务 doExport(); }}//使用synchonized进行同步，保证了线程安全性protected synchronized void doExport() { if (unexported) { throw new IllegalStateException(\"Already unexported!\"); } if (exported) { return; } //将exported状态改为true exported = true; if (interfaceName == null || interfaceName.length() == 0) { throw new IllegalStateException(\"&lt;dubbo:service interface=\\\"\\\" /&gt; interface not allow null!\"); } checkDefault(); if (provider != null) { if (application == null) { application = provider.getApplication(); } if (module == null) { module = provider.getModule(); } if (registries == null) { registries = provider.getRegistries(); } if (monitor == null) { monitor = provider.getMonitor(); } if (protocols == null) { protocols = provider.getProtocols(); } } if (module != null) { if (registries == null) { registries = module.getRegistries(); } if (monitor == null) { monitor = module.getMonitor(); } } if (application != null) { if (registries == null) { registries = application.getRegistries(); } if (monitor == null) { monitor = application.getMonitor(); } } if (ref instanceof GenericService) { interfaceClass = GenericService.class; if (StringUtils.isEmpty(generic)) { generic = Boolean.TRUE.toString(); } } else { try { interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader()); } catch (ClassNotFoundException e) { throw new IllegalStateException(e.getMessage(), e); } checkInterfaceAndMethods(interfaceClass, methods); checkRef(); generic = Boolean.FALSE.toString(); } if (local != null) { if (\"true\".equals(local)) { local = interfaceName + \"Local\"; } Class&lt;?&gt; localClass; try { localClass = ClassHelper.forNameWithThreadContextClassLoader(local); } catch (ClassNotFoundException e) { throw new IllegalStateException(e.getMessage(), e); } if (!interfaceClass.isAssignableFrom(localClass)) { throw new IllegalStateException(\"The local implementation class \" + localClass.getName() + \" not implement interface \" + interfaceName); } } if (stub != null) { if (\"true\".equals(stub)) { stub = interfaceName + \"Stub\"; } Class&lt;?&gt; stubClass; try { stubClass = ClassHelper.forNameWithThreadContextClassLoader(stub); } catch (ClassNotFoundException e) { throw new IllegalStateException(e.getMessage(), e); } if (!interfaceClass.isAssignableFrom(stubClass)) { throw new IllegalStateException(\"The stub implementation class \" + stubClass.getName() + \" not implement interface \" + interfaceName); } } checkApplication(); checkRegistry(); checkProtocol(); appendProperties(this); checkStubAndMock(interfaceClass); if (path == null || path.length() == 0) { path = interfaceName; } doExportUrls(); ProviderModel providerModel = new ProviderModel(getUniqueServiceName(), this, ref); ApplicationModel.initProviderModel(getUniqueServiceName(), providerModel);} 在doExport()函数中调用了doExportUrls()方法，我们将进一步分析doExportUrls()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180@SuppressWarnings({\"unchecked\", \"rawtypes\"})private void doExportUrls() { //支持多个注册中心 List&lt;URL&gt; registryURLs = loadRegistries(true); for (ProtocolConfig protocolConfig : protocols) { //执行doExportUrlsFor1Protocol方法 doExportUrlsFor1Protocol(protocolConfig, registryURLs); }}private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) { String name = protocolConfig.getName(); if (name == null || name.length() == 0) { name = \"dubbo\"; } Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) { map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); } appendParameters(map, application); appendParameters(map, module); appendParameters(map, provider, Constants.DEFAULT_KEY); appendParameters(map, protocolConfig); appendParameters(map, this); if (methods != null &amp;&amp; !methods.isEmpty()) { for (MethodConfig method : methods) { appendParameters(map, method, method.getName()); String retryKey = method.getName() + \".retry\"; if (map.containsKey(retryKey)) { String retryValue = map.remove(retryKey); if (\"false\".equals(retryValue)) { map.put(method.getName() + \".retries\", \"0\"); } } List&lt;ArgumentConfig&gt; arguments = method.getArguments(); if (arguments != null &amp;&amp; !arguments.isEmpty()) { for (ArgumentConfig argument : arguments) { // convert argument type if (argument.getType() != null &amp;&amp; argument.getType().length() &gt; 0) { Method[] methods = interfaceClass.getMethods(); // visit all methods if (methods != null &amp;&amp; methods.length &gt; 0) { for (int i = 0; i &lt; methods.length; i++) { String methodName = methods[i].getName(); // target the method, and get its signature if (methodName.equals(method.getName())) { Class&lt;?&gt;[] argtypes = methods[i].getParameterTypes(); // one callback in the method if (argument.getIndex() != -1) { if (argtypes[argument.getIndex()].getName().equals(argument.getType())) { appendParameters(map, argument, method.getName() + \".\" + argument.getIndex()); } else { throw new IllegalArgumentException(\"argument config error : the index attribute and type attribute not match :index :\" + argument.getIndex() + \", type:\" + argument.getType()); } } else { // multiple callbacks in the method for (int j = 0; j &lt; argtypes.length; j++) { Class&lt;?&gt; argclazz = argtypes[j]; if (argclazz.getName().equals(argument.getType())) { appendParameters(map, argument, method.getName() + \".\" + j); if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j) { throw new IllegalArgumentException(\"argument config error : the index attribute and type attribute not match :index :\" + argument.getIndex() + \", type:\" + argument.getType()); } } } } } } } } else if (argument.getIndex() != -1) { appendParameters(map, argument, method.getName() + \".\" + argument.getIndex()); } else { throw new IllegalArgumentException(\"argument config must set index or type attribute.eg: &lt;dubbo:argument index='0' .../&gt; or &lt;dubbo:argument type=xxx .../&gt;\"); } } } } // end of methods for } if (ProtocolUtils.isGeneric(generic)) { map.put(Constants.GENERIC_KEY, generic); map.put(Constants.METHODS_KEY, Constants.ANY_VALUE); } else { String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) { map.put(\"revision\", revision); } String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) { logger.warn(\"NO method found in service interface \" + interfaceClass.getName()); map.put(Constants.METHODS_KEY, Constants.ANY_VALUE); } else { map.put(Constants.METHODS_KEY, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), \",\")); } } if (!ConfigUtils.isEmpty(token)) { if (ConfigUtils.isDefault(token)) { map.put(Constants.TOKEN_KEY, UUID.randomUUID().toString()); } else { map.put(Constants.TOKEN_KEY, token); } } if (Constants.LOCAL_PROTOCOL.equals(protocolConfig.getName())) { protocolConfig.setRegister(false); map.put(\"notify\", \"false\"); } // export service String contextPath = protocolConfig.getContextpath(); if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) { contextPath = provider.getContextpath(); } String host = this.findConfigedHosts(protocolConfig, registryURLs, map); Integer port = this.findConfigedPorts(protocolConfig, name, map); URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? \"\" : contextPath + \"/\") + path, map); if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .hasExtension(url.getProtocol())) { url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .getExtension(url.getProtocol()).getConfigurator(url).configure(url); } String scope = url.getParameter(Constants.SCOPE_KEY); // don't export when none is configured if (!Constants.SCOPE_NONE.equalsIgnoreCase(scope)) { // export to local if the config is not remote (export to remote only when config is remote) if (!Constants.SCOPE_REMOTE.equalsIgnoreCase(scope)) { //本地暴露（分析1） exportLocal(url); } // export to remote if the config is not local (export to local only when config is local) //如果配置不是local则暴露为远程服务 if (!Constants.SCOPE_LOCAL.equalsIgnoreCase(scope)) { if (logger.isInfoEnabled()) { logger.info(\"Export dubbo service \" + interfaceClass.getName() + \" to url \" + url); } if (registryURLs != null &amp;&amp; !registryURLs.isEmpty()) { //多个注册中心 for (URL registryURL : registryURLs) { url = url.addParameterIfAbsent(Constants.DYNAMIC_KEY, registryURL.getParameter(Constants.DYNAMIC_KEY)); URL monitorUrl = loadMonitor(registryURL); if (monitorUrl != null) { url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString()); } if (logger.isInfoEnabled()) { logger.info(\"Register dubbo service \" + interfaceClass.getName() + \" url \" + url + \" to registry \" + registryURL); } // For providers, this is used to enable custom proxy to generate invoker String proxy = url.getParameter(Constants.PROXY_KEY); if (StringUtils.isNotEmpty(proxy)) { registryURL = registryURL.addParameter(Constants.PROXY_KEY, proxy); } //根据Java SPI机制得到ProxyFactory$Adaptive类的实例proxyFactory Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); //获取包装类?? DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); //调用Protocol$Adaptive的export()方法 Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); } } else { //没有注册中心，只在本机IP打开服务端口生成服务代理，并不注册到注册中心 Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); } } } this.urls.add(url);} 本地服务发布过程首先是进入exportLocal()函数： 1234567891011121314private void exportLocal(URL url) { if (!Constants.LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) { URL local = URL.valueOf(url.toFullString()) .setProtocol(Constants.LOCAL_PROTOCOL) .setHost(LOCALHOST) .setPort(0); ServiceClassHolder.getInstance().pushServiceClass(getServiceClass(ref)); //这是核心步骤，先是执行proxyFactory.getInvoker()方法生成invoker，然后是执行protocol.export()方法暴露服务，下面将会分别介绍 Exporter&lt;?&gt; exporter = protocol.export( proxyFactory.getInvoker(ref, (Class) interfaceClass, local)); exporters.add(exporter); logger.info(\"Export dubbo service \" + interfaceClass.getName() + \" to local registry\"); }} 分析proxyFactory.getInvoker()过程通过Dubbo SPI机制（详见《Dubbo SPI机制源码分析》），proxyFactory是ProxyFactory$Adaptive类的实例，我们来看它的getInvoker()方法： 123456789101112//传入三个参数，分别是ref、interfaceClass和urlpublic org.apache.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, org.apache.dubbo.common.URL arg2) throws org.apache.dubbo.rpc.RpcException { if (arg2 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg2; //默认是使用Javassist生成代理 String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.MEAT-INF.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\"); //根据Dubbo SPI机制得到JavassistProxyFactory扩展类 org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2);} 然后调用extension.getInvoker()方法，这里的extension，默认是JavassistProxyFactory类的实例（也是基于Java SPI机制），然后调用它的getInvoker()方法： 1234567891011121314@Overridepublic &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) { // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' //获取包装类,具体代码是怎样的？ final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) { @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable { return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); } };} 这里以文章开头的Demo为例，通过Wrapper.getWrapper()返回的类代码，这里需要代码hack： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package com.alibaba.dubbo.common.bytecode;import com.alibaba.dubbo.common.DemoService;import java.lang.reflect.InvocationTargetException;import java.util.Map;public class Wrapper0 extends Wrapper implements ClassGenerator.DC{ public static String[] pns; public static Map pts; public static String[] mns; public static String[] dmns; public static Class[] mts0; public String[] getPropertyNames() { return pns; } public boolean hasProperty(String paramString) { return pts.containsKey(paramString); } public Class getPropertyType(String paramString) { return (Class)pts.get(paramString); } public String[] getMethodNames() { return mns; } public String[] getDeclaredMethodNames() { return dmns; } public void setPropertyValue(Object paramObject1, String paramString, Object paramObject2) { try { DemoService localDemoService = (DemoService)paramObject1; } catch (Throwable localThrowable) { throw new IllegalArgumentException(localThrowable); } throw new NoSuchPropertyException(\"Not found property \\\"\" + paramString + \"\\\" filed or setter method in class com.alibaba.dubbo.common.DemoService.\"); } public Object getPropertyValue(Object paramObject, String paramString) { try { DemoService localDemoService = (DemoService)paramObject; } catch (Throwable localThrowable) { throw new IllegalArgumentException(localThrowable); } throw new NoSuchPropertyException(\"Not found property \\\"\" + paramString + \"\\\" filed or setter method in class com.alibaba.dubbo.common.DemoService.\"); } //(**看这里，关键方法实现****) public Object invokeMethod(Object paramObject, String paramString, Class[] paramArrayOfClass, Object[] paramArrayOfObject) throws InvocationTargetException { DemoService localDemoService; try { //赋值执行实例，这里是接口实现类，DemoServiceImpl对象 localDemoService = (DemoService)paramObject; } catch (Throwable localThrowable1) { throw new IllegalArgumentException(localThrowable1); } try { //根据传入的要调用的方法名paramString,方法参数值，调用执行实例方法 if ((\"sayHello\".equals(paramString)) || (paramArrayOfClass.length == 1)) return localDemoService.sayHello((String)paramArrayOfObject[0]); } catch (Throwable localThrowable2) { throw new InvocationTargetException(localThrowable2); } throw new NoSuchMethodException(\"Not found method \\\"\" + paramString + \"\\\" in class com.alibaba.dubbo.common.DemoService.\"); }} 到这就比较清楚了解具体的代理的过程了。 分析protocol.export()过程上面的过程已经生成好了invoker对象，接下来就要通过Protocol$Adaptive的export()方法暴露服务： 12345678910111213public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(\"org.apache.MEAT-INF.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.MEAT-INF.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? \"MEAT-INF.dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.MEAT-INF.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); //因为这是本地服务发布，因此protocol为injvm //所以这里会走到InjvmProtocol的export()方法 org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0);} 看下InjvmProtocol的export()方法 12345@Overridepublic &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException { //返回InjvmExporter对象 return new InjvmExporter&lt;T&gt;(invoker, invoker.getUrl().getServiceKey(), exporterMap);} InjvmExporter的构造函数： 1234567InjvmExporter(Invoker&lt;T&gt; invoker, String key, Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap) { super(invoker); this.key = key; this.exporterMap = exporterMap; //存的形式，serviceKey:自身(exporter) put到map关联起来，这样可以通过servciekey找到exporterMap然后找到invoker exporterMap.put(key, this);} 这里的exporterMap是由InjvmProtocol实例拥有，而InjvmProtocol又是单例的，因为InjvmProtocol类有如下实例和方法： 123456//静态自身成员变量private static InjvmProtocol INSTANCE;//构造方法，把自己赋值给INSTANCE对象public InjvmProtocol() { INSTANCE = this;} 所以exporterMap对象也是单例的，同时这里顺便看下InjvmProtocol的refer()方法，本地服务的引用查找也是通过自身的exporterMap对象： 12345678910111213141516@Overridepublic &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException { //把exporterMap对象赋值给InjvmInvoker return new InjvmInvoker&lt;T&gt;(serviceType, url, url.getServiceKey(), exporterMap);}//具体查找过程@Overridepublic Result doInvoke(Invocation invocation) throws Throwable { //通过exporterMap获取exporter Exporter&lt;?&gt; exporter = InjvmProtocol.getExporter(exporterMap, getUrl()); if (exporter == null) { throw new RpcException(\"Service [\" + key + \"] not found.\"); } RpcContext.getContext().setRemoteAddress(NetUtils.LOCALHOST, 0); return exporter.getInvoker().invoke(invocation);} 以上的所有步骤就是本地服务的发布和引用过程。 远程服务发布上面调用了proFactory的getInvoker()方法，我们来看一下ProxyFactory$Adaptive.getInvoker()的代码： 123456789101112//传入三个参数，分别是ref、interfaceClass和urlpublic org.apache.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, org.apache.dubbo.common.URL arg2) throws org.apache.dubbo.rpc.RpcException { if (arg2 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg2; //默认是使用Javassist生成代理 String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.MEAT-INF.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\"); //根据Dubbo SPI机制得到JavassistProxyFactory扩展类 org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2);} 再来看一下JavassistProxyFactory.getInvoker()方法： 1234567891011121314@Overridepublic &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) { // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' //获取包装类,具体代码是怎样的？ final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) { @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable { return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); } };} 在doExportUrlsFor1Protocol()方法中还调用了Protocol$Adaptive.export()方法： 1234567891011public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(\"org.apache.MEAT-INF.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.MEAT-INF.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? \"MEAT-INF.dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.MEAT-INF.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0);} 根据Dubbo SPI机制可以看出调用RegistryProtocol.export()方法，Protocol还定义了ProtocolFilterWrapper、QosProtocolWrapper和ProtocolListenerWrapper三个Wrapper扩展点，根据ExtensionLoader的加载规则，他会返回ProtocolFilterWrapper-&gt;QosProtocolWrapper-&gt;ProtocolListenerWrapper-&gt;RegistryProtocol（对象链调用顺序还待进一步求证）对象链： 1234567891011121314151617181920212223242526272829303132333435@Overridepublic &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException { //export invoker //暴露invoker（暴露服务过程从这里开始，看doLocalExport()） final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); URL registryUrl = getRegistryUrl(originInvoker); //registry provider //获取对应注册中心操作对象 final Registry registry = getRegistry(originInvoker); //获取要注册到注册中心的地址 final URL registeredProviderUrl = getRegisteredProviderUrl(originInvoker); //to judge to delay publish whether or not boolean register = registeredProviderUrl.getParameter(\"register\", true); ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); //判断是否注册服务 if (register) { //执行注册(服务注册过程从这里开始) register(registryUrl, registeredProviderUrl); ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true); } // Subscribe the override data // FIXME When the provider subscribes, it will affect the scene : a certain JVM exposes the service and call the same service. Because the subscribed is cached key with the name of the service, it causes the subscription information to cover. final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registeredProviderUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); //Ensure that a new exporter instance is returned every time export //保证每次export都返回一个新的exporter实例 return new DestroyableExporter&lt;T&gt;(exporter, originInvoker, overrideSubscribeUrl, registeredProviderUrl);} 因此有如下的调用栈： 12345at org.apache.dubbo.registry.integration.RegistryProtocol.export(RegistryProtocol.java:133)at org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper.export(ProtocolListenerWrapper.java:55)at org.apache.dubbo.qos.protocol.QosProtocolWrapper.export(QosProtocolWrapper.java:61)at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper.export(ProtocolFilterWrapper.java:98)at org.apache.dubbo.rpc.Protocol$Adaptive.export(Protocol$Adaptive.java:-1) 继续看执行服务暴露的函数doLocalExport(): 123456789101112131415161718192021222324252627@SuppressWarnings(\"unchecked\")private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker) { //通过原始originInvoker构造缓存key String key = getCacheKey(originInvoker); ExporterChangeableWrapper&lt;T&gt; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); //没有缓存，走具体暴露流程 if (exporter == null) { synchronized (bounds) { exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) { //InvokerDelegete是RegistryProtocol类的静态内部类，继承自InvokerWrapper， //通过构造器赋值持有代理originInvoker和服务暴露协议url对象,算是包装一层 //而url 是通过getProviderUrl(originInvoker)返回的，此时url的协议已是dubbo，即服务暴露的协议 final Invoker&lt;?&gt; invokerDelegete = new InvokerDelegete&lt;T&gt;(originInvoker, getProviderUrl(originInvoker)); //ExporterChangeableWrapper是RegistryProtocol的私有内部类实现了Exporter接口。 //通过调用它的构造方法(Exporter&lt;T&gt; exporter, Invoker&lt;T&gt; originInvoker)构造exporterWrapper实例 //而这里传入的exporter是通过(Exporter&lt;T&gt;) protocol.export(invokerDelegete)语句创建 //由上一步知道，这里的invokerDelegete里url属性的protocol协议已经是dubbo //下面具体看下protocol.export(invokerDelegete)方法。 exporter = new ExporterChangeableWrapper&lt;T&gt;((Exporter&lt;T&gt;) protocol.export(invokerDelegete), originInvoker); bounds.put(key, exporter); } } } return exporter;} 再继续往下看，通过调用Protocol$Adaptive类的export()方法，然后再调用DubboProtocol的export()方法，同理在这里也会生成ProtocolFilterWrapper-&gt;QosProtocolWrapper-&gt;ProtocolListenerWrapper-&gt;DubboProtocol对象链： 12345678910111213141516171819202122232425262728293031323334@Overridepublic &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException { URL url = invoker.getUrl(); // export service. //获取service key //key的组成group/service:version:port String key = serviceKey(url); //构造服务的exporter //如同InjvmProtocol一样，DubboProtocol也是单例的，所以这里exporterMap也是单例的 DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); //通过key放入exporterMap，把持有invoker的exporter 和serviceKey关联 //这个在后面服务调用时，可以通过key找到对应的exporter进而找到invoker提供服务 exporterMap.put(key, exporter); //export an stub service for dispatching event Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice) { String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0) { if (logger.isWarnEnabled()) { logger.warn(new IllegalStateException(\"consumer [\" + url.getParameter(Constants.INTERFACE_KEY) + \"], has set stubproxy support event ,but no stub methods founded.\")); } } else { stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); } } //根据url开启一个服务，比如绑定端口，开始接受请求 openServer(url); optimizeSerialization(url); return exporter;} 到这里就可以对应下面的调用栈： 123456at org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol.export(DubboProtocol.java:267)at org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper.export(ProtocolListenerWrapper.java:57)at org.apache.dubbo.qos.protocol.QosProtocolWrapper.export(QosProtocolWrapper.java:63)at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper.export(ProtocolFilterWrapper.java:100)at org.apache.dubbo.rpc.Protocol$Adaptive.export(Protocol$Adaptive.java:-1)at org.apache.dubbo.registry.integration.RegistryProtocol.doLocalExport(RegistryProtocol.java:170) 再继续看openServer()方法 1234567891011121314151617181920212223242526private void openServer(URL url) { // find server. //key=host:port 用于定位server String key = url.getAddress(); //client can export a service which's only for server to invoke //client也可以暴露一个只有server可以调用的服务 boolean isServer = url.getParameter(Constants.IS_SERVER_KEY, true); if (isServer) { //服务实例放到serverMap中，key是host:port //这里serverMap也是单例的 ExchangeServer server = serverMap.get(key); if (server == null) { synchronized (this) { server = serverMap.get(key); if (server == null) { //通过createServer(url)方法获取server serverMap.put(key, createServer(url)); } } } else { // server supports reset, use together with override //server支持reset，配合override使用 server.reset(url); } }} 再继续看createServer()代码： 1234567891011121314151617181920212223242526272829303132private ExchangeServer createServer(URL url) { // send readonly event when server closes, it's enabled by default //默认开启server关闭时关闭readonly事件 url = url.addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY, Boolean.TRUE.toString()); // enable heartbeat by default //默认开启heartbeat url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); String str = url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER); //通过server key检查是否是dubbo目前spi扩展支持的传输框架，默认是netty if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) throw new RpcException(\"Unsupported server type: \" + str + \", url: \" + url); //通过codec key获取编码方法，默认是dubbo url = url.addParameter(Constants.CODEC_KEY, DubboCodec.NAME); ExchangeServer server; try { //构造具体服务实例， //Exchangers是门面类，里面封装了具体交换层实现，并调用它的bind方法 server = Exchangers.bind(url, requestHandler); } catch (RemotingException e) { throw new RpcException(\"Fail to start server(url: \" + url + \") \" + e.getMessage(), e); } //这里会验证一下客户端传输实现 //如果没有对应的实现，会抛出异常 str = url.getParameter(Constants.CLIENT_KEY); if (str != null &amp;&amp; str.length() &gt; 0) { Set&lt;String&gt; supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); if (!supportedTypes.contains(str)) { throw new RpcException(\"Unsupported client type: \" + str); } } return server;} 继续看Exchanges类的bind()方法： 12345678910111213141516171819202122232425public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException { if (url == null) { throw new IllegalArgumentException(\"url == null\"); } if (handler == null) { throw new IllegalArgumentException(\"handler == null\"); } url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\"); return getExchanger(url).bind(url, handler);}public static Exchanger getExchanger(URL url) { String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER); return getExchanger(type);}public static Exchanger getExchanger(String type) { return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type);}//HeaderExchanger类的bind()方法@Overridepublic ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException { return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));} 继续跟进Transporters.bind()方法： 1234567891011121314151617181920212223242526272829303132public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException { if (url == null) { throw new IllegalArgumentException(\"url == null\"); } if (handlers == null || handlers.length == 0) { throw new IllegalArgumentException(\"handlers == null\"); } ChannelHandler handler; if (handlers.length == 1) { handler = handlers[0]; } else { handler = new ChannelHandlerDispatcher(handlers); } //根据Dubbo SPI机制，这里走NettyTransporter.bind()方法 return getTransporter().bind(url, handler);}public static Transporter getTransporter() { return ExtensionLoader.getExtensionLoader(Transporter.class).getAdaptiveExtension();}//NettyTransporter的bind方法public Server bind(URL url, ChannelHandler listener) throws RemotingException { //可以看到这里是NettyServer实例 return new NettyServer(url, listener);}//NettyServer构造器public NettyServer(URL url, ChannelHandler handler) throws RemotingException { //调用父类AbstractServer构造器 //注意下这里的ChannelHandlers.wrap()方法，生成MultiMessageHandler-&gt;HeartbeatHandler-&gt;AllChannelHandler的调用链 super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME)));} 看一下父类AbstractServer()的构造函数： 1234567891011121314151617181920212223242526public AbstractServer(URL url, ChannelHandler handler) throws RemotingException { super(url, handler); localAddress = getUrl().toInetSocketAddress(); String bindIp = getUrl().getParameter(Constants.BIND_IP_KEY, getUrl().getHost()); int bindPort = getUrl().getParameter(Constants.BIND_PORT_KEY, getUrl().getPort()); if (url.getParameter(Constants.ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(bindIp)) { bindIp = NetUtils.ANYHOST; } bindAddress = new InetSocketAddress(bindIp, bindPort); this.accepts = url.getParameter(Constants.ACCEPTS_KEY, Constants.DEFAULT_ACCEPTS); this.idleTimeout = url.getParameter(Constants.IDLE_TIMEOUT_KEY, Constants.DEFAULT_IDLE_TIMEOUT); try { //打开端口，启动服务 doOpen(); if (logger.isInfoEnabled()) { logger.info(\"Start \" + getClass().getSimpleName() + \" bind \" + getBindAddress() + \", export \" + getLocalAddress()); } } catch (Throwable t) { throw new RemotingException(url.toInetSocketAddress(), null, \"Failed to bind \" + getClass().getSimpleName() + \" on \" + getLocalAddress() + \", cause: \" + t.getMessage(), t); } //fixme replace this with better method DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); executor = (ExecutorService) dataStore.get(Constants.EXECUTOR_SERVICE_COMPONENT_KEY, Integer.toString(url.getPort()));} 再来看NettyServer的doOpen()方法： 123456789101112131415161718192021222324252627282930313233@Overrideprotected void doOpen() throws Throwable { bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup(1, new DefaultThreadFactory(\"NettyServerBoss\", true)); workerGroup = new NioEventLoopGroup(getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), new DefaultThreadFactory(\"NettyServerWorker\", true)); final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); channels = nettyServerHandler.getChannels(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() { @Override protected void initChannel(NioSocketChannel ch) throws Exception { NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ch.pipeline()//.addLast(\"logging\",new LoggingHandler(LogLevel.INFO))//for debug .addLast(\"decoder\", adapter.getDecoder()) .addLast(\"encoder\", adapter.getEncoder()) .addLast(\"handler\", nettyServerHandler); } }); // bind //bind地址，开启端口 ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); channelFuture.syncUninterruptibly(); channel = channelFuture.channel();} 分析到这里可以对应如下的调用栈： 12345678910at org.apache.dubbo.remoting.transport.netty4.NettyServer.doOpen(NettyServer.java:97) at org.apache.dubbo.remoting.transport.AbstractServer.&lt;init&gt;(AbstractServer.java:63) at org.apache.dubbo.remoting.transport.netty4.NettyServer.&lt;init&gt;(NettyServer.java:65) at org.apache.dubbo.remoting.transport.netty4.NettyTransporter.bind(NettyTransporter.java:32) at org.apache.dubbo.remoting.Transporter$Adaptive.bind(Transporter$Adaptive.java:-1) at org.apache.dubbo.remoting.Transporters.bind(Transporters.java:56) at org.apache.dubbo.remoting.exchange.support.header.HeaderExchanger.bind(HeaderExchanger.java:44) at org.apache.dubbo.remoting.exchange.Exchangers.bind(Exchangers.java:70) at org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol.createServer(DubboProtocol.java:306) at org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol.openServer(DubboProtocol.java:283) 分析到这里Dubbo服务提供者服务发布过程源码分析已经完成了，下面将继续分析服务注册过程。 Dubbo服务注册过程在之前的分析中，我们知道注册服务的过程是从RegistryProtocol的export()方法开始的，我们来看一下export()方法： 12345678910111213141516171819202122232425262728293031@Overridepublic &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException { //export invoker final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); URL registryUrl = getRegistryUrl(originInvoker); //registry provider final Registry registry = getRegistry(originInvoker); final URL registeredProviderUrl = getRegisteredProviderUrl(originInvoker); //to judge to delay publish whether or not boolean register = registeredProviderUrl.getParameter(\"register\", true); ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registeredProviderUrl); if (register) { //注册服务从这里开始 register(registryUrl, registeredProviderUrl); ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true); } // Subscribe the override data // FIXME When the provider subscribes, it will affect the scene : a certain JVM exposes the service and call the same service. Because the subscribed is cached key with the name of the service, it causes the subscription information to cover. final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registeredProviderUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); //Ensure that a new exporter instance is returned every time export return new DestroyableExporter&lt;T&gt;(exporter, originInvoker, overrideSubscribeUrl, registeredProviderUrl);} 我们再继续看register()方法： 123456public void register(URL registryUrl, URL registedProviderUrl) { //registryFactory是由Dubbo SPI机制生成的RegistryFactory$Adaptive的实例 //调用其的getRegistry()方法获得registry Registry registry = registryFactory.getRegistry(registryUrl); registry.register(registedProviderUrl);} 我们来看一下RegistryFactory$Adaptive类的getRegistry()方法： 123456789101112131415161718public org.apache.dubbo.registry.Registry getRegistry(org.apache.dubbo.common.URL arg0) { if (arg0 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg0; String extName = (url.getProtocol() == null ? \"dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.registry.RegistryFactory) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.registry.RegistryFactory extension = null; try { //得到ZookeeperRegistryFactory的实例extension extension = (org.apache.dubbo.registry.RegistryFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.registry.RegistryFactory.class).getExtension(extName); } catch (Exception e) { if (count.incrementAndGet() == 1) { logger.warn(\"Failed to find extension named \" + extName + \" for type org.apache.dubbo.registry.RegistryFactory, will use default extension dubbo instead.\", e); } extension = (org.apache.dubbo.registry.RegistryFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.registry.RegistryFactory.class).getExtension(\"dubbo\"); } return extension.getRegistry(arg0);} 先调用ZookeeperRegister的父类FailbackRegistry的register()方法： 1234567891011121314151617181920212223242526272829@Overridepublic void register(URL url) { super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try { // Sending a registration request to the server side doRegister(url); } catch (Exception e) { Throwable t = e; // If the startup detection is opened, the Exception is thrown directly. boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) { if (skipFailback) { t = t.getCause(); } throw new IllegalStateException(\"Failed to register \" + url + \" to registry \" + getUrl().getAddress() + \", cause: \" + t.getMessage(), t); } else { logger.error(\"Failed to register \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); } // Record a failed registration request to a failed list, retry regularly failedRegistered.add(url); }} 最后执行ZookeeperRegistry的doRegister()方法，向服务端发送注册请求： 12345678@Overrideprotected void doRegister(URL url) { try { zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); } catch (Throwable e) { throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); }} 服务注册调用栈： 1234567891011121314151617&quot;main@1&quot; prio=5 tid=0x1 nid=NA runnable java.lang.Thread.State: RUNNABLE at org.apache.dubbo.registry.zookeeper.ZookeeperRegistry.doRegister(ZookeeperRegistry.java:114) at org.apache.dubbo.registry.support.FailbackRegistry.register(FailbackRegistry.java:137) at org.apache.dubbo.registry.integration.RegistryProtocol.register(RegistryProtocol.java:127) at org.apache.dubbo.registry.integration.RegistryProtocol.export(RegistryProtocol.java:147) at org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper.export(ProtocolListenerWrapper.java:55) at org.apache.dubbo.qos.protocol.QosProtocolWrapper.export(QosProtocolWrapper.java:61) at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper.export(ProtocolFilterWrapper.java:98) at org.apache.dubbo.rpc.Protocol$Adaptive.export(Protocol$Adaptive.java:-1) at org.apache.dubbo.config.ServiceConfig.doExportUrlsFor1Protocol(ServiceConfig.java:513) at org.apache.dubbo.config.ServiceConfig.doExportUrls(ServiceConfig.java:358) at org.apache.dubbo.config.ServiceConfig.doExport(ServiceConfig.java:317) - locked &lt;0x9bb&gt; (a org.apache.dubbo.config.spring.ServiceBean) at org.apache.dubbo.config.ServiceConfig.export(ServiceConfig.java:216) at org.apache.dubbo.config.spring.ServiceBean.onApplicationEvent(ServiceBean.java:123) at org.apache.dubbo.config.spring.ServiceBean.onApplicationEvent(ServiceBean.java:49)","link":"/2018/09/09/dubbo-provider-calling-process-source-code-analysis/"},{"title":"Dubbo消费者调用过程源码分析","text":"在分析Dubbo RPC服务调用过程之前，我们先写一个基于Dubbo实现的Consumer-Provider的Demo，通过这个Demo来分析具体的RPC调用栈。 先定义一个接口： 1234567/** * @author Junlan Shuai[shuaijunlan@gmail.com]. * @date Created on 11:02 AM 2018/07/19. */public interface ITestService { String sayHello(String msg);} 我们基于zookeeper注册中心，服务端配置如下： 12345678&lt;dubbo:application name=\"dubbo-server\" owner=\"Junlan\" /&gt;&lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/&gt;&lt;!--protocal configuration--&gt;&lt;dubbo:protocol name=\"dubbo\" port=\"20881\"/&gt;&lt;dubbo:provider server=\"netty\"/&gt;&lt;!--service configuration--&gt;&lt;dubbo:service interface=\"cn.shuaijunlan.dubbo.learning.service.ITestService\" ref=\"testService\" protocol=\"dubbo\" loadbalance=\"roundrobin\"/&gt;&lt;bean class=\"cn.shuaijunlan.dubbo.learning.service.impl.TestServiceImpl\" name=\"testService\" /&gt; 客户端配置如下： 1234&lt;dubbo:application name=\"dubbo-client\" owner=\"Junlan\"/&gt;&lt;dubbo:consumer client=\"netty\"/&gt;&lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/&gt;&lt;dubbo:reference interface=\"cn.shuaijunlan.dubbo.learning.service.ITestService\" id=\"testService\" check=\"false\"/&gt; 项目的部分依赖如下： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.7.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt;&lt;/dependency&gt; 具体的服务提供者实现参照service-provider-a ，服务消费者实现参照dubbo-client-demo。 先启动服务提供者服务，下面分析在哪打断点： 我们看下org.apache.dubbo.remoting.transport.netty4.NettyChannel的send方法： 1234567891011121314151617181920212223242526@Overridepublic void send(Object message, boolean sent) throws RemotingException { super.send(message, sent); boolean success = true; int timeout = 0; try { //向远程服务发送消息，因此我们在这句打个断点 ChannelFuture future = channel.writeAndFlush(message); if (sent) { timeout = getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success = future.await(timeout); } Throwable cause = future.cause(); if (cause != null) { throw cause; } } catch (Throwable e) { throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \", cause: \" + e.getMessage(), e); } if (!success) { throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \"in timeout(\" + timeout + \"ms) limit\"); }} 我们在ChannelFuture future = channel.writeAndFlush(message);这句打个断点，Debug服务消费者，得到如下线程栈信息： 123456789101112131415161718192021222324&quot;main@1&quot; prio=5 tid=0x1 nid=NA runnable java.lang.Thread.State: RUNNABLE at org.apache.dubbo.remoting.transport.netty4.NettyChannel.send(NettyChannel.java:101) at org.apache.dubbo.remoting.transport.AbstractClient.send(AbstractClient.java:265) at org.apache.dubbo.remoting.transport.AbstractPeer.send(AbstractPeer.java:53) at org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.request(HeaderExchangeChannel.java:116) at org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeClient.request(HeaderExchangeClient.java:90) at org.apache.dubbo.rpc.protocol.dubbo.ReferenceCountExchangeClient.request(ReferenceCountExchangeClient.java:83) at org.apache.dubbo.rpc.protocol.dubbo.DubboInvoker.doInvoke(DubboInvoker.java:108) at org.apache.dubbo.rpc.protocol.AbstractInvoker.invoke(AbstractInvoker.java:154) at org.apache.dubbo.rpc.listener.ListenerInvokerWrapper.invoke(ListenerInvokerWrapper.java:77) at org.apache.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:72) at org.apache.dubbo.rpc.protocol.dubbo.filter.FutureFilter.invoke(FutureFilter.java:47) at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:72) at org.apache.dubbo.rpc.filter.ConsumerContextFilter.invoke(ConsumerContextFilter.java:50) at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:72) at org.apache.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:56) at org.apache.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:78) at org.apache.dubbo.rpc.cluster.support.AbstractClusterInvoker.invoke(AbstractClusterInvoker.java:243) at org.apache.dubbo.rpc.cluster.support.wrapper.MockClusterInvoker.invoke(MockClusterInvoker.java:75) at org.apache.dubbo.rpc.proxy.InvokerInvocationHandler.invoke(InvokerInvocationHandler.java:70) at org.apache.dubbo.common.bytecode.proxy0.sayHello(proxy0.java:-1) at cn.shuaijunlan.dubbo.learning.main.Main.main(Main.java:16) 自底向上，可以直观的看到服务消费者调用要经过的类和方法，下面将进行一步步分析，对每一个类的创建过程和调用过程做出解析： 第一行栈信息 1at cn.shuaijunlan.dubbo.learning.main.Main.main(Main.java:16) Main.java 类是消费者端的启动类，可以忽略。 第二行栈信息 1at org.apache.dubbo.common.bytecode.proxy0.sayHello(proxy0.java:-1) org.apache.dubbo.common.bytecode.proxy0类是一个代理类，它代理了所有RPC服务接口的方法调用。这个类实例是什么时候创建的？类代码是怎样的？ Dubbo基于Spring的构建分析（参考文章《基于Spring构建Dubbo源码分析》）， 代理类的创建是由ReferenceBean类的 123public Object getObject() throws Exception { return get();} 方法里触发的，具体的实现在ReferenceConfig类createProxy方法里 12345678@SuppressWarnings({\"unchecked\", \"rawtypes\", \"deprecation\"})private T createProxy(Map&lt;String, String&gt; map) { // ... // 用于生成invoker的逻辑，关于invoker生成逻辑这里先忽略，后面会说到 // ... // create service proxy return (T) proxyFactory.getProxy(invoker);} proxyFactory变量赋值为 1private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); Dubbo SPI机制(参考文章《Dubbo SPI机制源码分析》)里可以得到ProxyFactory接口的Adaptive类的getProxy方法源码如下： 123456789101112131415161718192021222324252627282930313233343536373839package org.apache.dubbo.rpc;import org.apache.dubbo.common.extension.ExtensionLoader;public class ProxyFactory$Adaptive implements org.apache.dubbo.rpc.ProxyFactory { public java.lang.Object getProxy(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); } public java.lang.Object getProxy(org.apache.dubbo.rpc.Invoker arg0, boolean arg1) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0, arg1); } public org.apache.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, org.apache.dubbo.common.URL arg2) throws org.apache.dubbo.rpc.RpcException { if (arg2 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg2; String extName = url.getParameter(\"proxy\", \"javassist\"); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.ProxyFactory) name from url(\" + url.toString() + \") use keys([proxy])\"); org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2); }} 在如上ProxyFactory$Adaptive类中，调用getProxy(org.apache.dubbo.rpc.Invoker arg0)方法，其中： 12String extName = url.getParameter(\"proxy\", \"javassist\");org.apache.dubbo.rpc.ProxyFactory extension = (org.apache.dubbo.rpc.ProxyFactory) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.ProxyFactory.class).getExtension(extName); 默认获取ProxyFactory接口的javassist扩展类JavassistProxyFactory，先调用JavassitProxyFactory的父类ProxyFactory的getProxy(Invoker&lt;T&gt; invoker)方法和getProxy(Invoker&lt;T&gt; invoker, boolean generic)方法： 1234@Overridepublic &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException { return getProxy(invoker, false);} 再调用JavassistProxyFactory类的getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces)方法： 12345@Override@SuppressWarnings(\"unchecked\")public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) { return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));} 再到生成代理类的Proxy类（具体过程在另一篇文章中详细分析） 123456789/** * Get proxy. * * @param ics interface class array. * @return Proxy instance. */public static Proxy getProxy(Class&lt;?&gt;... ics) { return getProxy(ClassHelper.getClassLoader(Proxy.class), ics);} 这里直接贴出通过代码hack生成的代理类源码，这里动态生成了两个类： 1234567891011121314package com.alibaba.dubbo.common.bytecode;import com.alibaba.dubbo.common.bytecode.ClassGenerator.DC;import java.lang.reflect.InvocationHandler;public class Proxy0 extends Proxy implements DC { public Object newInstance(InvocationHandler var1) { return new proxy01(var1); } public Proxy0_my() { }} 这个类继承抽象类Proxy，实现了它的抽象方法newInstance，接口DC是Dubbo内部作为动态类标示的接口； 还有一个proxy01，就是在开始方法栈里看到的代理类，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142package com.alibaba.dubbo.common.bytecode;import com.alibaba.dubbo.rpc.service.EchoService;import demo.dubbo.api.DemoService;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;public class proxy01 implements ClassGenerator.DC, EchoService, DemoService { public static Method[] methods; private InvocationHandler handler; //实现了接口方法 public String sayHello(String var1) { Object[] var2 = new Object[]{var1}; Object var3 = null; try { var3 = this.handler.invoke(this, methods[1], var2); } catch (Throwable throwable) { throwable.printStackTrace(); } return (String)var3; } public Object $echo(Object var1) { Object[] var2 = new Object[]{var1}; Object var3 = null; try { var3 = this.handler.invoke(this, methods[3], var2); } catch (Throwable throwable) { throwable.printStackTrace(); } return (Object)var3; } public proxy01() { } //public 构造函数，这里handler是 //由Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker))语句传入的InvokerInvocationHandler对象 public proxy01(InvocationHandler var1) { this.handler = var1; }} 可以看到代理类实现类三个接口，ClassGeneratr.DC是Dubbo动态类标识接口，DemoService是实际的业务接口，这样代理就可以调用服务方法了，EchoService是回显测试接口，只有一个$echo(Object var1)法。 1234567891011121314151617package org.apache.dubbo.rpc.service;/** * Echo service. * @export */public interface EchoService { /** * echo test. * * @param message message. * @return message. */ Object $echo(Object message);} 它能为所有的Dubbo RPC服务加上一个回显测试方法。 123// 通过类型强制转换为EchoService，可以测试EchoService echoService = (EchoService) service;System.out.println(echoService.$echo(\"hello\")); 到这可以了解代理类生成的整个过程，可以看到sayHello方法的调用其实是调用this.handler.invoke(this, methods[1], var2);，因此这也解释了线程栈中第三行信息： 1at org.apache.dubbo.rpc.proxy.InvokerInvocationHandler.invoke(InvokerInvocationHandler.java:70) 再往下看org.apache.dubbo.rpc.proxy.InvokerInvocationHandler类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class InvokerInvocationHandler implements InvocationHandler { private final Invoker&lt;?&gt; invoker; //通过构造函数传入invoker public InvokerInvocationHandler(Invoker&lt;?&gt; handler) { this.invoker = handler; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { String methodName = method.getName(); Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); // 如果是Object类方法 if (method.getDeclaringClass() == Object.class) { //反射调用 return method.invoke(invoker, args); } // 对toString、hashCode、equals三个方法做了处理 if (\"toString\".equals(methodName) &amp;&amp; parameterTypes.length == 0) { return invoker.toString(); } if (\"hashCode\".equals(methodName) &amp;&amp; parameterTypes.length == 0) { return invoker.hashCode(); } if (\"equals\".equals(methodName) &amp;&amp; parameterTypes.length == 1) { return invoker.equals(args[0]); } RpcInvocation invocation; if (RpcUtils.hasGeneratedFuture(method)) { Class&lt;?&gt; clazz = method.getDeclaringClass(); String syncMethodName = methodName.substring(0, methodName.length() - Constants.ASYNC_SUFFIX.length()); Method syncMethod = clazz.getMethod(syncMethodName, method.getParameterTypes()); invocation = new RpcInvocation(syncMethod, args); invocation.setAttachment(Constants.FUTURE_GENERATED_KEY, \"true\"); invocation.setAttachment(Constants.ASYNC_KEY, \"true\"); } else { invocation = new RpcInvocation(method, args); if (RpcUtils.hasFutureReturnType(method)) { invocation.setAttachment(Constants.FUTURE_RETURNTYPE_KEY, \"true\"); invocation.setAttachment(Constants.ASYNC_KEY, \"true\"); } } return invoker.invoke(invocation).recreate(); }} 在这里的invoker对象，是通过InvokerInvocationHandler构造方法传入，而且InvokerInvocationHandler对象是由JavassistProxyFactory类的getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces)方法创建，回到调用proxyFactory.getProxy(invoker);的地方，即ReferenceConfig类的createProxy(Map&lt;String, String&gt; map)方法，以下部分是生成invoker的过程： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364if (isJvmRefer) { URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map); invoker = refprotocol.refer(interfaceClass, url); if (logger.isInfoEnabled()) { logger.info(\"Using injvm service \" + interfaceClass.getName()); }} else { if (url != null &amp;&amp; url.length() &gt; 0) { // user specified URL, could be peer-to-peer address, or register center's address. String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length &gt; 0) { for (String u : us) { URL url = URL.valueOf(u); if (url.getPath() == null || url.getPath().length() == 0) { url = url.setPath(interfaceName); } if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); } else { urls.add(ClusterUtils.mergeUrl(url, map)); } } } } else { // assemble URL from register center's configuration //从注册中心获取配置URL List&lt;URL&gt; us = loadRegistries(false); if (us != null &amp;&amp; !us.isEmpty()) { for (URL u : us) { URL monitorUrl = loadMonitor(u); if (monitorUrl != null) { map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString())); } urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); } } if (urls.isEmpty()) { throw new IllegalStateException(\"No such any registry to reference \" + interfaceName + \" on the consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", please config &lt;dubbo:registry address=\\\"...\\\" /&gt; to your spring config.\"); } } //只有一个直连地址或者一个注册中心配置地址 if (urls.size() == 1) { //这里的urls.get(0)，可能是直连地址（默认为dubbo协议），也可能是register注册地址（zookeeper协议） //示例中使用了zookeeper注册中心，因此会执行这一步 invoker = refprotocol.refer(interfaceClass, urls.get(0)); } else {//多个直连地址或者多个注册中心，甚至是两者的结合，执行这一步 List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) { //创建invoker放入invokers invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { registryURL = url; // use last registry url } } if (registryURL != null) { // registry url is available // use AvailableCluster only when register's cluster is available //这其中包括直连和注册中心混合或者都是注册中心两种情况，默认使用AvailableCluster集群策略 URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); invoker = cluster.join(new StaticDirectory(u, invokers)); } else { // not a registry url //多个直连的URL invoker = cluster.join(new StaticDirectory(invokers)); } }} 经过上面的分析，可以发现invoker是通过refprotocol.refer(interfaceClass, urls.get(0));、cluster.join(new StaticDirectory(u, invokers));和cluster.join(new StaticDirectory(invokers));三种构建语句其中之一生成的，这里是经过第一种方式生成invoker的，下面来分析第一种生成invoker的情况，根据SPI机制这里refprotocol对象是Protocol$Adpative实例，具体refer实现是： 123456789public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException { if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; String extName = (url.getProtocol() == null ? \"MEAT-INF.dubbo\" : url.getProtocol()); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.MEAT-INF.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1);} 示例中是通过注册中心，因此这里protocol是register，会走RegistryProtocol类的refer方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Override@SuppressWarnings(\"unchecked\")public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { //通过register可以获取具体注册中心协议，这里是zookeeper，因此url的协议值被设置为zookeeper url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); //获取zookeeper Registry实现，即ZookeeperRegistryFactory，并调用getRegistry方法实现 //获取zookeeper类型的registry对象 Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) { return proxyFactory.getInvoker((T) registry, type, url); } // group=\"a,b\" or group=\"*\" Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0) { if ((Constants.COMMA_SPLIT_PATTERN.split(group)).length &gt; 1 || \"*\".equals(group)) { return doRefer(getMergeableCluster(), registry, type, url); } } //根据Dubbo SPI机制，给setXxx方法对应的属性赋值为Xxx$Adaptive，这里就是Cluster$Adaptive return doRefer(cluster, registry, type, url);}private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) { //这里的RegistryDirectory和StaticDirectory相对应的，前者是动态从注册中心获取url目录对象，后者是静态指定url目录 RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); // all attributes of REFER_KEY Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters()); URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, parameters.remove(Constants.REGISTER_IP_KEY), 0, type.getName(), parameters); if (!Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) { registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); } //订阅注册中心，可以获取服务提供方地址等信息 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + \",\" + Constants.CONFIGURATORS_CATEGORY + \",\" + Constants.ROUTERS_CATEGORY)); //通过调用Cluster$Adpative类的join方法返回Invoker对象(基于Dubbo SPI机制实现setXX()方法自动注入属性) Invoker invoker = cluster.join(directory); ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory); return invoker;} 这里看下Cluster$Adpative类的join方法实现 12345678910111213141516171819202122232425262728package org.apache.dubbo.rpc.cluster;import org.apache.dubbo.common.extension.ExtensionLoader;public class Cluster$Adaptive implements org.apache.dubbo.rpc.cluster.Cluster { private static final org.apache.dubbo.common.logger.Logger logger = org.apache.dubbo.common.logger.LoggerFactory.getLogger(ExtensionLoader.class); private java.util.concurrent.atomic.AtomicInteger count = new java.util.concurrent.atomic.AtomicInteger(0); public org.apache.dubbo.rpc.Invoker join(org.apache.dubbo.rpc.cluster.Directory arg0) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.cluster.Directory argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.cluster.Directory argument getUrl() == null\"); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(\"cluster\", \"failover\"); if (extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.cluster.Cluster) name from url(\" + url.toString() + \") use keys([cluster])\"); org.apache.dubbo.rpc.cluster.Cluster extension = null; try { extension = (org.apache.dubbo.rpc.cluster.Cluster) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.cluster.Cluster.class).getExtension(extName); } catch (Exception e) { if (count.incrementAndGet() == 1) { logger.warn(\"Failed to find extension named \" + extName + \" for type org.apache.dubbo.rpc.cluster.Cluster, will use default extension failover instead.\", e); } extension = (org.apache.dubbo.rpc.cluster.Cluster) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.cluster.Cluster.class).getExtension(\"failover\"); } return extension.join(arg0); }} 再看下FailoverCluster的join方法： 1234@Overridepublic &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException { return new FailoverClusterInvoker&lt;T&gt;(directory);} 由于Cluster SPI实现中有个MockClusterWrapper是包装类，这里牵扯到Dubbo的AOP机制(后期详细分析)，这里先调用它的join方法： 12345@Overridepublic &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException { return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory));} 生成MockClusterInvoker之后，由于FailoverClusterInvoker是AbstractClusterInvoker的子类，它的invoke方法实现在其父类中，接下来的调用链是MockClusterInvoker.invoke()-&gt;AbstractClusterInvoker.invoke()-&gt;FailoverClusterInvoker.doInvoke()，下面来一步步分析，首先来看MockClusterInvoker类的invoke()方法： 12345678910111213141516171819202122232425262728293031@Overridepublic Result invoke(Invocation invocation) throws RpcException { Result result = null; String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim(); if (value.length() == 0 || value.equalsIgnoreCase(\"false\")) { //no mock result = this.invoker.invoke(invocation); } else if (value.startsWith(\"force\")) { if (logger.isWarnEnabled()) { logger.warn(\"force-mock: \" + invocation.getMethodName() + \" force-mock enabled , url : \" + directory.getUrl()); } //force:direct mock result = doMockInvoke(invocation, null); } else { //fail-mock try { result = this.invoker.invoke(invocation); } catch (RpcException e) { if (e.isBiz()) { throw e; } else { if (logger.isWarnEnabled()) { logger.warn(\"fail-mock: \" + invocation.getMethodName() + \" fail-mock enabled , url : \" + directory.getUrl(), e); } result = doMockInvoke(invocation, e); } } } return result;} 然后调用AbstractClusterInvoker的invoke()方法： 123456789101112131415@Overridepublic Result invoke(final Invocation invocation) throws RpcException { checkWhetherDestroyed(); // binding attachments into invocation. Map&lt;String, String&gt; contextAttachments = RpcContext.getContext().getAttachments(); if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) { ((RpcInvocation) invocation).addAttachments(contextAttachments); } List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); LoadBalance loadbalance = initLoadBalance(invokers, invocation); RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); return doInvoke(invocation, invokers, loadbalance);} 最后调用FailoverClusterInvoker的doInvoke()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Override@SuppressWarnings({\"unchecked\", \"rawtypes\"})public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException { List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers; checkInvokers(copyinvokers, invocation); String methodName = RpcUtils.getMethodName(invocation); //设置重试次数 int len = getUrl().getMethodParameter(methodName, Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;= 0) { len = 1; } // retry loop. RpcException le = null; // last exception. List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) { //Reselect before retry to avoid a change of candidate `invokers`. //NOTE: if `invokers` changed, then `invoked` also lose accuracy. if (i &gt; 0) { checkWhetherDestroyed(); copyinvokers = list(invocation); // check again checkInvokers(copyinvokers, invocation); } //根据负载均衡策略选择调用者 Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); //将使用过的invoker放入invoked invoked.add(invoker); RpcContext.getContext().setInvokers((List) invoked); try { Result result = invoker.invoke(invocation); if (le != null &amp;&amp; logger.isWarnEnabled()) { logger.warn(\"Although retry the method \" + methodName + \" in the service \" + getInterface().getName() + \" was successful by the provider \" + invoker.getUrl().getAddress() + \", but there have been failed providers \" + providers + \" (\" + providers.size() + \"/\" + copyinvokers.size() + \") from the registry \" + directory.getUrl().getAddress() + \" on the consumer \" + NetUtils.getLocalHost() + \" using the dubbo version \" + Version.getVersion() + \". Last error is: \" + le.getMessage(), le); } return result; } catch (RpcException e) { if (e.isBiz()) { // biz exception. throw e; } le = e; } catch (Throwable e) { le = new RpcException(e.getMessage(), e); } finally { providers.add(invoker.getUrl().getAddress()); } } throw new RpcException(le.getCode(), \"Failed to invoke the method \" + methodName + \" in the service \" + getInterface().getName() + \". Tried \" + len + \" times of the providers \" + providers + \" (\" + providers.size() + \"/\" + copyinvokers.size() + \") from the registry \" + directory.getUrl().getAddress() + \" on the consumer \" + NetUtils.getLocalHost() + \" using the dubbo version \" + Version.getVersion() + \". Last error is: \" + le.getMessage(), le.getCause() != null ? le.getCause() : le);} 所以会有如下的线程栈信息： 123at org.apache.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:78)at org.apache.dubbo.rpc.cluster.support.AbstractClusterInvoker.invoke(AbstractClusterInvoker.java:243)at org.apache.dubbo.rpc.cluster.support.wrapper.MockClusterInvoker.invoke(MockClusterInvoker.java:75) 这些类都是关于Dubbo的集群容错机制（将会写一篇关于Dubbo的集群容错机制）。 再往下看invokers是如何生成的呢？又回到AbstractClusterInvoker的invoke方法实现： 123456789101112131415161718192021@Overridepublic Result invoke(final Invocation invocation) throws RpcException { checkWhetherDestroyed(); LoadBalance loadbalance = null; // binding attachments into invocation. Map&lt;String, String&gt; contextAttachments = RpcContext.getContext().getAttachments(); if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) { ((RpcInvocation) invocation).addAttachments(contextAttachments); } //会调用directory的list方法 返回要调用invokers集合。 //其实是AbstractDirectory的list方法，这个方法里就是利用路由规则（如果有），从所有 //提供者中，遴选出符合规则的提供者,接下里才是，集群容错和负载均衡。 List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); if (invokers != null &amp;&amp; !invokers.isEmpty()) { //通过key（loadbalance）从url中取值，默认值为random loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(RpcUtils.getMethodName(invocation), Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); } RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); return doInvoke(invocation, invokers, loadbalance);} 再来看一下list方法： 12345protected List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException { //directory.list(invocation)获取invokers，这里directory是RegistryDirectory List&lt;Invoker&lt;T&gt;&gt; invokers = directory.list(invocation); return invokers;} 跟到RegistryDirectory类的list方法，实现在其父类AbstractDirectory中，主要是生成路由规则（将会在另一篇文章中详细讲解，敬请期待）： 1234567891011121314151617181920212223@Overridepublic List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException { if (destroyed) { throw new RpcException(\"Directory already destroyed .url: \" + getUrl()); } //获取所有的提供者 List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation); //本地路由规则 List&lt;Router&gt; localRouters = this.routers; // local reference if (localRouters != null &amp;&amp; !localRouters.isEmpty()) { for (Router router : localRouters) { try { if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, false)) { //Router接口，实现route的方法，路由获取服务提供者 invokers = router.route(invokers, getConsumerUrl(), invocation); } } catch (Throwable t) { logger.error(\"Failed to execute router: \" + getUrl() + \", cause: \" + t.getMessage(), t); } } } return invokers;} 再来看一下doList方法，它是个抽象方法具体实现在RegistryDirectory类中： 12345678910111213141516171819202122232425262728293031323334@Overridepublic List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) { //没有服务提供者或者服务提供者被禁用 if (forbidden) { // 1. No service provider 2. Service providers are disabled throw new RpcException(RpcException.FORBIDDEN_EXCEPTION, \"No provider available from registry \" + getUrl().getAddress() + \" for service \" + getConsumerUrl().getServiceKey() + \" on consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", please check status of providers(disabled, not registered or in blacklist).\"); } List&lt;Invoker&lt;T&gt;&gt; invokers = null; //从这里搜索methodInvokerMap赋值，在refreshInvoker方法里 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; localMethodInvokerMap = this.methodInvokerMap; // local reference if (localMethodInvokerMap != null &amp;&amp; localMethodInvokerMap.size() &gt; 0) { String methodName = RpcUtils.getMethodName(invocation); Object[] args = RpcUtils.getArguments(invocation); if (args != null &amp;&amp; args.length &gt; 0 &amp;&amp; args[0] != null &amp;&amp; (args[0] instanceof String || args[0].getClass().isEnum())) { invokers = localMethodInvokerMap.get(methodName + \".\" + args[0]); // The routing can be enumerated according to the first parameter } if (invokers == null) { invokers = localMethodInvokerMap.get(methodName); } if (invokers == null) { invokers = localMethodInvokerMap.get(Constants.ANY_VALUE); } if (invokers == null) { Iterator&lt;List&lt;Invoker&lt;T&gt;&gt;&gt; iterator = localMethodInvokerMap.values().iterator(); if (iterator.hasNext()) { invokers = iterator.next(); } } } return invokers == null ? new ArrayList&lt;Invoker&lt;T&gt;&gt;(0) : invokers;} 下面是refreshInvoker(List&lt;URL&gt; invokerUrls)方法的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Convert the invokerURL list to the Invoker Map. The rules of the conversion are as follows: * 1.If URL has been converted to invoker, it is no longer re-referenced and obtained directly from the cache, and notice that any parameter changes in the URL will be re-referenced. * 2.If the incoming invoker list is not empty, it means that it is the latest invoker list * 3.If the list of incoming invokerUrl is empty, It means that the rule is only a override rule or a route rule, which needs to be re-contrasted to decide whether to re-reference. * * @param invokerUrls this parameter can't be null */// TODO: 2017/8/31 FIXME The thread pool should be used to refresh the address, otherwise the task may be accumulated.private void refreshInvoker(List&lt;URL&gt; invokerUrls) { if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) { //禁止访问 this.forbidden = true; // Forbid to access //置空列表 this.methodInvokerMap = null; // Set the method invoker map to null //关闭所有invokers destroyAllInvokers(); // Close all invokers } else { //允许访问 this.forbidden = false; // Allow to access Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) { invokerUrls.addAll(this.cachedInvokerUrls); } else { this.cachedInvokerUrls = new HashSet&lt;URL&gt;(); //缓存invokerUrls列表，便于交叉对比 this.cachedInvokerUrls.addAll(invokerUrls);//Cached invoker urls, convenient for comparison } if (invokerUrls.isEmpty()) { return; } //生成invoker方法 toInvokers //将url列表转换成invoker列表 Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map //换方法名映射invoker列表 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // Change method name to map Invoker Map // state change // If the calculation is wrong, it is not processed. //如果计算错误则不进行处理 if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) { logger.error(new IllegalStateException(\"urls to invokers error .invokerUrls.size :\" + invokerUrls.size() + \", invoker.size :0. urls :\" + invokerUrls.toString())); return; } this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap; this.urlInvokerMap = newUrlInvokerMap; try { //关闭不使用的invoker destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker } catch (Exception e) { logger.warn(\"destroyUnusedInvokers error. \", e); } }} 可以知道refreshInvoker()方法会在RegistryDirectory类的notify()方法里调用，这个方法是订阅注册中心的回调方法。下面来看一下toInvokers()的方法实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * Turn urls into invokers, and if url has been refer, will not re-reference. * 将urls转换成invokers，如果url已经被refer过则不在重新引用 * @param urls * @return invokers */private Map&lt;String, Invoker&lt;T&gt;&gt; toInvokers(List&lt;URL&gt; urls) { Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = new HashMap&lt;String, Invoker&lt;T&gt;&gt;(); if (urls == null || urls.isEmpty()) { return newUrlInvokerMap; } Set&lt;String&gt; keys = new HashSet&lt;String&gt;(); String queryProtocols = this.queryMap.get(Constants.PROTOCOL_KEY); for (URL providerUrl : urls) { // If protocol is configured at the reference side, only the matching protocol is selected //若果reference端配置了protocol，则只选择匹配的protocol if (queryProtocols != null &amp;&amp; queryProtocols.length() &gt; 0) { boolean accept = false; String[] acceptProtocols = queryProtocols.split(\",\"); for (String acceptProtocol : acceptProtocols) { if (providerUrl.getProtocol().equals(acceptProtocol)) { accept = true; break; } } if (!accept) { continue; } } if (Constants.EMPTY_PROTOCOL.equals(providerUrl.getProtocol())) { continue; } if (!ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(providerUrl.getProtocol())) { logger.error(new IllegalStateException(\"Unsupported protocol \" + providerUrl.getProtocol() + \" in notified url: \" + providerUrl + \" from registry \" + getUrl().getAddress() + \" to consumer \" + NetUtils.getLocalHost() + \", supported protocol: \" + ExtensionLoader.getExtensionLoader(Protocol.class).getSupportedExtensions())); continue; } URL url = mergeUrl(providerUrl); //url参数是排序的 String key = url.toFullString(); // The parameter urls are sorted //跳过重复的url if (keys.contains(key)) { // Repeated url continue; } keys.add(key); // Cache key is url that does not merge with consumer side parameters, regardless of how the consumer combines parameters, if the server url changes, then refer again //缓存key为没有合并消费端参数的URL，不管消费端如何合并参数，如果服务端URL发生变化，则重新refer Map&lt;String, Invoker&lt;T&gt;&gt; localUrlInvokerMap = this.urlInvokerMap; // local reference Invoker&lt;T&gt; invoker = localUrlInvokerMap == null ? null : localUrlInvokerMap.get(key); if (invoker == null) { // Not in the cache, refer again try { boolean enabled = true; if (url.hasParameter(Constants.DISABLED_KEY)) { enabled = !url.getParameter(Constants.DISABLED_KEY, false); } else { enabled = url.getParameter(Constants.ENABLED_KEY, true); } if (enabled) { //创建invoker（这里创建invoker） invoker = new InvokerDelegate&lt;T&gt;(protocol.refer(serviceType, url), url, providerUrl); } } catch (Throwable t) { logger.error(\"Failed to refer invoker for interface:\" + serviceType + \",url:(\" + url + \")\" + t.getMessage(), t); } if (invoker != null) { // Put new invoker in cache //将新的引用放入缓存 newUrlInvokerMap.put(key, invoker); } } else { newUrlInvokerMap.put(key, invoker); } } keys.clear(); return newUrlInvokerMap;} 找到了invoker的创建地方，来看下InvokerDelegate，它是RegistryDirectory的内部类： 12345678910111213141516171819/** * The delegate class, which is mainly used to store the URL address sent by the registry,and can be reassembled on the basis of providerURL queryMap overrideMap for re-refer. * 代理类，主要用于存储注册中心下发的URL地址 * 用于重新refer时能够根据providerURL queryMap overrideMap重新组装 * @param &lt;T&gt; */private static class InvokerDelegate&lt;T&gt; extends InvokerWrapper&lt;T&gt; { private URL providerUrl; public InvokerDelegate(Invoker&lt;T&gt; invoker, URL url, URL providerUrl) { //调用父类构造方法 super(invoker, url); this.providerUrl = providerUrl; } public URL getProviderUrl() { return providerUrl; }} invoke方法在父类InvokerWrapper里实现的： 12345@Overridepublic Result invoke(Invocation invocation) throws RpcException { //这里的invoker是从它的构造方法里传入的 return invoker.invoke(invocation);} 所以在调用栈里可以看到如下一条信息： 1at org.apache.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:56) InvokerDelegete构造方法调用的父类InvokerWrapper的构造方法并传入invoker实例，回头看new InvokerDelegate&lt;T&gt;(protocol.refer(serviceType, url), url, providerUrl);这句，可知上面的invoker的是由protocol.refer(serviceType, url)创建的。 通过debug可得知这里的protocol是Protocol$Adaptive类型的，这里的url的protocol是dubbo，通过Dubbo SPI机制可以得到这里最后走DubboProtocol类的refer()方法，但是由于Protocol接口实现中由两个包装类： 12filter=org.apache.dubbo.rpc.protocol.ProtocolFilterWrapperlistener=org.apache.dubbo.rpc.protocol.ProtocolListenerWrapper 所以这里先执行ProtocolFilterWrapper的refer方法，再执行ProtocolListenerWrapper的refer方法，最后才执行DubboProtocol类的refer方法，ProtocolFilterWrapper类的refer方法如下： 1234567@Overridepublic &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { return protocol.refer(type, url); } return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER);} 方法里调用了buildInvokerChain()方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) { Invoker&lt;T&gt; last = invoker; //先获取激活的过滤器，我们这里手动配置了monitor MonitorFilter过滤器 //另外两个自动激活的过滤器是FutureFilter，ConsumerContextFilter //这里需要看SPI机制的getActivateExtension方法的相关代码 List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (!filters.isEmpty()) { for (int i = filters.size() - 1; i &gt;= 0; i--) { final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() { @Override public Class&lt;T&gt; getInterface() { return invoker.getInterface(); } @Override public URL getUrl() { return invoker.getUrl(); } @Override public boolean isAvailable() { return invoker.isAvailable(); } //实现invoker的invoke方法 @Override public Result invoke(Invocation invocation) throws RpcException { //嵌套进过滤器链 return filter.invoke(next, invocation); } @Override public void destroy() { invoker.destroy(); } @Override public String toString() { return invoker.toString(); } }; } } return last;} 所以有如下的调用栈信息： 123456at org.apache.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75)at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:72)at org.apache.dubbo.rpc.protocol.dubbo.filter.FutureFilter.invoke(FutureFilter.java:47)at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:72)at org.apache.dubbo.rpc.filter.ConsumerContextFilter.invoke(ConsumerContextFilter.java:50)at org.apache.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:72) 接着ProtocolListenerWrapper的refer方法： 1234567891011@Overridepublic &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { return protocol.refer(type, url); } //获取激活的监听器，目前dubbo没有提供合适的监听器，只有一个DeprecatedInvokerListener实现类，并且还是Deprecated的 return new ListenerInvokerWrapper&lt;T&gt;(protocol.refer(type, url), Collections.unmodifiableList( ExtensionLoader.getExtensionLoader(InvokerListener.class) .getActivateExtension(url, Constants.INVOKER_LISTENER_KEY)));} 所以会出现如下栈信息： 1at org.apache.dubbo.rpc.listener.ListenerInvokerWrapper.invoke(ListenerInvokerWrapper.java:77) 最后看一下DubboProtocol类的refer方法，这里创建了DubboInvoker对象： 12345678@Overridepublic &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException { optimizeSerialization(url); // create rpc invoker. DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker;} DubboInvoker的父类AbstractInvoker实现了invoke方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Overridepublic Result invoke(Invocation inv) throws RpcException { if (destroyed.get()) { throw new RpcException(\"Rpc invoker for service \" + this + \" on consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \" is DESTROYED, can not be invoked any more!\"); } RpcInvocation invocation = (RpcInvocation) inv; invocation.setInvoker(this); if (attachment != null &amp;&amp; attachment.size() &gt; 0) { invocation.addAttachmentsIfAbsent(attachment); } Map&lt;String, String&gt; contextAttachments = RpcContext.getContext().getAttachments(); if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) { /** * invocation.addAttachmentsIfAbsent(context){@link RpcInvocation#addAttachmentsIfAbsent(Map)}should not be used here, * because the {@link RpcContext#setAttachment(String, String)} is passed in the Filter when the call is triggered * by the built-in retry mechanism of the Dubbo. The attachment to update RpcContext will no longer work, which is * a mistake in most cases (for example, through Filter to RpcContext output traceId and spanId and other information). */ invocation.addAttachments(contextAttachments); } if (getUrl().getMethodParameter(invocation.getMethodName(), Constants.ASYNC_KEY, false)) { invocation.setAttachment(Constants.ASYNC_KEY, Boolean.TRUE.toString()); } RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); try { //doInvoke()方法具体实现在子类中 return doInvoke(invocation); } catch (InvocationTargetException e) { // biz exception Throwable te = e.getTargetException(); if (te == null) { return new RpcResult(e); } else { if (te instanceof RpcException) { ((RpcException) te).setCode(RpcException.BIZ_EXCEPTION); } return new RpcResult(te); } } catch (RpcException e) { if (e.isBiz()) { return new RpcResult(e); } else { throw e; } } catch (Throwable e) { return new RpcResult(e); }} 看一下DubboInvoker实现的doInvoke方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Overrideprotected Result doInvoke(final Invocation invocation) throws Throwable { RpcInvocation inv = (RpcInvocation) invocation; final String methodName = RpcUtils.getMethodName(invocation); inv.setAttachment(Constants.PATH_KEY, getUrl().getPath()); inv.setAttachment(Constants.VERSION_KEY, version); ExchangeClient currentClient; if (clients.length == 1) { currentClient = clients[0]; } else { currentClient = clients[index.getAndIncrement() % clients.length]; } try { boolean isAsync = RpcUtils.isAsync(getUrl(), invocation); boolean isAsyncFuture = RpcUtils.isGeneratedFuture(inv) || RpcUtils.isFutureReturnType(inv); boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); int timeout = getUrl().getMethodParameter(methodName, Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (isOneway) { boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture(null); return new RpcResult(); } else if (isAsync) { ResponseFuture future = currentClient.request(inv, timeout); // For compatibility FutureAdapter&lt;Object&gt; futureAdapter = new FutureAdapter&lt;&gt;(future); RpcContext.getContext().setFuture(futureAdapter); Result result; if (isAsyncFuture) { // register resultCallback, sometimes we need the asyn result being processed by the filter chain. result = new AsyncRpcResult(futureAdapter, futureAdapter.getResultFuture(), false); } else { result = new SimpleAsyncRpcResult(futureAdapter, futureAdapter.getResultFuture(), false); } return result; } else { RpcContext.getContext().setFuture(null); return (Result) currentClient.request(inv, timeout).get(); } } catch (TimeoutException e) { throw new RpcException(RpcException.TIMEOUT_EXCEPTION, \"Invoke remote method timeout. method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); } catch (RemotingException e) { throw new RpcException(RpcException.NETWORK_EXCEPTION, \"Failed to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); }} 所以会有这两句线程栈输出： 12at org.apache.dubbo.rpc.protocol.dubbo.DubboInvoker.doInvoke(DubboInvoker.java:108)at org.apache.dubbo.rpc.protocol.AbstractInvoker.invoke(AbstractInvoker.java:154) 接下来就是用于发送请求的currentClient对象的实现了，它的逻辑可以追踪到DubboProtocol类的refer方法里： 12345678@Overridepublic &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException { optimizeSerialization(url); // create rpc invoker. DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker;} 具体的获取逻辑在getClients()方法中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586private ExchangeClient[] getClients(URL url) { // whether to share connection //是否共享连接 boolean service_share_connect = false; int connections = url.getParameter(Constants.CONNECTIONS_KEY, 0); // if not configured, connection is shared, otherwise, one connection for one service //如果没有配置connection，那么就创建共享连接，否则一个服务一个连接？ if (connections == 0) { service_share_connect = true; connections = 1; } ExchangeClient[] clients = new ExchangeClient[connections]; for (int i = 0; i &lt; clients.length; i++) { if (service_share_connect) { clients[i] = getSharedClient(url); } else { clients[i] = initClient(url); } } return clients;}/** * Get shared connection */private ExchangeClient getSharedClient(URL url) { String key = url.getAddress(); ReferenceCountExchangeClient client = referenceClientMap.get(key); if (client != null) { if (!client.isClosed()) { client.incrementAndGetCount(); return client; } else { referenceClientMap.remove(key); } } locks.putIfAbsent(key, new Object()); synchronized (locks.get(key)) { if (referenceClientMap.containsKey(key)) { return referenceClientMap.get(key); } ExchangeClient exchangeClient = initClient(url); client = new ReferenceCountExchangeClient(exchangeClient, ghostClientMap); referenceClientMap.put(key, client); ghostClientMap.remove(key); locks.remove(key); return client; }}/** * Create new connection */private ExchangeClient initClient(URL url) { // client type setting. String str = url.getParameter(Constants.CLIENT_KEY, url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_CLIENT)); url = url.addParameter(Constants.CODEC_KEY, DubboCodec.NAME); // enable heartbeat by default //默认开启heartbeat url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); // BIO is not allowed since it has severe performance issue. //BIO存在严重的性能问题，因此不能使用 if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) { throw new RpcException(\"Unsupported client type: \" + str + \",\" + \" supported client type is \" + StringUtils.join(ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(), \" \")); } ExchangeClient client; try { // connection should be lazy if (url.getParameter(Constants.LAZY_CONNECT_KEY, false)) { client = new LazyConnectExchangeClient(url, requestHandler); } else { //通过 Exchangers.connect(url, requestHandler); 构建client ，接下来跟踪Exchangers.connect方法 //这里会传入一个requestHandler，这个是客户端解救服务端方法返回回调的 client = Exchangers.connect(url, requestHandler); } } catch (RemotingException e) { throw new RpcException(\"Fail to create remoting client for service(\" + url + \"): \" + e.getMessage(), e); } return client;} 这里用到了Facade设计模式，Exchangers是个门面类，封装了具体查找合适的Exchanger实现，并调用connect方法返回ExchangeClient的过程，相关代码如下： 12345678910111213141516171819202122public static ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException { if (url == null) { throw new IllegalArgumentException(\"url == null\"); } if (handler == null) { throw new IllegalArgumentException(\"handler == null\"); } url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\"); //把codec key设置为exchange return getExchanger(url).connect(url, handler);}public static Exchanger getExchanger(URL url) { String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER); //通过exchanger key 获取 Exchanger的spi实现，默认是header，这里是HeaderExchanger类 return getExchanger(type);}public static Exchanger getExchanger(String type) { //这里返回Exchanger接口的header扩展类的HeaderExchanger return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type);} 看一下HeaderExchanger类的connect方法： 12345//客户端的连接操作@Overridepublic ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException { return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true);} 所以有栈信息： 1at org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeClient.request(HeaderExchangeClient.java:90) 再来看HeaderExchnageClient的request()方法： 1234567891011121314151617181920212223public HeaderExchangeClient(Client client, boolean needHeartbeat) { if (client == null) { throw new IllegalArgumentException(\"client == null\"); } this.client = client; //初始化HeaderExchangeChannel this.channel = new HeaderExchangeChannel(client); String dubbo = client.getUrl().getParameter(Constants.DUBBO_VERSION_KEY); this.heartbeat = client.getUrl().getParameter(Constants.HEARTBEAT_KEY, dubbo != null &amp;&amp; dubbo.startsWith(\"1.0.\") ? Constants.DEFAULT_HEARTBEAT : 0); this.heartbeatTimeout = client.getUrl().getParameter(Constants.HEARTBEAT_TIMEOUT_KEY, heartbeat * 3); if (heartbeatTimeout &lt; heartbeat * 2) { throw new IllegalStateException(\"heartbeatTimeout &lt; heartbeatInterval * 2\"); } if (needHeartbeat) { startHeartbeatTimer(); }}@Overridepublic ResponseFuture request(Object request) throws RemotingException { //调用Channel的request方法 return channel.request(request);} 因此会有如下的栈信息： 1at org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.request(HeaderExchangeChannel.java:116) 再来看一下HeaderExchangeChannel的request方法： 12345678910111213141516171819202122232425@Overridepublic ResponseFuture request(Object request) throws RemotingException { return request(request, channel.getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT));}@Overridepublic ResponseFuture request(Object request, int timeout) throws RemotingException { if (closed) { throw new RemotingException(this.getLocalAddress(), null, \"Failed to send request \" + request + \", cause: The channel \" + this + \" is closed!\"); } // create request. Request req = new Request(); req.setVersion(Version.getProtocolVersion()); req.setTwoWay(true); req.setData(request); DefaultFuture future = new DefaultFuture(channel, req, timeout); try { //发送请求 channel.send(req); } catch (RemotingException e) { future.cancel(); throw e; } return future;} channel.send(req);中channel实例是通过HeaderExchangeChannel(Channel channel)构造函数初始化的，继续往上看是通过构造函数public HeaderExchangeClient(Client client, boolean needHeartbeat)传进来的，最终生成channel的代码是在类HeaderExchanger中： 1234@Overridepublic ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException { return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true);} 调用Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler)))生成channel实例，这里Transporters也是个门面类，是Facade设计模式的实现，继续分析Transporters的connect方法： 1234567891011121314151617181920public static Client connect(URL url, ChannelHandler... handlers) throws RemotingException { if (url == null) { throw new IllegalArgumentException(\"url == null\"); } ChannelHandler handler; if (handlers == null || handlers.length == 0) { handler = new ChannelHandlerAdapter(); } else if (handlers.length == 1) { handler = handlers[0]; } else { handler = new ChannelHandlerDispatcher(handlers); } //所以这里默认返回的NettyClient return getTransporter().connect(url, handler);}//这个方法根据spi返回NettyTransporter扩展类public static Transporter getTransporter() { //生成Transporter$Adaptive类 return ExtensionLoader.getExtensionLoader(Transporter.class).getAdaptiveExtension();} 所以最后是通过NettyClient类实例的send方法发送具体请求，NettyClient类的send方法在其祖先类AbstractPeer中： 1234@Overridepublic void send(Object message) throws RemotingException { send(message, url.getParameter(Constants.SENT_KEY, false));} 这个实现又调用NettyClient父类AbstractClient的send方法实现： 12345678910111213@Overridepublic void send(Object message, boolean sent) throws RemotingException { if (send_reconnect &amp;&amp; !isConnected()) { connect(); } //获取具体的channel实例 Channel channel = getChannel(); //TODO Can the value returned by getChannel() be null? need improvement. if (channel == null || !channel.isConnected()) { throw new RemotingException(this, \"message can not send, because channel is closed . url:\" + getUrl()); } channel.send(message, sent);} 这里的getChannel()方法由NettyClient自身实现，如下： 1234567@Overrideprotected org.apache.dubbo.remoting.Channel getChannel() { Channel c = channel; if (c == null || !c.isActive()) return null; return NettyChannel.getOrAddChannel(c, getUrl(), this);} 所以有如下栈信息： 123at org.apache.dubbo.remoting.transport.netty4.NettyChannel.send(NettyChannel.java:101)at org.apache.dubbo.remoting.transport.AbstractClient.send(AbstractClient.java:265)at org.apache.dubbo.remoting.transport.AbstractPeer.send(AbstractPeer.java:53) 最后就走到NettyChannel的send方法，即到了断点处： 1234567891011121314151617181920212223242526@Overridepublic void send(Object message, boolean sent) throws RemotingException { super.send(message, sent); boolean success = true; int timeout = 0; try { //断点处 ChannelFuture future = channel.writeAndFlush(message); if (sent) { timeout = getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success = future.await(timeout); } Throwable cause = future.cause(); if (cause != null) { throw cause; } } catch (Throwable e) { throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \", cause: \" + e.getMessage(), e); } if (!success) { throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \"in timeout(\" + timeout + \"ms) limit\"); }} 到此，整个消费者调用过程就分析完了，文章中提到的一些关于Dubbo的核心feature将会写文章进一步分析，敬请期待。","link":"/2018/08/05/dubbo-consumer-calling-process-source-code-analysis/"}],"tags":[{"name":"java","slug":"java","link":"/tags/java/"},{"name":"WebSystem","slug":"WebSystem","link":"/tags/WebSystem/"},{"name":"KVM","slug":"KVM","link":"/tags/KVM/"},{"name":"CentOS","slug":"CentOS","link":"/tags/CentOS/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"MutliThread","slug":"MutliThread","link":"/tags/MutliThread/"},{"name":"nio","slug":"nio","link":"/tags/nio/"},{"name":"LRU","slug":"LRU","link":"/tags/LRU/"},{"name":"cache","slug":"cache","link":"/tags/cache/"},{"name":"MyBatis3","slug":"MyBatis3","link":"/tags/MyBatis3/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"javassist","slug":"javassist","link":"/tags/javassist/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"AQS","slug":"AQS","link":"/tags/AQS/"},{"name":"TreeMap","slug":"TreeMap","link":"/tags/TreeMap/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"虚拟化","slug":"虚拟化","link":"/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"网络配置","slug":"网络配置","link":"/tags/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"DirectIO","slug":"DirectIO","link":"/tags/DirectIO/"},{"name":"log4j","slug":"log4j","link":"/tags/log4j/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/tags/Spring-Cloud/"},{"name":"Micro Service","slug":"Micro-Service","link":"/tags/Micro-Service/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"B+Tree","slug":"B-Tree","link":"/tags/B-Tree/"},{"name":"cpu","slug":"cpu","link":"/tags/cpu/"},{"name":"mmap","slug":"mmap","link":"/tags/mmap/"},{"name":"SPI","slug":"SPI","link":"/tags/SPI/"}],"categories":[{"name":"WebSystem","slug":"WebSystem","link":"/categories/WebSystem/"},{"name":"java","slug":"java","link":"/categories/java/"}]}